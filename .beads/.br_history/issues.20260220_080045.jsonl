{"id":"bd-10a","title":"Add donor-extraction scope document with explicit V8/QuickJS exclusions","description":"## Plan Reference\nSection 10.1 (charter/governance), donor-extraction policy track.\n\n## Objective\nDefine an explicit donor-extraction scope document that permits behavior-level semantic harvesting from legacy donor corpora while explicitly forbidding architecture/runtime transplants from V8/QuickJS into FrankenEngine core.\n\n## Required Outputs\n1. Normative allowlist of donor-extraction artifacts (observable semantics, compatibility edge cases, conformance vectors).\n2. Normative denylist of prohibited donor reuse (core architecture, scheduler/runtime internals, embedding assumptions, hidden compatibility shims).\n3. Review checklist for PRs that consume donor-derived artifacts, including explicit spec-extraction-versus-implementation-source evidence.\n4. Escalation/exception path for ambiguous donor material with mandatory decision record and rollback plan.\n\n## User/Operator Value\n- Prevents accidental architecture drift toward binding-led engines.\n- Preserves compatibility confidence through explicit, auditable extraction rules.\n- Reduces reviewer ambiguity and accelerates safe approvals.\n\n## Verification Requirements\n- Unit tests for policy parser/rule classification if machine-readable policy artifacts are added.\n- E2E validation script exercising acceptance/rejection examples across representative donor samples.\n- Structured logging of policy decisions with stable fields (trace_id, policy_id, decision_id, artifact_class, outcome, reason_code).\n\n## Done Definition\n- Governance artifact published and linked from section-10.1 execution docs.\n- Review workflow updated so donor-use decisions are reproducible and auditable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"in_progress","priority":1,"issue_type":"task","assignee":"StormyPond","created_at":"2026-02-20T07:24:56.303039948Z","created_by":"StormyPond","updated_at":"2026-02-20T08:00:39.458217166Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["architecture","documentation","donor-spec","governance","plan","section-10-1"]}
{"id":"bd-117","title":"[10.11] Add deterministic fallback protocol when anti-entropy reconciliation cannot peel/resolve.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add deterministic fallback protocol when anti-entropy reconciliation cannot peel/resolve.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:37.768994935Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.230592Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-11ni","title":"[11] Define deterministic fallback-trigger conditions and safe-mode entry","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: fallback trigger\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Fallback trigger conditions are formally specified with deterministic predicates.\\n2. Safe-mode transition is exercised by unit tests and end-to-end replay scenarios with structured logs.\\n3. Documentation includes operator-visible trigger semantics and rollback linkage.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:16.714171974Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:26.734124217Z","closed_at":"2026-02-20T07:38:23.098483379Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"],"dependencies":[{"issue_id":"bd-11ni","depends_on_id":"bd-von8","type":"blocks","created_at":"2026-02-20T07:38:26.271271018Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-11p","title":"[10.7] Integrate `test262` ES2020 normative profile as a release blocker with explicit waiver file and zero silent failures policy.","description":"## Plan Reference\nSection 10.7 (Conformance + Verification), item 2.\nPhase A exit gate: \"ES2020 conformance gate: applicable test262 ES2020 normative profile passes with explicit zero-surprise waiver policy (waivers allowed only for documented non-normative harness/host gaps, never silent semantic failures).\"\nRelated: 10.1 (feature-parity tracker), 10.2 (VM Core), 9A.1 (TS-first capability-typed IR execution).\n\n## What\nIntegrate the official ECMA-402/test262 ES2020 normative test profile into FrankenEngine's CI pipeline as a hard release blocker, with an explicit machine-readable waiver file governing all non-passing tests and a zero-silent-failures enforcement policy.\n\n## Detailed Requirements\n1. **test262 checkout and pinning:** Pin a specific test262 commit hash in `conformance_pins.toml`. The pinned revision must cover the ES2020 normative profile (up to and including ES2020 features). Updates to the pin require a tracked bead and diff review.\n2. **Profile selection:** Define an explicit test262 profile filter (`test262_profile.toml`) that includes all normative ES2020 tests and excludes: (a) tests for post-ES2020 proposals, (b) Annex B tests marked optional, (c) Intl/ECMA-402 tests (separate conformance track). Each exclusion must cite the normative clause justification.\n3. **Harness implementation:** Implement test262 harness hooks (`$262.createRealm`, `$262.evalScript`, `$262.gc`, `$262.detachArrayBuffer`, `$DONE`, `print`, `assert.throws`, `assert.sameValue`, etc.) as a dedicated Rust module (`crate::test_harness::test262`). Hooks must faithfully implement ES2020 semantics without shortcuts.\n4. **Waiver file (`conformance_waivers.toml`):** Shared with bd-d93. Each waiver entry requires: `test_id`, `reason_code` (enum: `harness_gap | host_hook_missing | intentional_divergence | not_yet_implemented`), `es2020_clause`, `tracking_bead`, `expiry_date`, `reviewer`. Waivers are reviewed monthly; expired waivers cause CI failure.\n5. **Zero silent failures policy:** Any test262 test that is not explicitly (a) passing or (b) waived causes a hard CI gate failure. No \"expected failure\" lists, no \"known flaky\" suppression outside the waiver file.\n6. **Parallel runner:** test262 contains ~45,000 tests. Runner must support parallel execution with deterministic scheduling (sorted test order, fixed worker assignment) so failures are reproducible.\n7. **Structured reporting:** Emit per-test structured log: `trace_id`, `test_id`, `es2020_clause`, `outcome` (pass|fail|waived|timeout|crash), `duration_us`, `error_code`, `error_detail`. Aggregate into `test262_evidence.jsonl` with run manifest, profile hash, waiver file hash, and environment fingerprint.\n8. **Release gate integration:** Wire the test262 gate into the release pipeline so that no release candidate can be cut while any unwaived test262 failure exists. Gate status is visible in the release checklist artifact.\n9. **Regression tracking:** Maintain a monotonic pass-count high-water mark. Any commit that reduces the pass count (net of waiver changes) triggers a CI warning and requires explicit acknowledgment.\n\n## Rationale\ntest262 is the industry-standard correctness oracle for ECMAScript engines. Without it as a release blocker, conformance claims are unverifiable. The waiver file makes the gap between current implementation and full conformance transparent and auditable. The zero-silent-failures policy ensures that conformance progress is monotonic and regressions are caught immediately, not discovered during release qualification.\n\n## Testing Requirements (Meta-Tests for Test Infrastructure)\n1. **Harness correctness meta-test:** Run a curated subset of test262 tests (>= 200, covering all harness hooks) against a known-good reference engine (e.g., V8 via d8) and confirm identical pass/fail classification.\n2. **Waiver enforcement meta-test:** Inject a synthetic test that fails without a waiver entry and confirm CI blocks. Add a waiver and confirm CI passes. Remove the waiver and confirm CI blocks again.\n3. **Expiry enforcement meta-test:** Set a waiver expiry to yesterday and confirm CI fails with a clear message identifying the expired waiver.\n4. **Parallelism determinism meta-test:** Run the suite twice with the same seed and confirm identical test ordering and identical pass/fail sets.\n5. **High-water-mark regression meta-test:** Simulate a commit that breaks a previously passing test without adding a waiver and confirm the regression warning fires.\n6. **Profile filter meta-test:** Confirm the profile filter excludes exactly the intended test categories and includes no post-ES2020 tests.\n\n## Implementation Notes\n- test262 is checked out as a git submodule under `vendor/test262/` or fetched via a pinned archive URL.\n- Runner binary: `franken_test262_runner` built as a separate binary target to avoid bloating the main engine binary.\n- Waiver file path: `conformance/waivers/conformance_waivers.toml` (shared with bd-d93).\n- Integration with `rch`-wrapped commands for heavy parallel test execution.\n- The pass-count high-water mark is stored in `conformance/test262_hwm.json` and checked in to source control.\n\n## Dependencies\n- Upstream: 10.2 (VM Core must implement enough ES2020 semantics to run test262 tests), bd-d93 (shared waiver file and evidence format).\n- Downstream: bd-2vu (lockstep suite references test262 pass/fail classification), 10.9 release gates (test262 conformance is a Phase A exit gate prerequisite).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:26.184167072Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.378308353Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-11ua","title":"[13] PLAS produces signed `capability_witness` artifacts for >= 90% of targeted extension cohorts in production lanes","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: PLAS produces signed `capability_witness` artifacts for >= 90% of targeted extension cohorts in production lanes\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:24.766230125Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:26.827487144Z","closed_at":"2026-02-20T07:39:58.284248144Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-11z7","title":"[10.13] Add compile-time lint/CI guard rejecting ambient authority in extension-host control paths.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Add compile-time lint/CI guard rejecting ambient authority in extension-host control paths.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:43.934720672Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.420470162Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-121","title":"[10.11] Build deterministic lab runtime harness with schedule replay, virtual time, and cancellation injection.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Build deterministic lab runtime harness with schedule replay, virtual time, and cancellation injection.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:34.501148876Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.594138774Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-127","title":"[10.11] Add bounded masking helper for tiny atomic publication steps only; block long-operation masking by policy.","description":"## Plan Reference\n- **Section**: 10.11 item 5 (FrankenSQLite-Inspired Runtime Systems Track)\n- **9G Cross-ref**: 9G.2 — Cancellation as protocol (request -> drain -> finalize)\n- **Top-10 Links**: #3 (Deterministic evidence graph + replay)\n\n## What\nAdd a bounded masking helper that allows tiny atomic publication steps to temporarily mask cancellation signals, with a strict policy that blocks long-operation masking. This ensures that critical atomic commit points (e.g., writing a finalized checkpoint, publishing an evidence entry, completing a two-phase commit) are not interrupted mid-operation while preventing abuse of masking to delay cancellation.\n\n## Detailed Requirements\n1. Define a \\`CancelMask\\` guard type that temporarily suppresses cancellation observation within a scoped block.\n2. \\`CancelMask\\` must enforce a hard maximum duration bound (configurable, default 1ms) and a hard maximum instruction/operation count bound (configurable, default 64 operations).\n3. If either bound is exceeded, the mask automatically drops and cancellation becomes observable. The violation is recorded as a \\`MaskBoundExceeded\\` evidence event with severity \\`warning\\` in production and \\`fatal\\` in lab mode.\n4. \\`CancelMask::new()\\` requires a \\`MaskJustification\\` parameter containing: \\`operation_name\\`, \\`expected_duration_hint\\`, \\`atomicity_reason\\`.\n5. Nesting of \\`CancelMask\\` is forbidden; attempting to create a nested mask must return \\`MaskNestingDenied\\` error.\n6. Policy enforcement: a \\`MaskPolicy\\` configuration defines which operation names are allowed to mask and their per-operation bounds. Operations not in the allowlist cannot create masks.\n7. All mask creation and release events must be recorded for replay determinism: \\`trace_id\\`, \\`region_id\\`, \\`mask_id\\`, \\`operation_name\\`, \\`duration_actual\\`, \\`outcome\\` (clean_release / bound_exceeded / cancel_deferred).\n\n## Rationale\nThe 9G.2 cancellation protocol requires that cancellation is always observable, but some operations (atomic writes, hash-linked append, two-phase commit finalization) must complete atomically to avoid corruption. The bounded masking helper resolves this tension: it permits atomic completion while making it structurally impossible to abuse masking as a cancellation-avoidance mechanism. The hard bounds and policy allowlist prevent long operations from hiding behind masks, which would violate the \\`<= 250ms\\` containment SLO.\n\n## Testing Requirements\n- **Unit tests**: Verify mask correctly suppresses cancellation within bounds. Verify automatic drop on duration bound exceeded. Verify automatic drop on operation count exceeded. Verify nesting denial. Verify policy allowlist enforcement.\n- **Property tests**: Fuzz mask durations and verify bound enforcement is never violated (mask never exceeds configured bounds by more than one check interval).\n- **Integration tests**: Within a region-quiescence scenario (bd-2ao), create a mask during drain phase, verify atomic operation completes, then verify cancellation proceeds after mask release.\n- **Lab mode test**: Verify that mask bound violation is fatal in lab mode (bd-121 harness).\n- **Logging/observability**: Mask events carry structured fields for replay correlation and audit.\n- **Reproducibility**: Mask timing must use virtual time in deterministic lab runtime for replay stability.\n\n## Implementation Notes\n- Implement as a RAII guard (\\`Drop\\` impl restores cancellation observability).\n- Use thread-local or \\`Cx\\`-embedded state to track mask nesting depth and enforce the no-nesting rule.\n- Duration bounds should be checked via monotonic clock (or virtual clock in lab mode), not wall clock.\n- The \\`MaskPolicy\\` should be loadable from runtime configuration and updateable via policy epoch transitions (bd-xga).\n\n## Dependencies\n- Depends on: bd-2ao (region-quiescence protocol provides the cancellation flag that masks interact with), bd-3vg (checkpoint contract defines where masks are valid).\n- Blocks: bd-1bl (obligation channels may use masks for atomic commit steps).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:33.901233114Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.778462041Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-12m","title":"[10.6] Performance Program - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.6: Performance Program\n\n## Overview\nThis epic covers the systematic performance engineering program: benchmark suite design, denominator math, profiling infrastructure, optimization workflow, and security-proof-guided specialization benchmarks.\n\n## Child Beads\n- bd-2ql: Define and publish Extension-Heavy Benchmark Suite v1.0 (foundational)\n- bd-2n9: Implement benchmark denominator calculator (weighted geometric mean)\n- bd-1nn: Add flamegraph pipeline and artifact storage\n- bd-js4: Add opportunity matrix scoring to optimization workflow\n- bd-2l6: Enforce one-lever-per-change performance policy\n- bd-3qv: Add constrained-vs-ambient benchmark lanes (PLAS/IFC specialization uplift)\n\n## Dependency Chain\nbd-2ql (benchmark suite) → bd-2n9 (denominator) → bd-1nn (flamegraphs) → bd-js4 (opportunity matrix) → bd-2l6 (one-lever policy)\nbd-2ql → bd-3qv (constrained vs ambient, also depends on 10.15 PLAS/IFC)\n\n## Key Requirements\n- >= 3x weighted geometric mean vs both Node and Bun (Phase C exit gate)\n- Profile-first discipline: baseline → profile → prove → implement → verify\n- One optimization lever per commit with score >= 2.0\n- Behavior-equivalence requirements for all benchmark comparisons\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.562536505Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:10.632299886Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-6"],"dependencies":[{"issue_id":"bd-12m","depends_on_id":"bd-19l0","type":"parent-child","created_at":"2026-02-20T07:53:36.071233879Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-1nn","type":"parent-child","created_at":"2026-02-20T07:52:45.139545949Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-1yq","type":"blocks","created_at":"2026-02-20T07:32:55.957795889Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-2l6","type":"parent-child","created_at":"2026-02-20T07:52:48.413583884Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-2n9","type":"parent-child","created_at":"2026-02-20T07:52:48.713280628Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-2ql","type":"parent-child","created_at":"2026-02-20T07:52:49.031875601Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-3qv","type":"parent-child","created_at":"2026-02-20T07:52:53.542309252Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-js4","type":"parent-child","created_at":"2026-02-20T07:52:56.019650066Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12m","depends_on_id":"bd-ntq","type":"blocks","created_at":"2026-02-20T07:32:55.871267855Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-12n5","title":"[10.15] Publish governance scorecards covering attested-receipt coverage, privacy-budget health, moonshot-governor decisions, and cross-repo conformance stability.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Publish governance scorecards covering attested-receipt coverage, privacy-budget health, moonshot-governor decisions, and cross-repo conformance stability.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:49.637142682Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.441280081Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-12p","title":"[10.12] Add incident replay artifact bundle format and verifier CLI for external audit.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Add incident replay artifact bundle format and verifier CLI for external audit.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:39.330652847Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.358826393Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-133a","title":"[10.15] Add frankensqlite-backed specialization index enabling deterministic audit queries from security proof -> optimization receipt -> benchmark outcome.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankensqlite-backed specialization index enabling deterministic audit queries from security proof -> optimization receipt -> benchmark outcome.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:53.380938673Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.279966191Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-13a5","title":"[11] Define and enforce evidence-and-decision contract template for all subsystem proposals.","description":"## Plan Reference\nSection 11: Evidence And Decision Contracts (Mandatory)\n\n## What\nCreate a mandatory contract template that every major subsystem proposal must satisfy before merge. The template enforces artifact-backed discipline across the entire program.\n\n## Required Template Fields\nEvery proposal must include ALL of the following:\n1. **Change summary**: What is being proposed and why\n2. **Hotspot/threat evidence**: Profile data, threat model, or risk assessment justifying the change\n3. **EV score and tier**: Expected value assessment using the program's EV >= 2.0 threshold from alien-graveyard methodology (Section 5.3)\n4. **Expected-loss model**: Explicit loss matrix for the action space, following alien-artifact-coding discipline (Section 5.2)\n5. **Fallback trigger**: Conditions under which the change auto-reverts or degrades to safe mode\n6. **Rollout wedge**: Staged deployment strategy (shadow -> canary -> ramp -> default per Section 8.8)\n7. **Rollback command**: Exact command(s) to revert the change\n8. **Benchmark and correctness artifacts**: Before/after performance data, golden output checksums, test results\n\n## Enforcement Rule\n'No contract, no merge.' This is a hard gate, not a guideline.\n\n## Rationale\nFrom the plan's ambition-first doctrine: every claim must ship with proof artifacts. This contract template ensures that principle is operationalized at the PR level, preventing unfounded changes from entering the codebase.\n\n## Testing Requirements\n- Unit test: validate that a contract struct with any missing field fails validation\n- Unit test: validate that a complete contract struct passes validation\n- Integration test: CI gate that rejects PRs touching runtime code without a linked contract artifact\n- Test that contract schema is versioned and backward-compatible\n\n## Implementation Notes\n- Implement as a Rust struct with serde support in a shared governance module\n- Consider a CLI subcommand (frankenctl contract validate) for pre-commit checking\n- Store validated contracts alongside code changes in a canonical location\n- Reference: The extreme-software-optimization methodology (Section 5.1) mandates baseline/profile/prove/implement/verify for every optimization - this contract template is the enforcement mechanism\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.\n\n## Scope Boundary\\nThis bead defines the mandatory evidence/declaration template contract and should remain the canonical governance gate for proposal completeness across subsystems.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:38:55.368693030Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.190894677Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","documentation","evidence","governance","plan","section-11"]}
{"id":"bd-1401","title":"[14] Adversarial resilience (campaign success-rate suppression vs baseline engines).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Adversarial resilience (campaign success-rate suppression vs baseline engines).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:33.792382432Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:27.173003310Z","closed_at":"2026-02-20T07:41:19.377640744Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-14da","title":"[14] Compute per-case speedup `r_i = throughput_franken_engine_i / throughput_B_i`.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Compute per-case speedup `r_i = throughput_franken_engine_i / throughput_B_i`.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:30.438475371Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:27.220209075Z","closed_at":"2026-02-20T07:41:20.824984602Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-1525","title":"[13] manual policy-authoring time for onboarded extensions is reduced by >= 70% while maintaining security gate compliance","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: manual policy-authoring time for onboarded extensions is reduced by >= 70% while maintaining security gate compliance\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:25.232809293Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:27.291185615Z","closed_at":"2026-02-20T07:39:58.086563560Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-15g2","title":"[10.15] Add governance audit ledger capturing all automatic and human override promote/hold/kill decisions with signed rationale.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add governance audit ledger capturing all automatic and human override promote/hold/kill decisions with signed rationale.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:48.647418079Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.691844320Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-15vm","title":"[12] Reduce operational complexity via evidence-ledger tooling and deterministic fallback mode","description":"Plan Reference: section 12 (Risk Register).\nObjective: Operational complexity:\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:18.176437649Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:27.395759974Z","closed_at":"2026-02-20T07:39:04.733555437Z","close_reason":"Consolidated into single risk register tracking bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-12"]}
{"id":"bd-161","title":"[10.2] Define proof-to-specialization linkage in IR contracts (`proof_input_ids`, `optimization_class`, `validity_epoch`, `rollback_token`) for IR3/IR4 artifacts.","description":"## Plan Reference\nSection 10.2, item 6. Cross-refs: 9I.8 (Security-Proof-Guided Specialization), 9F.1 (Verified Adaptive Compiler), 10.12 (proof schema for optimizer), 10.15 (specialization receipt schema).\n\n## What\nDefine the linkage between security proofs and optimizer specializations in IR3/IR4 artifacts. This enables security proofs to serve as optimizer inputs, so tighter verified constraints yield faster executable paths.\n\n## Detailed Requirements\n- IR3 artifacts must carry: proof_input_ids (which proofs justify this specialization), optimization_class (superinstruction, trace specialization, layout specialization, devirtualized hostcall fast paths), validity_epoch (when this specialization expires), rollback_token (how to revert to unspecialized path)\n- IR4 witness artifacts must record: which specializations were active during execution, what proofs were consumed, performance delta observed\n- Specializations must be invalidated deterministically on policy/proof epoch changes (per 9I.8)\n- Automatic fallback to unspecialized baseline paths when proofs expire or are invalidated\n\n## Rationale\nSection 9I.8: 'Make security proofs first-class optimizer inputs so tighter verified constraints yield faster executable paths instead of being treated as overhead.' This creates a structural flywheel: better security → better proofs → faster code → more security investment justified. This is described as 'a structural flywheel unavailable to generic runtimes without proof-bearing security planes.'\n\n## Testing Requirements\n- Unit tests: IR3 artifacts with proof linkage serialize/deserialize correctly\n- Unit tests: specialization invalidation on epoch change triggers rollback\n- Unit tests: fallback path produces semantically identical results to specialized path\n- Specialization-conformance suite (10.7): proof-specialized and unspecialized execution remain semantically equivalent\n\n## Dependencies\n- Blocked by: IR contract (bd-1wa), IFC flow-lattice (bd-1fm)\n- Blocks: optimizer activation (10.12), specialization receipt schema (10.15), specialization-conformance suite (10.7)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:22.063014834Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.487458340Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-16n","title":"[10.10] Add optional threshold-signing workflow for emergency revocation and key rotation operations.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Add optional threshold-signing workflow for emergency revocation and key rotation operations.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:30.817987466Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.360241311Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-16u","title":"[10.10] Define trust-zone taxonomy and capability ceilings with deterministic inheritance semantics.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Define trust-zone taxonomy and capability ceilings with deterministic inheritance semantics.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:31.812601797Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.070858106Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-16up","title":"[16] Reference proofs or proof sketches for key policy and protocol safety claims.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: Reference proofs or proof sketches for key policy and protocol safety claims.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:36.451806803Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:27.583603340Z","closed_at":"2026-02-20T07:46:50.921665748Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-16x","title":"[10.4] Implement module cache invalidation strategy.","description":"## Plan Reference\nSection 10.4, item 2. Cross-refs: 9A.5 (supply-chain trust), 9A.10 (provenance + revocation), 10.10 (revocation).\n\n## What\nImplement module cache invalidation strategy that correctly handles trust revocation, code updates, and policy changes without stale or compromised code remaining in the cache.\n\n## Detailed Requirements\n- Cache invalidation on code update: when module source changes, cached compiled form is invalidated\n- Cache invalidation on trust revocation: when a module's trust is revoked (10.10 revocation fabric), cached code must be immediately invalidated and re-resolution must fail or use safe fallback\n- Cache invalidation on policy change: when capability policy changes, cached modules with stale policy assumptions must be re-validated\n- Deterministic invalidation: cache state transitions must be reproducible for replay\n- No stale code: there must be no window where revoked code continues executing from cache\n- Cache coherence: distributed runtime instances must converge on cache state\n\n## Rationale\nModule caching is essential for performance, but stale caches are a security risk. The plan's supply-chain trust fabric (9A.5) and revocation fabric (9A.10) require that trust revocation propagates to all cached code. If compromised module code remains cached after revocation, the revocation is ineffective. Deterministic invalidation is required for replay (9A.3).\n\n## Testing Requirements\n- Unit tests: cache hit for unchanged module, cache miss after source change\n- Unit tests: cache invalidation on trust revocation event\n- Unit tests: cache invalidation on policy change affecting module capabilities\n- Unit tests: no stale code accessible after invalidation\n- Integration tests: end-to-end revocation → cache invalidation → re-resolution flow\n- Determinism tests: same invalidation sequence produces same cache state\n\n## Implementation Notes\n- Cache key should include: module specifier + source hash + policy version + trust state\n- Consider content-addressed cache entries for efficient invalidation\n- Revocation integration requires subscription to revocation events from 10.10\n- Cache coherence for distributed scenarios is covered by anti-entropy (10.11)\n\n## Dependencies\n- Blocked by: module resolver (bd-tgv), revocation fabric (10.10)\n- Blocks: compatibility mode matrix (bd-3vp), production deployment reliability\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:23.634424Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.946321111Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-4"]}
{"id":"bd-17v2","title":"[10.15] Add mandatory receipt + replay linkage for every escrow, deny, or emergency grant decision.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add mandatory receipt + replay linkage for every escrow, deny, or emergency grant decision.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:50.968457919Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.115394977Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-181","title":"[10.9] Release gate: GA default lanes are fully native (`0` mandatory delegate cells), with complete signed replacement lineage for all formerly delegated core slots (implementation ownership: `10.15` + `10.2` + `10.7`).","description":"## Plan Reference\nSection 10.9, item 7 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that all GA (Generally Available) default lanes are fully native -- meaning zero mandatory delegate cells remain -- and that every formerly delegated core slot has a complete, signed replacement lineage proving the provenance of its native replacement. The gate confirms that FrankenEngine's GA configuration no longer depends on any external delegate runtime for core functionality.\n\nThe gate owner does not build the native replacements; the gate owner audits lane configurations, counts delegate cells, and validates replacement lineage signatures.\n\n## Gate Criteria\n1. The GA default lane configuration contains exactly `0` mandatory delegate cells. Every core slot (parser, compiler, optimizer, runtime builtins, GC integration points) is served by a native FrankenEngine implementation.\n2. For each core slot that was previously delegated, a signed replacement lineage artifact exists containing: slot identifier, former delegate identity, replacement component identity, replacement author, replacement date, behavioral equivalence test suite reference, and lineage signature.\n3. Replacement lineage signatures are verifiable using the project's published trust anchor without access to the signing service.\n4. Behavioral equivalence between the former delegate and the native replacement is demonstrated by a shared conformance test suite that both pass (with documented exceptions, if any, that are explicitly accepted).\n5. No hidden compatibility shims or silent fallback-to-delegate paths exist in the GA configuration. A runtime audit confirms that delegate code paths are unreachable in the GA lane.\n6. Optional delegate lanes (for backward compatibility or testing) remain available but are not the default and are clearly labeled as non-native.\n\n## Implementation Ownership\n- **10.15 (Delta Moonshots):** Builds native replacements for delegated slots and the replacement lineage signing infrastructure. Encompasses 9I moonshots: Verified Self-Replacement, PLAS.\n- **10.2 (Core Runtime):** Provides the native runtime implementations that replace delegate cells.\n- **10.7 (Conformance + Verification):** Provides the behavioral equivalence test suites and conformance infrastructure.\n- **10.9 (this gate):** Audits GA lane configuration, validates delegate-cell count, verifies replacement lineage signatures, and confirms no hidden delegate fallbacks.\n\n## Rationale\nA runtime that depends on delegate cells for core functionality is, by definition, not fully its own engine -- it is a wrapper. FrankenEngine's claim to be a category-shifting runtime requires that the GA default path is entirely native. The signed replacement lineage provides an auditable chain of custody showing exactly how each delegated slot was replaced, preventing silent regressions where a delegate sneaks back in. This gate feeds the `autonomy_delta` dimension of the disruption scorecard (bd-6pk).\n\nRelated 9I moonshots: Verified Self-Replacement, PLAS.\nRelated 9F moonshots: Verified Adaptive Compiler, Capability-Typed TS, Zero-Copy IPC.\n\n## Verification Requirements\n- **Delegate-cell census:** Enumerate all slots in the GA default lane configuration; confirm each is served by a native component with zero mandatory delegates.\n- **Lineage signature verification:** For each replacement lineage artifact, independently verify the signature using the published trust anchor.\n- **Behavioral equivalence confirmation:** For each replaced slot, confirm the shared conformance test suite passes for both the native replacement and the former delegate (with any documented exceptions).\n- **Hidden fallback scan:** Static analysis and runtime instrumentation confirm that no delegate code paths are reachable in the GA lane under normal operation.\n- **Scorecard integration:** Results feed `autonomy_delta` in the disruption scorecard (bd-6pk) -- specifically the \"fully native\" metric.\n- **Structured logging:** Lane configuration audit emits structured logs with fields: `trace_id`, `slot_id`, `component_type`, `is_native`, `delegate_fallback_reachable`, `lineage_hash`, `lineage_signature_valid`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate results feed `autonomy_delta` dimension.\n- bd-2n3 (PLAS gate) -- PLAS must be active for native slots that require capability grants.\n- bd-dkh (proof-specialized lanes gate) -- proof-specialized lanes build on fully native GA lanes.\n- 10.15 Delta Moonshots track -- delivers native replacements and lineage signing.\n- 10.2 Core Runtime track -- delivers native runtime implementations.\n- 10.7 Conformance + Verification track -- delivers behavioral equivalence test suites.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.575933913Z","created_by":"ubuntu","updated_at":"2026-02-20T07:58:54.313710442Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-18fu","title":"[11] Require hotspot and threat-evidence bundle per subsystem proposal","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: hotspot/threat evidence\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:16.065176532Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:27.773241118Z","closed_at":"2026-02-20T07:38:23.401865613Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"]}
{"id":"bd-18m","title":"[10.11] Implement lease-backed remote liveness tracking with explicit timeout/escalation paths.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement lease-backed remote liveness tracking with explicit timeout/escalation paths.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:36.549170870Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.944745454Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-1999","title":"[10.15] Make matrix+fault conformance lab pass a release blocker for shared-boundary changes, complementing the baseline compatibility gates in `10.14`.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Make matrix+fault conformance lab pass a release blocker for shared-boundary changes, complementing the baseline compatibility gates in `10.14`.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:49.471732515Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.479500121Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-19l0","title":"[14] Define normative Extension-Heavy Benchmark Suite v1.0 specification and workload matrix.","description":"## Plan Reference\nSection 14.1: Extension-Heavy Benchmark Suite v1.0 (Normative)\nSection 7.4-7.5: Benchmark Denominator Contract and Fairness Rules\nSection 9D: Extreme-Software-Optimization Enhancement Map\n\n## What\nDefine and publish the complete benchmark specification that will be used to validate the >= 3x throughput claim (a hard program success criterion from Section 3).\n\n## Suite Structure\nFive benchmark families, each REQUIRED:\n1. **boot-storm**: Extension cold-start and initialization under load\n2. **capability-churn**: Rapid capability grant/revoke cycles\n3. **mixed-cpu-io-agent-mesh**: Combined CPU and I/O workloads simulating agent mesh behavior\n4. **reload-revoke-churn**: Extension hot-reload and revocation under continuous traffic\n5. **adversarial-noise-under-load**: Normal workload with injected adversarial extension behavior\n\nEach family requires three scale profiles: S, M, L with fixed extension counts, event rates, dependency graph sizes, and policy complexity tiers.\n\n## Per-Case Publication Requirements\nEach benchmark case must publish: throughput, p50/p95/p99 latency, allocation/peak memory, correctness digest, and security-event envelope.\n\n## Behavior-Equivalence Requirements (Hard Gates)\n- Equivalent external outputs (canonical digest comparison)\n- Equivalent side-effect trace class (fs/network/process/policy actions normalized by contract schema)\n- Equivalent error-class semantics for negative/exceptional cases\n- No work dropping, relaxed durability, or disabled policy checks to inflate throughput\n\n## Scoring Formula (Binding)\nPrimary score is weighted geometric mean: score(engine, baseline) = exp(sum_i w_i * ln(throughput_engine_i / throughput_baseline_i)), with sum_i w_i = 1\nClaim acceptance requires BOTH: score vs Node >= 3.0 AND score vs Bun >= 3.0\n\n## Fairness Rules (Binding)\n- Baselines pinned to declared versions (Node LTS, Bun stable) with full CLI/env manifests\n- Identical hardware/OS envelopes, warmed/cold cache protocols, fixed dataset seeds\n- Report median + dispersion over repeated runs; publish raw per-run artifacts\n- Result ledgers stored via frankensqlite; operator consoles via frankentui\n- Every claim must include verifier scripts for third-party reruns\n\n## Required Metric Families\n1. Throughput/latency (p50, p95, p99) under extension-heavy workloads\n2. Containment quality (time-to-detect, time-to-contain, FP/FN envelopes)\n3. Replay correctness (determinism pass rate, artifact completeness)\n4. Revocation/quarantine propagation (freshness lag, convergence SLO attainment)\n5. Adversarial resilience (campaign success-rate suppression vs baselines)\n6. Information-flow security (unauthorized flow block rate, declassification envelopes)\n7. Security-proof specialization uplift (proof-specialized vs ambient-authority delta)\n\n## Testing Requirements\n- Unit tests for scoring formula implementation (golden test vectors for weighted geometric mean)\n- Unit tests for behavior-equivalence checker (known-equivalent and known-divergent cases)\n- Integration test running mini S-profile benchmark end-to-end\n- E2E test: full suite run produces valid result artifacts with all required fields\n\n## Rationale\nFrom Section 3: the >= 3x claim is the disruptive floor. From Section 14: FrankenEngine will define and own the reference benchmark standard. This bead defines the scoreboard that competitors must follow.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.\n\n## Scope Boundary\\nThis bead is the normative/publication gate for the benchmark specification and must consolidate outputs from implementation-focused benchmark beads (for example `bd-2ql`) rather than duplicating implementation scope.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:41:53.952557303Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.145719633Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["benchmark","detailed","performance","plan","section-10-6","section-14","specification"],"dependencies":[{"issue_id":"bd-19l0","depends_on_id":"bd-2ql","type":"blocks","created_at":"2026-02-20T07:56:08.972032676Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ad6","title":"[10.14] Define a `franken_engine` TUI adapter boundary for incident replay views, policy explanation cards, and control dashboards backed by `frankentui` components.","description":"## Plan Reference\nSection 10.14, item 2. Cross-refs: 10.15 (frankentui operator surfaces for PLAS, IFC, self-replacement, specialization), 10.13 (control-plane invariants dashboard).\n\n## What\nDefine the franken_engine TUI adapter boundary - a thin interface layer between FrankenEngine's runtime data and frankentui's rendering components. This boundary defines what data flows from engine to TUI and what interaction events flow back.\n\n## Detailed Requirements\n- Adapter boundary for incident replay views: feed replay trace data to frankentui timeline/event components\n- Adapter boundary for policy explanation cards: feed policy decision data to frankentui card/detail components\n- Adapter boundary for control dashboards: feed metrics, health, epoch status to frankentui dashboard components\n- Interface must be data-driven: engine produces structured data, TUI consumes and renders\n- No business logic in TUI layer: all decision-making stays in engine, TUI is pure presentation\n- Must support real-time updates (streaming metrics) and static views (incident replay)\n- Adapter types must be serializable for frankensqlite persistence and deterministic replay\n\n## Rationale\nA well-defined adapter boundary prevents tight coupling between engine internals and TUI rendering. This allows frankentui to evolve independently, enables testing of TUI data without rendering, and ensures deterministic data flow for replay. Section 10.15 defines many specific TUI surfaces (PLAS capability-delta reviews, IFC flow decisions, self-replacement dashboards) that all need to go through this boundary.\n\n## Testing Requirements\n- Unit tests: adapter produces correct structured data for each view type\n- Unit tests: adapter handles missing/partial data gracefully\n- Integration test: adapter data round-trips through serialization correctly\n- Integration test: frankentui components render adapter data without errors\n\n## Dependencies\n- Blocked by: frankentui ADR (bd-2l0x)\n- Blocks: all specific frankentui surfaces in 10.15, CI policy guard (bd-1qgn)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:44.898570137Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.680533884Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-1ai","title":"[10.10] Implement revocation freshness policy with explicit degraded-mode behavior and audit emission.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement revocation freshness policy with explicit degraded-mode behavior and audit emission.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:31.663094452Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.109576144Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1b2","title":"[10.10] Implement signature preimage contract using unsigned-view encoding and deterministic field ordering.","description":"## Plan Reference\nSection 10.10, item 4. Cross-refs: 9E.2 (Deterministic serialization and signature preimage contracts - \"a single unsigned-view signature preimage rule\"), Top-10 links #3, #7, #10.\n\n## What\nImplement the signature preimage contract that defines exactly which bytes are signed when producing or verifying a signature on any security-critical object. The contract uses unsigned-view encoding: the object is serialized in its canonical form with the signature field(s) zeroed or excluded, producing a deterministic preimage that is independent of the signature value itself. Field ordering in the preimage must be deterministic and defined by the schema.\n\n## Detailed Requirements\n- Define a `SignaturePreimage` trait that every signable security-critical object must implement\n- The `preimage_bytes(&self) -> Vec<u8>` method must produce the canonical serialization of the object with all signature fields set to a well-defined sentinel value (zero-length bytes or explicit null marker), not simply omitted\n- Field ordering in the preimage must match the deterministic serialization order (lexicographic key ordering from bd-2t3), with no exception\n- The preimage must include the schema-hash prefix (from bd-2t3) so that signatures are bound to the schema version\n- The preimage must include the EngineObjectId domain separation tag so that signatures are bound to the object class\n- Support both single-signature and multi-signature objects; for multi-sig objects, each signer signs the same preimage (the preimage is independent of other signatures)\n- Provide a `sign(object, signing_key) -> SignedObject` function that computes preimage, signs, and embeds the signature\n- Provide a `verify(signed_object, verification_key) -> Result<(), SignatureError>` function that recomputes preimage and verifies\n- Signature algorithm agility: support Ed25519 as the default, with trait abstraction for future algorithm additions\n- Reject any attempt to sign a non-canonical object (canonicality check before preimage computation)\n- Document the exact preimage construction with a formal specification and byte-level examples\n\n## Rationale\nFrom plan section 9E.2: \"a single unsigned-view signature preimage rule. Multi-signature vectors must be sorted by stable signer key ordering before verification. This gives language-agnostic signature reproducibility and shuts down malleability via field/order differences.\" Without a precisely defined preimage contract, different implementations may compute different bytes for the \"same\" object before signing, leading to verification failures or worse, signature-stripping attacks where valid signatures are transplanted between objects. The unsigned-view approach (zeroing signature fields rather than omitting them) preserves field count and ordering consistency, making the preimage construction purely mechanical and verifiable.\n\n## Testing Requirements\n- Unit tests: compute preimage for each signable object class, verify deterministic output\n- Unit tests: verify preimage excludes signature bytes (zeroed sentinel present, not raw signature)\n- Unit tests: verify preimage includes schema-hash prefix and domain separation tag\n- Unit tests: sign and verify round-trip for each object class with Ed25519\n- Unit tests: verify that modifying any non-signature field invalidates the signature\n- Unit tests: verify that two different signing keys on the same object produce different signatures but the same preimage\n- Unit tests: verify rejection of signing non-canonical objects\n- Unit tests: verify multi-signature preimage consistency (all signers get same preimage)\n- Cross-implementation tests: verify preimage bytes match across Rust and any reference implementation\n- Golden vector tests: publish preimage bytes and signatures for known test objects\n\n## Implementation Notes\n- The unsigned-view approach means the serialization format must have a fixed, known position or tag for signature fields; consider placing signatures in a dedicated envelope wrapper rather than inline\n- For efficiency, consider computing the preimage by serializing once and masking the signature region rather than re-serializing\n- The preimage contract is the security-critical path; it must be audited for correctness and must not be bypassable\n- Consider implementing `Signable` as a derive macro that auto-generates preimage computation from struct annotations\n- Wire signature operations into the audit chain (bd-1lp) for forensic traceability\n\n## Dependencies\n- Depends on: bd-2t3 (deterministic serialization for canonical byte output), bd-2y7 (EngineObjectId for domain separation in preimage), bd-3bc (canonicality rejection before signing)\n- Blocks: bd-3pl (multi-sig ordering builds on this preimage contract), bd-1c7 (PolicyCheckpoint signing), bd-28m (capability token signing), bd-1dp (key attestation signing), bd-26o (conformance suite tests signature verification)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:29.556632523Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.738538339Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1bi","title":"[10.10] Implement session-authenticated extension hostcall channel with per-message MAC.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement session-authenticated extension hostcall channel with per-message MAC.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:30.957371725Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.319877948Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1bl","title":"[10.11] Implement obligation-tracked channels for safety-critical two-phase internal protocols.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement obligation-tracked channels for safety-critical two-phase internal protocols.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:34.047346797Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.733044294Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-1blo","title":"[12] Counter heuristic-security false confidence with Bayesian + sequential testing + calibration audits","description":"Plan Reference: section 12 (Risk Register).\nObjective: False confidence from heuristic security:\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:17.760799368Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:28.145841240Z","closed_at":"2026-02-20T07:39:04.932159503Z","close_reason":"Consolidated into single risk register tracking bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-12"]}
{"id":"bd-1bzp","title":"[10.12] Define and publish category benchmark specification with reproducible harness and transparent scoring methodology.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Define and publish category benchmark specification with reproducible harness and transparent scoring methodology.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:41.181176444Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.847596961Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-1c7","title":"[10.10] Define `PolicyCheckpoint` object with `prev_checkpoint`, `checkpoint_seq`, `epoch_id`, policy heads, and quorum signatures.","description":"## Plan Reference\nSection 10.10, item 6. Cross-refs: 9E.3 (Checkpointed policy frontier with rollback/fork protection - \"Add a quorum-signed PolicyCheckpoint chain carrying monotonic checkpoint_seq and epoch metadata\"), Top-10 links #3, #5, #10.\n\n## What\nDefine the `PolicyCheckpoint` object structure, a quorum-signed chain element that anchors the canonical root of enforceable policy state. Each checkpoint contains a back-pointer to the previous checkpoint, a monotonically increasing sequence number, an epoch identifier, references to the current policy heads (active policy versions), and a quorum of signatures from authorized checkpoint signers.\n\n## Detailed Requirements\n- Define `PolicyCheckpoint` struct with fields: `checkpoint_id: EngineObjectId`, `prev_checkpoint: Option<EngineObjectId>` (None for genesis), `checkpoint_seq: u64` (strictly monotonic, starting from 0), `epoch_id: EpochId` (identifies the policy epoch/era), `policy_heads: Vec<PolicyHead>` (content-addressed references to active policy versions), `quorum_signatures: SortedSignatureArray`, `created_at: DeterministicTimestamp`\n- `PolicyHead` contains: `policy_type: PolicyType`, `policy_hash: ContentHash`, `policy_version: u64`\n- Genesis checkpoint: the first checkpoint in a chain has `prev_checkpoint = None`, `checkpoint_seq = 0`, and must be signed by the initial authority set\n- Chain integrity: each checkpoint must reference the immediately preceding checkpoint; gaps are forbidden\n- Monotonicity: `checkpoint_seq` must be strictly greater than the previous checkpoint's sequence; reject any checkpoint where `seq <= prev.seq`\n- Epoch transitions: `epoch_id` changes indicate a policy era boundary (e.g., key rotation, authority set change); epoch transitions must be explicitly documented in the checkpoint metadata\n- Quorum: the signature array must contain at least `quorum_threshold` valid signatures from the authorized signer set for the current epoch\n- Serialization: use the deterministic serialization module (bd-2t3) with schema-hash prefix\n- ID derivation: use EngineObjectId derivation (bd-2y7) for `checkpoint_id`\n- Signing: use the signature preimage contract (bd-1b2) with multi-sig ordering (bd-3pl)\n- The checkpoint object must be immutable after creation and signing\n\n## Rationale\nFrom plan section 9E.3: \"Add a quorum-signed PolicyCheckpoint chain carrying monotonic checkpoint_seq and epoch metadata, persisted as the canonical root of enforceable policy state.\" The checkpoint chain provides a tamper-evident, rollback-resistant foundation for policy state. By requiring quorum signatures, no single compromised key can forge policy state. The monotonic sequence number ensures that old checkpoints cannot be replayed, and the chain linkage ensures that the full policy history is auditable. This is analogous to blockchain block headers but purpose-built for policy governance.\n\n## Testing Requirements\n- Unit tests: create genesis checkpoint, verify all fields and ID derivation\n- Unit tests: create checkpoint chain (genesis -> cp1 -> cp2), verify chain linkage\n- Unit tests: verify monotonicity rejection (seq must be strictly increasing)\n- Unit tests: verify quorum threshold enforcement (reject insufficient signatures)\n- Unit tests: verify rejection of invalid back-pointer (wrong prev_checkpoint)\n- Unit tests: verify epoch transition handling\n- Unit tests: verify serialization round-trip preserves all fields\n- Unit tests: verify EngineObjectId derivation matches expected golden vectors\n- Integration tests: multi-party checkpoint creation workflow (multiple signers contribute signatures)\n- Integration tests: checkpoint chain persistence and retrieval from storage\n- Fuzz tests: random checkpoint field mutations should be caught by verification\n\n## Implementation Notes\n- The `PolicyCheckpoint` is a core security object; its implementation should be minimal and auditable\n- Consider implementing checkpoint creation as a builder pattern: `CheckpointBuilder::new(prev).add_policy_head(...).sign(key).build()`\n- The quorum verification should check signatures against the authorized signer set defined in the *previous* checkpoint (or genesis config for the first checkpoint)\n- Epoch transitions may change the authorized signer set; the transition checkpoint must be signed by the *old* authority set\n- Store checkpoint chain in an append-only structure; never allow mutation of existing checkpoints\n\n## Dependencies\n- Depends on: bd-2y7 (EngineObjectId for checkpoint_id), bd-2t3 (deterministic serialization), bd-1b2 (signature preimage contract), bd-3pl (sorted multi-signature arrays)\n- Blocks: bd-lpl (checkpoint frontier persistence), bd-1fx (fork detection), bd-28m (capability tokens bind to checkpoint), bd-26o (conformance suite tests checkpoint chain)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:29.838779423Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.653301183Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1coe","title":"[10.14] Add benchmark gates confirming sibling-repo integrations do not regress critical p95/p99 control-plane SLOs.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Add benchmark gates confirming sibling-repo integrations do not regress critical p95/p99 control-plane SLOs.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:46.678758372Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.220314745Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-1cu","title":"[10.0] Top-10 #6: Shadow-run + differential executor onboarding mode (strategy: `9A.6`; deep semantics: `9F.6`; execution owners: `10.7`, `10.12`).","description":"## Plan Reference\nSection 10.0 item 6. Strategy: 9A.6. Deep semantics: 9F.6 (Tri-Runtime Lockstep Oracle). Enhancement maps: 9B.6 (progressive delivery, deterministic simulation), 9C.6 (formal hypothesis test for shadow promotion), 9D.6 (shadow overhead SLO profiling).\n\n## What\nStrategic tracking bead for Initiative #6: Shadow-run + differential executor for safe extension onboarding. New extensions run in observe-only shadow mode before gaining active privileges.\n\n## Execution Owners\n- **10.7** (Conformance + Verification): differential lockstep suite, native-vs-delegate differential gate\n- **10.12** (Frontier Programs): causal replay, deterministic convergence, continuous adversarial campaigns\n\n## Strategic Rationale (from 9A.6)\n'Creates a low-risk adoption wedge that catches subtle abuse or breakage before production impact.'\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:19.897460064Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.121303841Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-1ddd","title":"[10.12] Build operator safety copilot surfaces with recommended actions, confidence bands, and deterministic rollback commands.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Build operator safety copilot surfaces with recommended actions, confidence bands, and deterministic rollback commands.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:41.025696575Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.890145293Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-1dp","title":"[10.10] Implement owner-signed key attestation objects with expiry and nonce freshness requirements.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement owner-signed key attestation objects with expiry and nonce freshness requirements.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:30.678161144Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.402399516Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1dxl","title":"[14] Containment quality (time-to-detect, time-to-contain, false-positive/false-negative envelopes).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Containment quality (time-to-detect, time-to-contain, false-positive/false-negative envelopes).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:33.082574256Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:28.476923962Z","closed_at":"2026-02-20T07:41:19.674683569Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-1edh","title":"[10.14] Add conformance tests proving deterministic replay/index behavior across `frankensqlite`-backed stores.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Add conformance tests proving deterministic replay/index behavior across `frankensqlite`-backed stores.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:46.025767468Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.391624222Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-1elf","title":"[13] 100% of activated proof-specializations carry signed receipts linking security-proof inputs to transformation and rollback artifacts","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: 100% of activated proof-specializations carry signed receipts linking security-proof inputs to transformation and rollback artifacts\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:26.875627360Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:28.573816313Z","closed_at":"2026-02-20T07:39:57.393735513Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1f45","title":"[13] at least 3 beyond-parity capabilities are in production with operator-facing evidence and documentation","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: at least 3 beyond-parity capabilities are in production with operator-facing evidence and documentation\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:22.599223591Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:28.620211488Z","closed_at":"2026-02-20T07:39:59.286557726Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1fa","title":"[10.0] Top-10 #8: Deterministic per-extension resource budget subsystem (strategy: `9A.8`; deep semantics: `9F.10`; execution owners: `10.11`, `10.12`, `10.13`).","description":"## Plan Reference\nSection 10.0 item 8. Strategy: 9A.8. Deep semantics: 9F.10 (SLO-Proven Scheduler). Enhancement maps: 9B.8 (expected-loss, OCO, BOCPD), 9C.8 (sequential decision process, Bayesian demand estimation), 9D.8 (enforcement overhead profiling).\n\n## What\nStrategic tracking bead for Initiative #8: Deterministic per-extension resource budgets with explicit exhaustion semantics. CPU/memory/IO/hostcall budgets enforced per extension.\n\n## Execution Owners\n- **10.11** (Runtime Systems): scheduler lanes, bulkheads, supervision tree\n- **10.12** (Frontier Programs): trust-economics model, runtime decision scoring\n- **10.13** (Asupersync Integration): Cx threading, obligation tracking\n\n## Strategic Rationale (from 9A.8)\n'Prevents noisy-neighbor failures and denial-of-service amplification from malicious or buggy extensions.'\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:20.147994640Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.021980468Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-1fm","title":"[10.2] Define IFC flow-lattice semantics (`label classes`, `clearance classes`, `declassification obligations`) in `IR2`.","description":"## Plan Reference\nSection 10.2, item 4. Cross-refs: 9I.7 (Runtime IFC + Deterministic Exfiltration Prevention), 9F.4 (Capability-Typed TS Execution), 10.15 (IFC artifacts and flow-label inference).\n\n## What\nDefine Information Flow Control (IFC) flow-lattice semantics within IR2 (CapabilityIR). This enables the runtime to constrain how data moves between sensitive sources and external sinks, blocking exfiltration by construction.\n\n## Detailed Requirements\n- Define label classes: categories of sensitive data (credentials, config secrets, key material, privileged environment state, policy-protected host artifacts)\n- Define clearance classes: authorized data destinations (network egress, subprocess/IPC, export/persistence channels)\n- Define declassification obligations: explicit paths for authorized cross-label data flow\n- Flow lattice must be composable: labels combine via join/meet operations\n- Labels must be representable in IR2 nodes alongside capability annotations\n- Flow-lattice semantics must support both static analysis (compile-time) and dynamic enforcement (runtime)\n- Must integrate with PLAS (9I.5) for automatic flow envelope synthesis\n\n## Rationale\nSection 9I.7 states: 'Capability gating alone cannot express source-to-sink data constraints. IFC closes this structural gap and enables a stronger category claim: deterministic exfiltration resistance with machine-verifiable provenance.' This is a category-defining feature: extensions that legitimately need both fs.read and net.connect can still be prevented from exfiltrating sensitive data unless an explicitly audited declassification path exists.\n\n## Testing Requirements\n- Unit tests: label join/meet operations produce correct lattice results\n- Unit tests: verify label assignment to IR2 nodes\n- Unit tests: verify declassification obligation representation\n- Property tests: lattice operations satisfy algebraic properties (associativity, commutativity, idempotency)\n- Conformance: IFC corpus tests from Section 10.7 (dual-capability benign, exfil-attempt, declassification-exception workloads)\n\n## Implementation Notes\n- Define label types as enum with lattice trait implementation\n- Labels attach to IR2 nodes as metadata, not as separate pass\n- Clearance checks are defined here but enforced in the flow-check pass (bd-3jg) and at runtime (10.5)\n- Must be extensible for new label categories without breaking existing flows\n\n## Dependencies\n- Blocked by: IR contract (bd-1wa) for IR2 type design\n- Blocks: flow-check pass (bd-3jg), PLAS flow envelope synthesis (10.15), runtime flow-label propagation (10.5)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.803200833Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.577585574Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-1fu7","title":"[10.15] Implement portfolio governor scoring engine and stage-gate automation for moonshot lifecycle transitions.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement portfolio governor scoring engine and stage-gate automation for moonshot lifecycle transitions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:48.484503060Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.736107045Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1fx","title":"[10.10] Implement same-sequence divergent-checkpoint fork detection and incident pathway.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement same-sequence divergent-checkpoint fork detection and incident pathway.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:30.116455726Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.569001734Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1g5c","title":"[10.15] Add slot-level promotion gate runner (equivalence, capability-preservation, performance threshold, adversarial survival) with deterministic pass/fail artifact bundles.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add slot-level promotion gate runner (equivalence, capability-preservation, performance threshold, adversarial survival) with deterministic pass/fail artifact bundles.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:54.232937676Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.047890440Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1gcu","title":"[10.15] Add deterministic fallback policy: when attestation validation fails or expires, high-impact autonomous actions degrade to conservative safe mode.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add deterministic fallback policy: when attestation validation fails or expires, high-impact autonomous actions degrade to conservative safe mode.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:47.492074612Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.003005058Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1h7n","title":"[13] franken_node composes those lanes for practical runtime usage","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: franken_node composes those lanes for practical runtime usage\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:19.216302677Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:28.977606059Z","closed_at":"2026-02-20T07:40:00.916776963Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1hh4","title":"[10.15] Add frankensqlite-backed provenance index supporting deterministic source-to-sink lineage queries and replay joins.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankensqlite-backed provenance index supporting deterministic source-to-sink lineage queries and replay joins.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:53.723022386Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.187482488Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1hu","title":"[10.5] Port extension lifecycle manager into compile-active modules.","description":"## Plan Reference\nSection 10.5, item 2 (Port extension lifecycle manager into compile-active modules). Cross-refs: 9A.8 (resource budgets per extension), 9G.2 (cancellation as protocol, not afterthought), 9A.1 (capability-typed execution model).\n\n## What\nImplement a deterministic extension lifecycle state machine that governs every extension from load through termination. The lifecycle states are: `Unloaded -> Validating -> Loading -> Starting -> Running -> Suspending -> Suspended -> Resuming -> Terminating -> Terminated -> Quarantined`. Each transition is guarded by explicit preconditions (validated manifest, resource budget allocated, capability set confirmed). The lifecycle manager is a compile-active module, meaning its state machine transitions and guard predicates are expressed in the type system where possible, preventing invalid transitions at compile time.\n\n## Detailed Requirements\n- Define `ExtensionState` enum with all lifecycle states listed above.\n- Define `LifecycleTransition` enum representing valid transitions (e.g., `Start`, `Suspend`, `Resume`, `Terminate`, `Quarantine`).\n- Implement `ExtensionLifecycleManager` struct that holds current state, validated manifest reference, resource budget handle, and a transition log.\n- Each transition method must: (a) verify precondition (current state allows transition), (b) execute transition logic, (c) emit structured lifecycle event to telemetry, (d) update state atomically.\n- Invalid transitions must return `LifecycleError` with deterministic error messages including `extension_id`, `current_state`, `attempted_transition`.\n- Implement cancellation protocol per 9G.2: `Terminate` must be a cooperative protocol with a timeout fallback to forced termination. The extension gets a `cancel_token` and has a configurable grace period (default 5s, max 30s) before forced kill.\n- Resource budget enforcement per 9A.8: each lifecycle transition checks remaining budget (CPU time, memory, hostcall count). Budget exhaustion triggers automatic `Suspend` or `Terminate` depending on policy.\n- The lifecycle manager must be `Send + Sync` for use across async task boundaries.\n- All state transitions must be logged with monotonic timestamps for replay.\n\n## Rationale\nExtensions are untrusted code running inside the engine. Without a rigorous lifecycle manager, extensions could enter inconsistent states, leak resources, or evade termination. The compile-active approach ensures that the type system prevents coding errors in lifecycle management itself. The cancellation protocol (9G.2) ensures that termination is never silent or abrupt without giving the extension a chance to clean up, while the timeout fallback ensures the runtime cannot be held hostage.\n\n## Testing Requirements\n- **Unit tests**: Test every valid state transition. Test every invalid transition is rejected with correct error. Test cancellation with cooperative shutdown. Test cancellation with timeout-forced shutdown. Test budget exhaustion triggers correct containment.\n- **State machine exhaustiveness**: Property test that from every reachable state, only documented transitions are possible.\n- **Integration tests**: Full lifecycle of a mock extension: load -> validate -> start -> run -> suspend -> resume -> terminate. Verify telemetry events emitted at each transition.\n- **Concurrency tests**: Multiple extensions running concurrently with independent lifecycle managers, verifying no cross-contamination.\n- **Determinism tests**: Replay a recorded transition sequence and verify identical state sequence and telemetry output.\n\n## Implementation Notes\n- Consider using a typestate pattern in Rust (`ExtensionLifecycle<Running>`, `ExtensionLifecycle<Suspended>`) for compile-time transition safety, with a dynamic fallback for runtime-driven transitions.\n- The transition log should be an append-only `Vec<LifecycleEvent>` with each event containing `(monotonic_timestamp, from_state, to_state, trigger, decision_id)`.\n- Integrate with the telemetry recorder (bd-5pk) for structured event emission.\n- Resource budget handles should be opaque tokens obtained from the resource subsystem (10.4 module surface).\n\n## Dependencies\n- **Blocked by**: bd-xq7 (manifest validation - lifecycle manager requires a validated manifest to proceed past `Validating` state).\n- **Blocks**: bd-5pk (telemetry needs lifecycle events), bd-2gl (containment actions are lifecycle transitions), bd-375 (delegate cells use the same lifecycle manager).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.021147784Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.850346957Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-1hw","title":"[10.5] Implement runtime flow-label propagation at dynamic hostcall boundaries and enforce sink-clearance checks.","description":"## Plan Reference\nSection 10.5, item 9 (Implement runtime flow-label propagation at dynamic hostcall boundaries). Cross-refs: 9I.7 (IFC + Deterministic Exfiltration Prevention), 10.2 (IFC flow-lattice in VM core), 9A.7 (capability lattice integrates with flow labels).\n\n## What\nImplement Information Flow Control (IFC) enforcement at runtime hostcall boundaries for dynamic paths that could not be verified statically. Every value crossing a hostcall boundary carries a flow label indicating its secrecy and integrity classification. The runtime propagation layer checks that the flow label of data being sent to a sink (e.g., network egress, file write, IPC channel) is compatible with the sink's clearance level. If the flow label exceeds the sink's clearance, the hostcall is blocked and the violation is recorded as evidence for the Guardplane. This is the runtime complement to the static IFC analysis in 10.2.\n\n## Detailed Requirements\n- Define `FlowLabel` struct: `{ secrecy: SecrecyLevel, integrity: IntegrityLevel }` where `SecrecyLevel` and `IntegrityLevel` are elements of a configurable lattice (partial order).\n- Define `SecrecyLevel` enum with at least: `Public`, `Internal`, `Confidential`, `Secret`, `TopSecret` (configurable/extensible).\n- Define `IntegrityLevel` enum with at least: `Untrusted`, `Validated`, `Verified`, `Trusted` (configurable/extensible).\n- Implement `FlowLabelLattice` that defines the partial order: `can_flow(from: &FlowLabel, to: &FlowLabel) -> bool` returns true iff `from.secrecy <= to.secrecy` AND `from.integrity >= to.integrity` (standard Bell-LaPadula + Biba).\n- Implement `SinkClearance` struct: `{ max_secrecy: SecrecyLevel, min_integrity: IntegrityLevel }` defining what data a sink is authorized to receive.\n- Implement runtime flow-label propagation at hostcall dispatch:\n  - Every hostcall argument carries a `FlowLabel` (attached via a `Labeled<T>` wrapper or context parameter).\n  - Before executing a sink-type hostcall (FsWrite, NetworkSend, IpcSend), the dispatcher checks `can_flow(argument_label, sink_clearance)`.\n  - If the check fails: block the hostcall, return `HostcallResult::Denied { reason: FlowViolation }`, emit a `FlowViolationEvent` to telemetry, and provide the violation as evidence to the Guardplane.\n  - If the check passes: execute the hostcall normally, propagate the label to the output.\n- Label join semantics for operations that combine multiple labeled values: `join(a, b) = FlowLabel { secrecy: max(a.secrecy, b.secrecy), integrity: min(a.integrity, b.integrity) }`.\n- Flow labels must be immutable once assigned (no downgrading without explicit declassification through bd-3jy).\n- Labels must be propagated through IPC channels: when an extension sends data to another extension via IPC, the receiving extension inherits the label.\n- Performance: flow-label checking must add < 500ns overhead per hostcall.\n\n## Rationale\nStatic IFC analysis (10.2) can verify many flow constraints at compile time, but dynamic hostcall paths -- especially those involving runtime-computed capabilities, user-provided data, or IPC between extensions -- cannot be fully analyzed statically. Runtime flow-label propagation closes this gap by enforcing IFC invariants at every hostcall boundary. Per 9I.7, the engine must prevent deterministic exfiltration: a compromised extension must not be able to send secret data to an unauthorized sink. The runtime layer is the last line of defense before data actually leaves the extension boundary.\n\n## Testing Requirements\n- **Unit tests**: `can_flow` with all lattice level combinations (authorized and unauthorized). Label join produces correct result. `Labeled<T>` wrapper preserves the label through operations.\n- **Hostcall dispatch tests**: A hostcall with a `Secret`-labeled argument to a `Public`-clearance network sink is blocked. A hostcall with a `Public`-labeled argument to a `Secret`-clearance sink is allowed. Verify telemetry records the violation/pass.\n- **IPC propagation tests**: Extension A sends `Confidential` data to Extension B via IPC; Extension B's subsequent hostcalls carry the `Confidential` label. Extension B attempts to send that data to a `Public` sink; verify it is blocked.\n- **Performance tests**: Benchmark flow-label checking overhead; assert < 500ns per hostcall.\n- **Integration tests**: Full pipeline: extension makes hostcalls with various labels, some pass, some are blocked. Verify Guardplane receives flow violations as evidence and adjusts posterior accordingly.\n- **Edge case tests**: Default label for unlabeled data (should be maximally restrictive: `TopSecret`/`Untrusted`). Label for system-generated data (should be `Public`/`Trusted`).\n\n## Implementation Notes\n- The `Labeled<T>` wrapper should be zero-cost when the label is statically known (use generics with const labels where possible).\n- Flow-label checking is a simple comparison in the partial order; implement as integer comparison on the ordinal values for performance.\n- The lattice configuration should be loadable from a policy file to support custom secrecy/integrity levels per deployment.\n- Integration point: the telemetry recorder (bd-5pk) already has a `flow_label` field in `HostcallTelemetryRecord`; this bead populates that field.\n- The IPC label propagation requires cooperation with the IPC subsystem (10.4 module surface); define a trait interface that the IPC layer implements.\n\n## Dependencies\n- **Blocked by**: bd-5pk (telemetry records flow violations), 10.2 (IFC flow-lattice defines the lattice structure; this bead uses it at runtime).\n- **Blocks**: bd-3jy (declassification is the controlled way to change flow labels), bd-375 (delegate cells must have flow-label enforcement).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.948569696Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.519124401Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-1i2","title":"[10.11] Define canonical runtime capability profiles (`FullCaps`, `EngineCoreCaps`, `PolicyCaps`, `RemoteCaps`, `ComputeOnlyCaps`) and enforce them at API boundaries.","description":"## Plan Reference\n- **Section**: 10.11 item 1 (FrankenSQLite-Inspired Runtime Systems Track)\n- **9G Cross-ref**: 9G.1 — Capability-context-first runtime (Cx threading)\n- **Top-10 Links**: #2 (Probabilistic Guardplane), #7 (Capability lattice + typed policy DSL), #8 (Per-extension resource budget)\n\n## What\nDefine canonical runtime capability profiles (`FullCaps`, `EngineCoreCaps`, `PolicyCaps`, `RemoteCaps`, `ComputeOnlyCaps`) as concrete Rust types and enforce them at every API boundary in the engine and extension-host crates. These profiles partition the full authority universe into narrow, composable subsets so that each subsystem receives only the capabilities it needs.\n\n## Detailed Requirements\n1. Define a `Capability` trait hierarchy and five canonical profile structs:\n   - `FullCaps`: union of all capabilities; only available to top-level orchestrator and test harness.\n   - `EngineCoreCaps`: VM dispatch, GC, IR lowering — no network, no policy mutation, no extension lifecycle.\n   - `PolicyCaps`: policy read/write, evidence emission, decision-contract invocation — no direct VM dispatch, no raw network.\n   - `RemoteCaps`: network egress, lease management, idempotency-key derivation — no policy mutation, no direct VM execution.\n   - `ComputeOnlyCaps`: pure computation with zero side effects — no I/O, no network, no policy, no evidence emission.\n2. Each profile must be a zero-cost compile-time marker where possible (generic bounds, sealed traits); runtime checks are fallback-only for dynamic dispatch paths.\n3. API boundaries (public trait methods, hostcall entry points, scheduler task constructors) must declare their required capability profile as a generic bound or explicit parameter.\n4. Attempting to invoke an operation without the required profile must fail at compile time where statically checkable, or return a typed `CapabilityDenied` error at runtime.\n5. Profile composition rules: profiles may be intersected (narrowing) but never unioned outside `FullCaps`; widening requires explicit `escalation_receipt` evidence artifact.\n6. Integration with `Cx`: capability profiles must be threaded through or embedded within the `Cx` context object so that control-plane and data-plane boundaries carry authority evidence.\n7. Serialization: each profile must have a canonical deterministic serialization for inclusion in evidence-ledger entries and replay artifacts.\n\n## Rationale\nThis is the foundational authority-control primitive for the entire runtime. Without typed capability profiles enforced at API boundaries, ambient authority leaks silently and the security doctrine (Section 6) cannot be upheld. By making authority a type-system property (9G.1), the engine structurally prevents privilege escalation and enables downstream proof-carrying specialization (Section 8.9) where tighter envelopes yield faster code paths.\n\n## Testing Requirements\n- **Unit tests**: Verify each profile grants exactly the expected capability set. Verify compile-time rejection of mismatched profiles (via `trybuild` or equivalent negative-compilation tests). Verify `CapabilityDenied` error on runtime dynamic-dispatch paths.\n- **Property tests**: Fuzz profile intersection/composition to confirm monotonic narrowing and that no composition produces capabilities outside the declared union.\n- **Integration tests**: End-to-end scenario where an extension-host task attempts operations requiring `RemoteCaps` while holding only `ComputeOnlyCaps`; verify denial, structured error, and evidence emission.\n- **Logging/observability**: All capability checks must emit structured log events with fields: `trace_id`, `component`, `required_profile`, `held_profile`, `outcome` (granted/denied), `error_code`.\n- **Reproducibility**: Profile definitions must be snapshot-stable across builds; canonical serialization must produce identical bytes for identical profiles.\n\n## Implementation Notes\n- Crate location: `crates/franken-engine` (profile definitions) + `crates/franken-extension-host` (enforcement at hostcall boundaries).\n- Use Rust sealed-trait pattern to prevent external implementations of capability profiles.\n- Consider `typestate` pattern for zero-cost compile-time enforcement on hot paths.\n- Coordinate with `Cx` type from `franken-kernel` (10.13 integration); profiles should embed into `Cx` without coupling VM hot loops to control-plane internals (Section 8.4.4 anti-coupling constraint).\n- Heavy compilation workloads should use `rch`-wrapped commands per project convention.\n\n## Dependencies\n- Depends on: `franken-kernel` `Cx` type definition (10.13 provides integration; this bead defines the primitive profiles).\n- Blocks: bd-1za (compile-time audit gate), bd-hli (remote capability gating), bd-2ao (region-quiescence close), and all downstream beads that reference capability profiles.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:33.274990242Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.966800916Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-1if","title":"[10.11] Implement saga orchestrator for multi-step publish/evict/quarantine workflows with deterministic compensation.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement saga orchestrator for multi-step publish/evict/quarantine workflows with deterministic compensation.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:36.695088308Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.898566019Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-1ilz","title":"[10.15] Add frankensqlite-backed lineage/evidence index for replacement receipts and deterministic replay joins.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankensqlite-backed lineage/evidence index for replacement receipts and deterministic replay joins.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:54.922121006Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.850914877Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1jak","title":"[15] Ecosystem Capture Strategy - Comprehensive Execution Epic","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nPurpose: Operationalize this section's governance/validation/adoption requirements into enforceable engineering work.\nQuality requirements for all children:\n- explicit acceptance criteria and failure semantics\n- unit-test and e2e/integration verification expectations\n- detailed structured logging and reproducibility artifacts where applicable\n- traceability back to category-level goals (security, performance, explainability, adoption)\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:34:15.651360044Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:10.708962979Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-15"],"dependencies":[{"issue_id":"bd-1jak","depends_on_id":"bd-1tsf","type":"blocks","created_at":"2026-02-20T07:34:38.106582763Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-1wqa","type":"parent-child","created_at":"2026-02-20T07:52:46.028067023Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-21ds","type":"blocks","created_at":"2026-02-20T07:34:38.692410684Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-2r0c","type":"parent-child","created_at":"2026-02-20T07:52:49.152308098Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-2wft","type":"parent-child","created_at":"2026-02-20T07:52:50.025196896Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-2x4b","type":"parent-child","created_at":"2026-02-20T07:52:50.144785140Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-395m","type":"blocks","created_at":"2026-02-20T07:34:38.595172120Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-3bz4","type":"parent-child","created_at":"2026-02-20T07:53:36.269330804Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-3j5s","type":"parent-child","created_at":"2026-02-20T07:52:52.479836766Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-3qhv","type":"parent-child","created_at":"2026-02-20T07:52:53.420387481Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-iqrn","type":"parent-child","created_at":"2026-02-20T07:52:55.859741531Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jak","depends_on_id":"bd-mrf8","type":"parent-child","created_at":"2026-02-20T07:52:56.223008560Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1jqt","title":"[10.15] Add frankentui operator surfaces for proof-specialization lineage (`proof ids`, `activated specializations`, `invalidations`, `fallback events`).","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankentui operator surfaces for proof-specialization lineage (`proof ids`, `activated specializations`, `invalidations`, `fallback events`).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:53.209298162Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.329416629Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1k5f","title":"[13] proof-carrying optimization path is enabled by default for at least one high-impact optimization family","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: proof-carrying optimization path is enabled by default for at least one high-impact optimization family\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:23.232379459Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:29.490629983Z","closed_at":"2026-02-20T07:39:58.984722894Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1k7","title":"[10.2] Implement closure and lexical scope model.","description":"## Plan Reference\nSection 10.2, item 11. Cross-refs: 9I.7 (IFC flow-label propagation through scope chains), 9F.4 (Capability-Typed TS Execution), Phase A exit gate.\n\n## What\nImplement the closure and lexical scope model for ES2020, including lexical scoping, closures, block scope (let/const), hoisting, the scope chain, and the interaction between scope semantics and IFC flow analysis.\n\n## Detailed Requirements\n- Lexical scoping: function scope, block scope (let/const/class), global scope, module scope\n- Closures: functions capture their enclosing lexical environment by reference; captured variables remain live as long as the closure exists\n- Block scoping: let and const declarations are block-scoped with temporal dead zone (TDZ) enforcement\n- Hoisting: var declarations hoisted to function scope, function declarations hoisted to function scope with initialization, let/const/class enter TDZ\n- Scope chain: variable lookup traverses enclosing scopes in lexical order\n- with statement: creates a dynamic scope entry (rare but must be supported for full ES2020)\n- eval: direct eval runs in the calling scope, indirect eval runs in global scope\n- arguments object: mapped arguments for sloppy-mode functions, unmapped for strict mode\n- IFC integration: scope chain traversal must propagate IFC flow labels - when a closure captures a variable labeled with a sensitivity class, the label flows with the captured reference (per 9I.7)\n\n## Rationale\nClosures and lexical scope are foundational to JavaScript semantics. Nearly every non-trivial extension uses closures. Block scoping with TDZ is critical for correctness with modern JS patterns (let/const). The IFC connection is architecturally important: data sensitivity labels must flow through scope chains. If a closure captures a variable carrying a 'credentials' label, any function that invokes that closure and reads the captured value must inherit the label. Without this, IFC flow analysis has a scope-chain-shaped hole that attackers could exploit.\n\n## Testing Requirements\n- Unit tests: lexical scoping - variable shadowing across nested functions\n- Unit tests: closure captures - verify captured variables reflect mutations in enclosing scope\n- Unit tests: block scope - let/const TDZ throws ReferenceError before declaration\n- Unit tests: hoisting - var vs let/const vs function declaration behavior\n- Unit tests: scope chain traversal across multiple nesting levels\n- Unit tests: eval in direct and indirect modes\n- Unit tests: arguments object (mapped vs unmapped)\n- Unit tests: IFC label propagation through closure captures\n- Conformance: test262 language/statements/let, language/statements/const, language/expressions/function, language/statements/with\n- Edge cases: closure over loop variables (let in for-loop), mutual recursion through closures, deeply nested closures\n\n## Implementation Notes\n- Environment records should be arena-allocated (per 9B.1 recommendation)\n- Consider environment record types: declarative, object (for with), function, global, module\n- Closure representation: function code reference + captured environment chain\n- TDZ enforcement: mark bindings as uninitialized until declaration is evaluated\n- IFC label propagation: environment records carry label metadata that joins on capture\n\n## Dependencies\n- Blocked by: baseline interpreter skeleton (bd-2f8), ES2020 object semantics (bd-1m9) for scope objects\n- Blocks: Phase A exit gate conformance, IFC flow-check accuracy (bd-3jg) for scope-aware flow analysis\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:22.711931209Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.290540405Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-1kd2","title":"[13] control-plane identifiers and capability context are canonicalized through asupersync-derived types (no competing local forks)","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: control-plane identifiers and capability context are canonicalized through asupersync-derived types (no competing local forks)\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:21.084427599Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:29.576623233Z","closed_at":"2026-02-20T07:40:00.000271547Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1kdc","title":"[10.15] Implement deterministic shadow ablation engine that tests capability subtraction candidates against correctness and risk invariants.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement deterministic shadow ablation engine that tests capability subtraction candidates against correctness and risk invariants.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:50.135558141Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.320114133Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1ko5","title":"[13] 100% of capability escrow/emergency-grant decisions emit receipt-linked replay artifacts with explicit expiry and operator rationale","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: 100% of capability escrow/emergency-grant decisions emit receipt-linked replay artifacts with explicit expiry and operator rationale\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:25.695732732Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:29.658806728Z","closed_at":"2026-02-20T07:39:57.888748945Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1kzo","title":"[10.15] Add compiler policy that only proof-grounded specializations may bypass capability/flow dynamic checks in marked regions.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add compiler policy that only proof-grounded specializations may bypass capability/flow dynamic checks in marked regions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:53.032092674Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.377108111Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1lp","title":"[10.10] Implement append-only hash-linked audit chain with `correlation_id` and optional full trace context.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement append-only hash-linked audit chain with `correlation_id` and optional full trace context.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:32.404729302Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.900964106Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1m9","title":"[10.2] Implement complete ES2020 object/prototype semantics (no permanent subset scope).","description":"## Plan Reference\nSection 10.2, item 10. Cross-refs: 9A.1 (TS-first authoring with native execution), 9F.4 (Capability-Typed TS Execution Contract), Phase A exit gate (native execution lanes pass baseline conformance), Section 2 (no permanent subset scope).\n\n## What\nImplement complete ES2020 object and prototype semantics including the full object model with prototypes, property descriptors, Proxy, Reflect, and all associated internal methods. The plan explicitly requires 'no permanent subset scope' - every ES2020 object-model feature must be implemented, not approximated.\n\n## Detailed Requirements\n- Full prototype chain: Object.create, Object.getPrototypeOf, Object.setPrototypeOf, prototype-based inheritance\n- Property descriptors: Object.defineProperty, Object.defineProperties, Object.getOwnPropertyDescriptor, accessor properties (get/set), configurable/enumerable/writable attributes\n- Proxy and Reflect: all 13 Proxy trap handlers (get, set, has, deleteProperty, ownKeys, apply, construct, getPrototypeOf, setPrototypeOf, isExtensible, preventExtensions, defineProperty, getOwnPropertyDescriptor) with full invariant checking per ES2020 spec\n- Internal methods: [[Get]], [[Set]], [[HasProperty]], [[Delete]], [[OwnPropertyKeys]], [[Call]], [[Construct]] with correct ordinary and exotic object behavior\n- Object.keys, Object.values, Object.entries, Object.assign, Object.freeze, Object.seal, Object.is\n- Symbol-keyed properties and well-known symbols (Symbol.iterator, Symbol.toPrimitive, Symbol.hasInstance, etc.)\n- for...in enumeration order per ES2020 spec\n- No permanent subset scope: every feature must be implemented or explicitly tracked as in-progress with a convergence date, never silently omitted\n\n## Rationale\nThe plan (Section 2) states there is 'no permanent subset scope' for ES2020 semantics. This is a hard requirement because extensions in the VS Code ecosystem depend on the full ES2020 object model. Proxy and Reflect are particularly critical because many popular extension frameworks (Vue, MobX) use them extensively. Incomplete object semantics would cause silent behavioral divergence that is extremely difficult to diagnose and would undermine trust in the runtime. The Phase A exit gate requires baseline conformance, which means full object semantics must be correct before any optimization work begins.\n\n## Testing Requirements\n- Unit tests: prototype chain traversal, property lookup, property descriptor operations\n- Unit tests: Proxy trap invocation for all 13 handlers with correct argument passing\n- Unit tests: Proxy invariant checking (e.g., non-configurable property cannot be reported as non-existent)\n- Unit tests: Reflect methods mirror corresponding Object operations\n- Unit tests: Symbol-keyed property access and well-known symbol behavior\n- Conformance: test262 built-ins/Object, built-ins/Proxy, built-ins/Reflect, built-ins/Symbol test suites\n- Edge cases: Proxy wrapping Proxy, revocable Proxy, frozen objects through Proxy, exotic objects (arrays, strings, arguments)\n- Determinism: object operations produce identical results across both execution lanes\n\n## Implementation Notes\n- Implement in crates/franken-engine as core object model module\n- Object representation should support efficient property lookup (hidden class / shape transition approach)\n- Proxy implementation must be correct-first, optimize-later - Proxy invariant checking is subtle and spec-critical\n- Property descriptor storage should distinguish data vs accessor descriptors efficiently\n- Symbol registry for well-known symbols should be initialized at engine startup\n- This module is exercised by virtually all other ES2020 features, so correctness here is load-bearing\n\n## Dependencies\n- Blocked by: baseline interpreter skeleton (bd-2f8) for execution context\n- Blocks: Phase A exit gate conformance, closure/scope model (bd-1k7) for scope objects, Promise semantics (bd-o8v) for thenable resolution\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:22.582533523Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.343092139Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-1md2","title":"[12] Prevent unsound specialization from stale proofs via epoch validity and fail-closed invalidation","description":"Plan Reference: section 12 (Risk Register).\nObjective: Stale/invalid security proofs causing unsound specialization:\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:18.794629093Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:29.822621828Z","closed_at":"2026-02-20T07:39:04.430895137Z","close_reason":"Consolidated into single risk register tracking bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-12"]}
{"id":"bd-1n78","title":"[10.15] Define advanced conformance-lab contract catalog (semantic version classes, failure taxonomy, replay obligations) extending `10.14` baseline boundary tests.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Define advanced conformance-lab contract catalog (semantic version classes, failure taxonomy, replay obligations) extending `10.14` baseline boundary tests.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:48.809108898Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.650243864Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1nh","title":"[10.12] Build deterministic causal replay engine with counterfactual branching over policy/action parameters.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Build deterministic causal replay engine with counterfactual branching over policy/action parameters.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:39.177747192Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.400149302Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-1nn","title":"[10.6] Add flamegraph pipeline and artifact storage.","description":"## Plan Reference\nSection 10.6, item 3. Cross-refs: 9D (extreme-software-optimization - profile top-5 hotspots), 9F.14 (Autopilot Performance Scientist).\n\n## What\nAdd a flamegraph pipeline that captures, stores, and makes accessible CPU/allocation flamegraphs for benchmark runs and production profiles.\n\n## Detailed Requirements\n- Automated flamegraph generation for benchmark suite runs\n- Artifact storage: flamegraphs stored as reproducible artifacts with metadata (workload, config, commit, timestamp)\n- Both CPU flamegraphs (hotspot identification) and allocation flamegraphs (allocation-heavy path identification)\n- Diff flamegraphs: compare before/after optimization to visualize impact\n- Integration with evidence graph: flamegraph artifacts linked to benchmark runs and optimization decisions\n- Storage via frankensqlite (per 10.14) for structured retrieval\n\n## Rationale\nThe plan's extreme-software-optimization discipline (9D) requires: 'Baseline first, profile top-5 hotspots before changes.' Flamegraphs are the standard tool for hotspot identification. Without automated capture and storage, profiling becomes ad-hoc and optimization decisions lose evidence backing. The Autopilot Performance Scientist (9F.14) needs flamegraph data as input for VOI-based experiment selection.\n\n## Testing Requirements\n- Integration test: run benchmark, verify flamegraph artifact is generated\n- Test: flamegraph artifact contains valid SVG/folded-stack data\n- Test: diff flamegraph between two runs shows expected changes\n- Test: flamegraph metadata is complete and queryable\n\n## Dependencies\n- Blocked by: benchmark suite (bd-2ql)\n- Blocks: opportunity matrix scoring (bd-js4), one-lever policy (bd-2l6)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:25.482572624Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:07.275176897Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-6"]}
{"id":"bd-1npj","title":"[14] A public `>= 3x` claim is valid only if:","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: A public `>= 3x` claim is valid only if:\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:30.918588910Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:29.987748111Z","closed_at":"2026-02-20T07:41:20.617789294Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-1o2","title":"[10.12] Implement security-proof ingestion path for optimizer hypotheses (PLAS witnesses, IFC flow proofs, replay sequence motifs).","description":"## Plan Reference\n- **10.12 Item 3** (Security-proof ingestion for optimizer hypotheses)\n- **9H.1**: Proof-Carrying Adaptive Optimizer -> canonical owner: 9F.1 (Verified Adaptive Compiler), execution: 10.12\n- **9H.14**: Security-Proof-Guided Specialization Flywheel -> canonical owner: 9I.8, execution: 10.12 + 10.15\n- **9I.8**: Security-Proof-Guided Specialization -- security proofs become first-class optimizer inputs\n\n## What\nImplement the ingestion path that allows the adaptive optimizer to consume security proofs as first-class optimization inputs. This is the mechanism by which PLAS capability witnesses, IFC flow proofs, and replay-derived sequence motifs are translated into optimizer hypotheses that enable proof-guided specialization.\n\n## Detailed Requirements\n\n### Proof Ingestion Interface\n1. Define a typed ingestion API that accepts three categories of security proof inputs:\n   - **PLAS capability witnesses** (from 10.15/9I.5): Contain minimal capability envelopes defining unreachable authority branches. Optimizer uses these to specialize hostcall dispatch and eliminate provably unreachable code paths.\n   - **IFC flow proofs** (from 10.15/9I.7): Identify regions where label propagation/checks are provably unnecessary. Optimizer elides flow-control checks in proven-safe regions.\n   - **Replay sequence motifs** (from sentinel/evidence system): Stable policy-legal call sequence patterns derived from production evidence. Optimizer proposes fused superinstructions with proof-linked activation for these motifs.\n2. Each ingested proof carries: `proof_id`, `proof_type`, `proof_epoch`, `validity_window`, `issuer_signature`, `canonical_hash`, and `linked_policy_id`.\n3. Ingestion validates: signature chain integrity, epoch freshness, policy compatibility, and proof-type-specific semantic checks.\n4. Invalid or expired proofs are rejected with structured diagnostic and audit trail.\n\n### Hypothesis Generation\n1. For each valid proof input, generate one or more optimizer hypotheses:\n   - PLAS witness -> dead-code elimination hypothesis, dispatch specialization hypothesis\n   - IFC flow proof -> check-elision hypothesis for proven-safe regions\n   - Replay motif -> superinstruction fusion hypothesis for stable sequences\n2. Each hypothesis carries: `hypothesis_id`, `source_proof_ids[]`, `optimization_class`, `expected_speedup_estimate`, `risk_assessment`, `validity_constraints`.\n3. Hypotheses feed into the translation-validation gate (bd-2qj) for equivalence verification before activation.\n\n### Epoch Binding and Invalidation\n1. All proof-derived hypotheses are bound to their source proof epoch.\n2. When source proofs are invalidated (policy churn, capability revocation, epoch rotation), derived hypotheses and any activated specializations are deterministically invalidated (coordinated with bd-nhp).\n3. Invalidation cascades: proof invalidation -> hypothesis invalidation -> specialization rollback -> baseline fallback.\n\n### Specialization Receipt Emission\n1. Every activated proof-guided specialization emits a signed `proof_specialization_receipt` (per 10.15 schema) linking: `proof_input_ids`, `optimization_class`, `transformation_witness`, `equivalence_evidence`, `rollback_token`, and `activation_stage`.\n2. Receipts enable audit queries from security proof -> optimization receipt -> benchmark outcome (per 10.15 frankensqlite index).\n\n## Rationale\n> \"Make security proofs first-class optimizer inputs so tighter verified constraints yield faster executable paths instead of being treated as overhead.\" -- 9I.8\n> \"Security investment compounds into performance improvement rather than competing with it, creating a structural flywheel unavailable to generic runtimes without proof-bearing security planes.\" -- 9I.8\n\nThis is the core mechanism of the security-as-optimization flywheel. Without it, security proofs remain pure overhead; with it, tighter security constraints directly produce faster execution.\n\n## Testing Requirements\n1. **Unit tests**: Proof ingestion validation for each proof type (valid, expired, revoked, wrong-epoch, malformed); hypothesis generation correctness for each proof-to-hypothesis mapping; invalidation cascade completeness.\n2. **Property tests**: Fuzz proof inputs to verify no invalid proof passes ingestion; verify hypothesis generation is deterministic given same proof inputs.\n3. **Integration tests**: End-to-end from proof emission (mock PLAS/IFC/replay sources) through ingestion, hypothesis generation, translation-validation, and activation with receipt emission and audit-chain verification.\n4. **Performance tests**: Measure overhead of proof ingestion on optimizer pipeline; verify specialization produces measurable speedup vs unspecialized baseline.\n5. **Regression tests**: Confirm proof-specialized paths produce identical observable behavior to unspecialized paths across conformance corpus (per 10.7 specialization-conformance suite).\n\n## Implementation Notes\n- Ingestion module acts as adapter layer between security subsystems (10.5, 10.15) and optimizer pipeline (10.12 items 1-2).\n- Use trait-based proof source abstraction so PLAS, IFC, and replay sources can be added/evolved independently.\n- Hypothesis priority scoring should integrate with the Autopilot Performance Scientist (9F.14) VOI framework when available.\n- Place receipt emission behind the same signer infrastructure as `opt_receipt` (bd-yqe).\n\n## Dependencies\n- bd-yqe: Proof schema and signer model\n- bd-2qj: Translation-validation gate (hypotheses must pass validation)\n- bd-nhp: Epoch-bound invalidation (coordinates invalidation cascades)\n- 10.15: PLAS capability witnesses, IFC flow proofs, specialization receipt schema\n- 10.5: Sentinel evidence system (replay sequence motifs)\n- 10.11: Security epoch model","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:38.537631360Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.568110823Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-1o7u","title":"[10.13] Integrate `frankenlab` scenarios for extension lifecycle and containment paths (startup, normal shutdown, forced cancel, quarantine, revocation, degraded mode).","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Integrate `frankenlab` scenarios for extension lifecycle and containment paths (startup, normal shutdown, forced cancel, quarantine, revocation, degraded mode).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:43.435115096Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.559600761Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-1of","title":"[10.0] Top 10 Initiative Tracking (Canonical Implementation Index) - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.0: Top 10 Initiative Tracking (Canonical Implementation Index)\n\n## Overview\nThis epic is the strategic index mapping the 10 adopted initiatives (9A) to their execution tracks. It is a governance/tracking artifact, not an implementation track itself. Each Top-10 initiative has a canonical owner section and execution owners in 10.x tracks.\n\n## Canonical Anti-Drift Contract (from plan)\n- 9A is the strategic Top-10 index (program intent and ordering)\n- 9F and 9I hold deep capability semantics and moonshot-level rationale\n- 10.x sections are the executable ownership surface for implementation\n- Precedence: 10.x execution contracts > 9F/9I capability semantics > 9A strategic framing\n- Any new capability must be added once as canonical owner, then referenced by mappings; no parallel implementation obligations\n\n## Child Beads (Initiative Tracking)\n- bd-20c: #1 TS-first capability-typed IR execution → 10.2, 10.5, 10.12\n- bd-3uk: #2 Probabilistic Guardplane → 10.5, 10.11, 10.12\n- bd-1to: #3 Deterministic evidence graph + replay → 10.5, 10.11, 10.12, 10.13\n- bd-3g4: #4 Alien-performance profile discipline → 10.6, 10.12\n- bd-3hj: #5 Supply-chain trust fabric → 10.10, 10.12, 10.13\n- bd-1cu: #6 Shadow-run + differential executor → 10.7, 10.12\n- bd-ttd: #7 Capability lattice + typed policy DSL → 10.5, 10.10, 10.12, 10.13\n- bd-1fa: #8 Deterministic resource budgets → 10.11, 10.12, 10.13\n- bd-3zj: #9 Adversarial security corpus + fuzzing → 10.7, 10.12\n- bd-3mx: #10 Provenance + revocation fabric → 10.10, 10.11, 10.12, 10.13\n\n## Recommended Staged Order\n1. TS-first IR execution, 2. Probabilistic Guardplane, 3. Evidence graph + replay, 4. Shadow-run + differential, 5. Resource budgets, 6. Capability lattice, 7. Adversarial corpus, 8. Supply-chain trust, 9. Provenance + revocation, 10. Alien-performance (continuous)\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.172859330Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:10.923753469Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-0"],"dependencies":[{"issue_id":"bd-1of","depends_on_id":"bd-1cu","type":"parent-child","created_at":"2026-02-20T07:52:43.719825917Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-1fa","type":"parent-child","created_at":"2026-02-20T07:52:43.999300364Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-1to","type":"parent-child","created_at":"2026-02-20T07:52:45.740945513Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-20c","type":"parent-child","created_at":"2026-02-20T07:52:46.436874636Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-3g4","type":"parent-child","created_at":"2026-02-20T07:52:52.203046989Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-3hj","type":"parent-child","created_at":"2026-02-20T07:52:52.362000284Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-3mx","type":"parent-child","created_at":"2026-02-20T07:52:52.916796195Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-3uk","type":"parent-child","created_at":"2026-02-20T07:52:54.143835532Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-3vh","type":"blocks","created_at":"2026-02-20T07:32:55.259844237Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-3zj","type":"parent-child","created_at":"2026-02-20T07:52:54.422009367Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1of","depends_on_id":"bd-ttd","type":"parent-child","created_at":"2026-02-20T07:52:56.670223281Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ovk","title":"[10.15] Define IFC artifacts (`flow_policy`, `flow_proof`, `declassification_receipt`, `confinement_claim`) with deterministic encoding and signature requirements.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Define IFC artifacts (`flow_policy`, `flow_proof`, `declassification_receipt`, `confinement_claim`) with deterministic encoding and signature requirements.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:52.166154216Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.623762367Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1p4","title":"[10.10] Add activation/update/rollback contract: sandbox setup, ephemeral secret injection, staged rollout, crash-loop auto-rollback, known-good pinning.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Add activation/update/rollback contract: sandbox setup, ephemeral secret injection, staged rollout, crash-loop auto-rollback, known-good pinning.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:32.979638185Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.732787875Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-1pqn","title":"[14] Each case must publish: throughput, `p50/p95/p99` latency, allocation/peak memory, correctness digest, and security-event envelope.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Each case must publish: throughput, `p50/p95/p99` latency, allocation/peak memory, correctness digest, and security-event envelope.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:29.214797229Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:30.234232622Z","closed_at":"2026-02-20T07:41:21.324671499Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-1ps3","title":"[10.14] Inventory every current/planned local persistence need (replay index, evidence index, benchmark ledger, policy artifact cache) and map each to a `frankensqlite` integration point.","description":"## Plan Reference\nSection 10.14, item 5. Cross-refs: 10.15 (frankensqlite-backed stores for witnesses, lineage, provenance, specialization).\n\n## What\nInventory every current and planned local persistence need in FrankenEngine and map each to a frankensqlite integration point. This is the design document that drives the storage adapter layer.\n\n## Detailed Requirements\n- Catalog all persistence needs: replay index, evidence index, benchmark ledger, policy artifact cache, PLAS witness store, replacement lineage log, IFC provenance index, specialization index\n- For each: define data model, access patterns, consistency requirements, retention policy\n- Map each to specific frankensqlite API/contract (table schema, query patterns, migration strategy)\n- Identify shared vs isolated databases (some stores may share a DB, others need isolation)\n- Define deterministic replay requirements for each store (can this data be replayed deterministically?)\n\n## Rationale\nWithout a comprehensive inventory, persistence needs will be addressed ad-hoc with inconsistent patterns. The inventory ensures all stores are designed together for schema coherence, migration compatibility, and deterministic behavior.\n\n## Testing Requirements\n- Review gate: inventory is complete before storage adapter implementation begins\n- Traceability: each planned store in 10.15 maps to an inventory entry\n\n## Dependencies\n- Blocked by: frankensqlite ADR (bd-3azm)\n- Blocks: storage adapter layer (bd-89l2), all specific frankensqlite stores in 10.15","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:45.381757842Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.555320297Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-1qgn","title":"[10.14] Add CI/policy guard preventing new local interactive TUI frameworks in `franken_engine` without explicit ADR exception.","description":"## Plan Reference\nSection 10.14, item 3. Cross-refs: bd-2l0x (frankentui ADR), Section 13 success criterion.\n\n## What\nAdd a CI/policy guard that prevents new local interactive TUI frameworks from being introduced in franken_engine without an explicit ADR exception. This enforces the frankentui-first policy.\n\n## Detailed Requirements\n- CI check: scan for new TUI framework dependencies (crossterm, ratatui, cursive, etc. when not routed through frankentui)\n- CI check: scan for new TUI module/file creation patterns\n- Exception process: explicit ADR exception document required to bypass guard\n- Guard must distinguish between: frankentui integration (allowed), simple CLI output (allowed), new local TUI framework (blocked)\n\n## Rationale\nWithout enforcement, the frankentui-first policy will erode under time pressure. Engineers will create 'quick' local TUI solutions that fragment the operator experience and duplicate frankentui work. The CI guard makes policy violations visible and actionable.\n\n## Testing Requirements\n- CI test: adding a ratatui dependency triggers guard failure\n- CI test: adding frankentui dependency passes guard\n- CI test: ADR exception document bypasses guard for documented cases\n\n## Dependencies\n- Blocked by: frankentui ADR (bd-2l0x), TUI adapter boundary (bd-1ad6)\n- Blocks: enforcement of frankentui-first policy","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:45.058058734Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.637247908Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-1qj6","title":"[13] GA default lanes run with zero mandatory delegate cells for core runtime slots","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: GA default lanes run with zero mandatory delegate cells for core runtime slots\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:27.343725828Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:30.356649985Z","closed_at":"2026-02-20T07:39:57.192430577Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1r25","title":"[10.15] Extend receipt schema to include attestation bindings (`quote_digest`, `measurement_id`, `attested_signer_key_id`, `nonce`, `validity_window`).","description":"## Plan Reference\nSection 10.15 (Delta Moonshots Execution Track), subsection 9I.1 (TEE-Bound Cryptographic Decision Receipts), item 2 of 4.\n\n## What\nExtend the existing decision-receipt schema to include attestation binding fields that cryptographically tie each receipt to the measured environment that produced it.\n\n## Detailed Requirements\n1. Add the following fields to the canonical receipt schema:\n   - `quote_digest`: hash of the full TEE attestation quote accompanying this receipt.\n   - `measurement_id`: reference to the specific approved measurement from the TEE attestation policy that was active when the receipt was signed.\n   - `attested_signer_key_id`: identifier of the signing key that was itself attested (bound to TEE identity), distinguishing it from software-only signing keys.\n   - `nonce`: cryptographic nonce used in the attestation challenge to prevent replay of stale quotes.\n   - `validity_window`: explicit start/end timestamps defining when this attestation binding is considered fresh.\n2. Fields must use deterministic canonical encoding consistent with the existing receipt serialization contract.\n3. Attestation bindings must be non-optional for high-impact decision classes (as defined by the sentinel risk tier); lower-impact receipts may include them optionally with a policy-controlled threshold.\n4. Schema versioning must accommodate receipts produced before attestation binding was available (backward compatibility with version discriminator).\n5. Define clear signature preimage contract: attestation fields must be included in the signed content, not appended post-signature.\n\n## Rationale\nFrom 9I.1: \"This upgrades auditability from 'signed by our service' to 'provably emitted by known measured code in a constrained environment.' That materially improves external trust for enterprise governance, incident response, regulator/auditor review, and cross-organization evidence sharing.\" Without binding fields in the receipt schema itself, attestation evidence would be a detached side-channel rather than a cryptographically integral part of the trust chain.\n\n## Testing Requirements\n- Unit tests: serialize/deserialize receipts with and without attestation bindings, reject receipts missing required attestation fields for high-impact classes, validate nonce uniqueness enforcement.\n- Integration tests: end-to-end receipt emission from an attested signer with full field population, verify round-trip through transparency log, validate that verifier pipeline accepts well-formed bindings and rejects tampered ones.\n- Backward compatibility tests: verify old-format receipts remain parseable and distinguishable from attested receipts.\n- Deterministic replay: receipt serialization must produce byte-identical output for identical inputs.\n\n## Implementation Notes\n- Align with `EngineObjectId` and deterministic serialization from 10.10 for the new fields.\n- The `attested_signer_key_id` should reference keys registered in the TEE attestation policy trust roots.\n- Nonce generation must use a CSPRNG with transcript commitment for replay auditability.\n\n## Dependencies\n- bd-2xu5 (TEE attestation policy definition - provides the measurement_id reference space).\n- 10.10 (deterministic serialization and signature preimage contracts).\n- 10.5 (decision receipt infrastructure in extension host).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:47.170176448Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.092478033Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1rdj","title":"[10.13] Add benchmark split showing control-plane overhead remains bounded while VM hot-loop performance remains decoupled.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Add benchmark split showing control-plane overhead remains bounded while VM hot-loop performance remains decoupled.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:44.251207526Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.329079965Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-1rju","title":"[13] privacy-preserving fleet learning operates continuously with zero budget-overrun incidents and measurable calibration/drift-improvement over local-only baselines","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: privacy-preserving fleet learning operates continuously with zero budget-overrun incidents and measurable calibration/drift-improvement over local-only baselines\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:24.095118828Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:30.483645416Z","closed_at":"2026-02-20T07:39:58.585156720Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1si","title":"[10.11] Implement `PolicyController` service for non-correctness knobs with explicit action sets and loss matrices.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement `PolicyController` service for non-correctness knobs with explicit action sets and loss matrices.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:35.080674328Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.410939451Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-1to","title":"[10.0] Top-10 #3: Deterministic evidence graph + replay tooling (strategy: `9A.3`; deep semantics: `9F.3`; execution owners: `10.5`, `10.11`, `10.12`, `10.13`).","description":"## Plan Reference\nSection 10.0 item 3. Strategy: 9A.3. Deep semantics: 9F.3 (Deterministic Time-Travel + Counterfactual Replay). Enhancement maps: 9B.3 (hindsight logging, deterministic simulation), 9C.3 (Bayes-factor decomposition, counterfactual action report), 9D.3 (replay throughput profiling).\n\n## What\nStrategic tracking bead for Initiative #3: Deterministic evidence graph + replay for all security/performance decisions. Every meaningful decision is recorded as linked artifacts with deterministic replay support.\n\n## Execution Owners\n- **10.5** (Extension Host): forensic replay tooling, decision receipt emission\n- **10.11** (Runtime Systems): evidence-ledger schema, deterministic ordering/stability, decision marker stream, lab runtime harness\n- **10.12** (Frontier Programs): causal replay engine with counterfactual branching, incident replay artifact bundle\n- **10.13** (Asupersync Integration): Cx threading, evidence replay checks, frankenlab scenarios\n\n## Strategic Rationale (from 9A.3)\n'Strong guarantees require explainability and post-incident forensics; otherwise both security and optimization claims are fragile.'\n\n## Key Deliverables\n- Every decision recorded as: claim → evidence → policy → action with trace_id, policy_id, decision_id\n- Deterministic replay: identical re-execution from fixed artifacts\n- Counterfactual branching: simulate alternate decisions from same evidence\n- Bayes-factor decomposition showing which evidence terms moved decisions\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:19.488373355Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.267462480Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-1tsf","title":"[MASTER] Execute PLAN 10.x end-to-end with full dependency graph","description":"Master orchestration epic for the full program-level TODO decomposition.\nThis bead represents complete execution of sections 10.0-10.15 with explicit dependency graphing, quality gates, and verification obligations.\nProgram invariants:\n- Preserve ambition-first doctrine and category-defining capability goals.\n- No scope collapse, no hidden compatibility shims, no proof-free claims.\n- Every stream must include unit tests, e2e/integration tests, and high-fidelity logging.\n- Every high-impact capability must carry reproducible/evidence-backed outputs.\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:32:58.319192260Z","created_by":"ubuntu","updated_at":"2026-02-20T07:53:36.377918800Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["master","plan","section-10"],"dependencies":[{"issue_id":"bd-1tsf","depends_on_id":"bd-12m","type":"parent-child","created_at":"2026-02-20T07:53:36.377868476Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-1of","type":"parent-child","created_at":"2026-02-20T07:52:45.297020570Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-1xm","type":"parent-child","created_at":"2026-02-20T07:52:46.069582209Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-1yq","type":"parent-child","created_at":"2026-02-20T07:52:46.229906078Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-2g9","type":"parent-child","created_at":"2026-02-20T07:52:47.936124621Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-2mf","type":"parent-child","created_at":"2026-02-20T07:52:48.551326813Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-2r6","type":"parent-child","created_at":"2026-02-20T07:52:49.191973248Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-32r","type":"parent-child","created_at":"2026-02-20T07:52:50.857762408Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-383","type":"parent-child","created_at":"2026-02-20T07:52:51.386858019Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-3ch","type":"parent-child","created_at":"2026-02-20T07:52:51.824763049Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-3nr","type":"parent-child","created_at":"2026-02-20T07:52:53.074950983Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-3q9","type":"parent-child","created_at":"2026-02-20T07:52:53.341741746Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-3vh","type":"parent-child","created_at":"2026-02-20T07:52:54.223445664Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-3vk","type":"parent-child","created_at":"2026-02-20T07:52:54.262939224Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-ntq","type":"parent-child","created_at":"2026-02-20T07:52:56.303992150Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1tsf","depends_on_id":"bd-zvn","type":"parent-child","created_at":"2026-02-20T07:52:57.251096102Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1tw4","title":"[13] cross-repo conformance lab pass rate is a hard release gate for shared-boundary changes, with deterministic repro artifacts for every failure class","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: cross-repo conformance lab pass rate is a hard release gate for shared-boundary changes, with deterministic repro artifacts for every failure class\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:24.533929503Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:30.647633048Z","closed_at":"2026-02-20T07:39:58.383051082Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-1ukb","title":"[10.13] Integrate region-per-extension/session execution cells with quiescent close guarantees using primitives owned by `10.11`.","description":"# Integrate Region-Per-Extension/Session Execution Cells with Quiescent Close\n\n## Plan Reference\nSection 10.13, Item 6.\n\n## What\nIntegrate the region-based execution cell model (owned by 10.11) into FrankenEngine's extension-host subsystem so that each loaded extension or active session runs within its own isolated execution region, and region teardown follows the quiescent close protocol guaranteeing no dangling work survives region destruction.\n\n## Detailed Requirements\n- **Integration/binding nature**: Region-based execution cells, their allocation, and quiescent close semantics are 10.11 primitives. This bead wires them into the extension-host lifecycle so that:\n  - Extension load creates a new execution region.\n  - Session start creates a sub-region scoped to the session lifetime.\n  - Region close follows the quiescent protocol: drain in-flight work -> await quiescence -> finalize -> destroy.\n  - No extension or session code can outlive its region; the region boundary is an absolute containment barrier.\n- Each region must carry a `Cx` (threaded per bd-2ygl) that provides the region's budget, trace context, and cancellation token.\n- Region allocation and teardown must be observable via evidence emission (bd-uvmm).\n- The extension-host must support concurrent regions (multiple extensions loaded simultaneously) without cross-region interference.\n- Region quiescent close must respect cancellation lifecycle (bd-2wz9): a cancel signal triggers drain, which leads to quiescent close.\n\n## Rationale\nWithout region isolation, a misbehaving extension can leak resources, corrupt shared state, or prevent orderly shutdown of other extensions. The region model provides hard containment boundaries. Quiescent close ensures that teardown is never abrupt; in-flight work always gets a chance to drain before the region is destroyed, preventing data loss and undefined behavior.\n\n## Testing Requirements\n- Unit test: create a region, spawn work, close the region, verify all work completes or is cancelled before region destruction.\n- Integration test: load two extensions in separate regions, crash one, verify the other is unaffected.\n- Quiescent close test: initiate region close while work is in-flight, verify drain completes before finalization.\n- Timeout test: verify that quiescent close with a budget-exceeded condition escalates to forced teardown within bounded time.\n- Frankenlab scenario (coordinated with bd-1o7u): full extension load/unload cycle with region lifecycle assertions.\n\n## Implementation Notes\n- **10.11 primitive ownership**: Execution regions, region allocation, quiescent close protocol, and budget enforcement are all 10.11 primitives imported through the adapter layer (bd-23om).\n- The integration point is the extension-host lifecycle manager, which must create/destroy regions at the correct lifecycle boundaries.\n- Coordinate with bd-2wz9 (cancellation) and bd-m9pa (obligation tracking) as they depend on region semantics.\n\n## Dependencies\n- Depends on bd-23om (adapter layer providing region APIs).\n- Depends on bd-2ygl (Cx threading, as each region carries a Cx).\n- Depended upon by bd-2wz9 (cancellation operates within regions) and bd-m9pa (obligations are region-scoped).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:42.479483918Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.863232104Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-1v5","title":"[10.11] Implement epoch transition barrier across core services to prevent mixed-epoch critical operations.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement epoch transition barrier across core services to prevent mixed-epoch critical operations.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:35.963158175Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.136817173Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-1v90","title":"[10.15] Extend PLAS synthesis to emit minimal flow envelopes in addition to capability envelopes.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Extend PLAS synthesis to emit minimal flow envelopes in addition to capability envelopes.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:52.675050458Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.477123643Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-1wa","title":"[10.2] Define multi-level IR contract (`IR0`/`IR1`/`IR2`/`IR3`/`IR4`) including canonical serialization/hash invariants.","description":"## Plan Reference\nSection 10.2, item 2. Cross-refs: 9A.1, 9B.1 (typestate/session types/algebraic effects), 9C.1 (proof-carrying compilation), 9F.4 (capability-typed TS execution), 9I.7 (IFC flow labels in IR2), 9I.8 (proof-to-specialization linkage in IR3/IR4).\n\n## What\nDefine the complete multi-level Intermediate Representation contract spanning five levels:\n- **IR0 (SyntaxIR)**: Direct AST output from parser, structurally canonical\n- **IR1 (SpecIR)**: Spec-level semantic representation, scope/binding resolved\n- **IR2 (CapabilityIR)**: Annotated with capability intent, effect boundaries, and IFC flow labels\n- **IR3 (ExecIR)**: Execution-ready form with proof-to-specialization linkage\n- **IR4 (WitnessIR)**: Post-execution witness artifacts for replay and audit\n\nEach level must define canonical serialization format and hash computation for deterministic replay and evidence linkage.\n\n## Detailed Requirements\n- Each IR level must have a defined Rust type hierarchy with serde support\n- Canonical serialization: deterministic byte output for identical semantic content (field ordering, normalization rules)\n- Hash invariants: content-addressed hashing at each level for evidence graph linkage\n- IR2 must carry: capability annotations per Section 9F.4, IFC flow labels per Section 9I.7 (label classes, clearance classes, declassification obligations)\n- IR3 must carry: proof-to-specialization linkage per Section 9I.8 (proof_input_ids, optimization_class, validity_epoch, rollback_token)\n- IR4 must carry: execution witness data for replay determinism and forensic audit\n- Version schema for IR formats to support migration (per Section 9E.10)\n\n## Rationale\nThe IR stack is the architectural spine of FrankenEngine. The plan explicitly requires that capability intent, effect boundaries, and host interaction metadata flow through compilation (9A.1). The proof-carrying compilation contract (9C.1) requires each lowering stage to emit invariants and machine-checkable witnesses. Without canonical serialization/hash invariants, evidence graph linkage (9A.3) and deterministic replay (9F.3) are impossible.\n\n## Testing Requirements\n- Unit tests: construct IR at each level, verify canonical serialization produces deterministic bytes\n- Unit tests: verify hash computation is stable across identical IR instances\n- Unit tests: verify IR2 capability annotations are preserved through serialization round-trip\n- Unit tests: verify IR3 proof linkage fields are present and correctly typed\n- Property tests: IR serialization round-trip preserves all semantic content\n- Migration tests: versioned IR can be deserialized by both current and next version\n\n## Implementation Notes\n- Define in crates/franken-engine as core IR types module\n- Use serde with deterministic field ordering (BTreeMap not HashMap for any map fields)\n- Consider content-addressed storage design from the start\n- IR0→IR1→IR2→IR3 forms a lowering pipeline; IR4 is emitted post-execution\n- Each level should have a From/TryFrom relationship to the next lower level\n\n## Dependencies\n- Blocked by: parser trait (bd-crp) for IR0 design\n- Blocks: lowering pipelines (bd-ug9), IFC flow-lattice (bd-1fm), proof-to-specialization linkage (bd-161), flow-check pass (bd-3jg)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.542756438Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.671748214Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-1wqa","title":"[15] Partner program for early lighthouse adopters who validate category-shift outcomes in production.","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Partner program for early lighthouse adopters who validate category-shift outcomes in production.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:35.214302597Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:30.856268871Z","closed_at":"2026-02-20T07:45:44.082252545Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-1xm","title":"[10.9] Moonshot Disruption Track - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.9 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## Purpose\nThis epic owns the release-gate verification layer for FrankenEngine's frontier and delta moonshot programs. It does NOT own implementation of moonshot capabilities -- those are delivered by tracks 10.2, 10.5, 10.6, 10.7, 10.12, and 10.15. Instead, this epic defines and enforces the evidence bar that implementations must clear before any frontier release ships.\n\n## Architecture: Gate-vs-Implementation Separation\nThe fundamental design principle of Section 10.9 is the strict separation between **gate ownership** (this track) and **implementation ownership** (other tracks). Each child bead is a release gate that:\n1. Defines measurable pass/fail criteria for a specific frontier capability.\n2. Executes validation campaigns (benchmarks, fault injection, corpus execution, audits) against the delivered implementation.\n3. Produces a signed evidence bundle certifying pass or fail.\n4. Feeds quantitative results into the disruption scorecard (bd-6pk).\n\nThis separation ensures that the team building a capability is never the sole judge of its readiness.\n\n## Disruption Scorecard Framework\nThe scorecard (bd-6pk) aggregates gate results into three dimensions:\n- **`performance_delta`:** FrankenEngine vs incumbent runtimes on the canonical benchmark corpus.\n- **`security_delta`:** Compromise-rate suppression, IFC exfiltration blocking, quarantine resilience.\n- **`autonomy_delta`:** Native lane coverage, PLAS accountability, proof-carrying pipeline completeness.\n\nAll three dimensions must meet defined thresholds before any frontier release ships.\n\n## Child Bead Summary (Execution Order)\n1. **bd-1ze** -- Node/Bun comparison harness gate (impl: 10.12 + Section 14)\n2. **bd-6pk** -- Disruption scorecard definition and enforcement\n3. **bd-uwc** -- Autonomous quarantine mesh fault-injection validation (impl: 10.12)\n4. **bd-2rx** -- Proof-carrying optimization pipeline replayability validation (impl: 10.12)\n5. **bd-3rd** -- Adversarial campaign runner compromise-rate suppression validation (impl: 10.12)\n6. **bd-2n3** -- PLAS signed capability_witness and escrow-path validation (impl: 10.15)\n7. **bd-181** -- GA native lanes zero-delegate-cell audit (impl: 10.15 + 10.2 + 10.7)\n8. **bd-eke** -- Deterministic IFC exfiltration corpus validation (impl: 10.15 + 10.5 + 10.7)\n9. **bd-dkh** -- Proof-specialized lanes performance delta and receipt coverage (impl: 10.12 + 10.15 + 10.6 + 10.7)\n10. **bd-f7n** -- Category-shift report publication (capstone, requires all gates passing)\n\n## Moonshot Coverage\n- **9F moonshots covered:** Verified Adaptive Compiler, Fleet Immune System, Time-Travel Replay, Capability-Typed TS, Cryptographic Receipts, Lockstep Oracle, Red-Team Generator, Policy Compiler, Revocation Mesh, SLO-Proven Scheduler, Semantic Build Graph, Zero-Copy IPC, Adversarial Benchmark, Autopilot Perf Scientist, Live Safety Twin.\n- **9I delta moonshots covered:** TEE-Bound Receipts, Privacy-Preserving Fleet Learning, Moonshot Portfolio Governor, Cross-Repo Conformance Lab, PLAS, Verified Self-Replacement, IFC, Security-Proof-Guided Specialization.\n\n## Cross-Track Dependencies\nThis epic blocks on implementation delivery from:\n- **10.12 (Frontier Programs):** Primary implementation track for 9F moonshots.\n- **10.15 (Delta Moonshots):** Primary implementation track for 9I moonshots.\n- **10.7 (Conformance + Verification):** Receipt verification, conformance test suites, fallback correctness.\n- **10.6 (Performance Program):** Benchmarking infrastructure and regression detection.\n- **10.5 (Security):** Exfiltration corpus, security label taxonomy, declassification policy.\n- **10.2 (Core Runtime):** Native runtime implementations replacing delegate cells.\n- **Section 14 (Benchmark Infrastructure):** Benchmark corpus definitions and statistical tooling.\n\n## Success Criteria\n1. All 10 child beads closed with passing, artifact-backed evidence bundles.\n2. Disruption scorecard shows all three dimensions at or above target thresholds.\n3. Category-shift report (bd-f7n) published with peer-reviewed evidence and reproducible claims.\n4. No silent scope reduction -- every moonshot capability listed in 9F and 9I has a traceable evidence path through at least one gate.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.753842457Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.849208186Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-9"],"dependencies":[{"issue_id":"bd-1xm","depends_on_id":"bd-12m","type":"blocks","created_at":"2026-02-20T07:32:56.483603902Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-181","type":"parent-child","created_at":"2026-02-20T07:52:43.186494998Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-1ze","type":"parent-child","created_at":"2026-02-20T07:52:46.310988932Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-2n3","type":"parent-child","created_at":"2026-02-20T07:52:48.630294618Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-2r6","type":"blocks","created_at":"2026-02-20T07:32:56.660166432Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-2rx","type":"parent-child","created_at":"2026-02-20T07:52:49.310701471Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-383","type":"blocks","created_at":"2026-02-20T07:32:56.573703198Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-3q9","type":"blocks","created_at":"2026-02-20T07:32:56.746329536Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-3rd","type":"parent-child","created_at":"2026-02-20T07:52:53.582071583Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-6pk","type":"parent-child","created_at":"2026-02-20T07:52:54.701992863Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-dkh","type":"parent-child","created_at":"2026-02-20T07:52:55.436807947Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-eke","type":"parent-child","created_at":"2026-02-20T07:52:55.519009775Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-f7n","type":"parent-child","created_at":"2026-02-20T07:52:55.669707965Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xm","depends_on_id":"bd-uwc","type":"parent-child","created_at":"2026-02-20T07:52:56.870320220Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1xva","title":"[14] Maintain a neutral verifier mode so third parties can run and validate claims.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Maintain a neutral verifier mode so third parties can run and validate claims.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:28.276857375Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:30.938939413Z","closed_at":"2026-02-20T07:41:21.720302844Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-1y5","title":"[10.5] Implement expected-loss action selector.","description":"## Plan Reference\nSection 10.5, item 5 (Implement expected-loss action selector). Cross-refs: 9C.2 (explicit expected-loss matrices in the full Bayesian decision loop), 9A.2 (Probabilistic Guardplane action selection), 9F.5 (cryptographic decision receipts for every action taken).\n\n## What\nImplement the \"decide\" stage of the 9C.2 Bayesian decision loop. Given a posterior distribution over extension risk states (from bd-3md) and an explicit loss matrix quantifying the cost of each (action, true-state) pair, the expected-loss action selector computes the expected loss for every candidate action and selects the action with minimum expected loss. Actions include: `Allow`, `Challenge`, `Sandbox`, `Suspend`, `Terminate`, `Quarantine`. The selector also produces a decision explanation (the \"explain\" stage of 9C.2) that records which posterior, which loss matrix, and which expected-loss values led to the chosen action -- this explanation is the basis for the cryptographic decision receipt (9F.5).\n\n## Detailed Requirements\n- Define `ContainmentAction` enum: `Allow`, `Challenge`, `Sandbox`, `Suspend`, `Terminate`, `Quarantine`.\n- Define `LossMatrix` as a mapping from `(ContainmentAction, RiskState) -> f64`. The matrix must be explicitly configured, never hardcoded. Provide a default matrix based on plan guidance.\n- Default loss matrix values (configurable):\n  - `(Allow, Benign) = 0.0` (correct: no cost)\n  - `(Allow, Malicious) = 100.0` (catastrophic: letting malicious code run)\n  - `(Terminate, Benign) = 10.0` (bad: killing a good extension)\n  - `(Terminate, Malicious) = 0.5` (minor: cleanup cost of terminating malicious code)\n  - Fill all 6x4 = 24 cells with principled defaults.\n- Implement `ExpectedLossSelector` with methods:\n  - `new(loss_matrix: LossMatrix) -> Self`\n  - `select(&self, posterior: &Posterior) -> ActionDecision` - compute expected loss for each action, return the action with minimum expected loss.\n  - `expected_losses(&self, posterior: &Posterior) -> BTreeMap<ContainmentAction, f64>` - return all expected losses for transparency.\n- `ActionDecision` struct: `{ action: ContainmentAction, expected_loss: f64, runner_up_action: ContainmentAction, runner_up_loss: f64, explanation: DecisionExplanation }`.\n- `DecisionExplanation` struct: `{ posterior_snapshot: Posterior, loss_matrix_id: String, all_expected_losses: BTreeMap<ContainmentAction, f64>, margin: f64 }` where margin = runner_up_loss - selected_loss.\n- The selector must be deterministic: identical posterior + loss matrix always produces identical action selection.\n- When two actions have identical expected loss, break ties by action severity (prefer less severe action).\n- Emit a structured `SecurityDecisionEvent` to telemetry for every selection.\n\n## Rationale\nRule-based security systems use fixed thresholds (e.g., \"if score > 0.9, terminate\"). This is fragile because it ignores the asymmetric costs of different errors. A false positive (terminating a benign extension) has a very different cost from a false negative (allowing a malicious extension to run). The expected-loss framework from 9C.2 makes these tradeoffs explicit and configurable per deployment. The decision explanation enables audit, debugging, and the cryptographic decision receipt (9F.5) that proves every security action was justified by evidence and a well-defined decision procedure.\n\n## Testing Requirements\n- **Unit tests**: Compute expected loss for a known posterior and loss matrix; verify arithmetic. Test that `P(Malicious) = 1.0` selects `Terminate`. Test that `P(Benign) = 1.0` selects `Allow`. Test tie-breaking favors less severe action. Test that changing the loss matrix changes the decision boundary.\n- **Boundary tests**: Posterior at exact decision boundaries (where two actions have nearly equal expected loss). Verify consistent tie-breaking.\n- **Explanation tests**: Verify `DecisionExplanation` contains correct posterior snapshot, all expected losses, and correct margin calculation.\n- **Property tests**: For any valid posterior (probabilities sum to 1.0) and any valid loss matrix (non-negative), the selector always returns a valid action. Expected loss of selected action is always <= expected loss of every other action.\n- **Integration tests**: Wire posterior updater (bd-3md) to action selector; feed synthetic evidence and verify the correct sequence of actions is selected.\n\n## Implementation Notes\n- Expected loss for action `a` = sum over states `s` of `P(s) * Loss(a, s)`. This is a simple dot product per action.\n- The `LossMatrix` should be loadable from a configuration file (TOML or JSON) for operator customization.\n- Consider providing named loss matrix presets: \"conservative\" (high cost for false negatives), \"permissive\" (high cost for false positives), \"balanced\".\n- The `margin` field in `DecisionExplanation` is crucial for monitoring: a small margin indicates the decision was borderline and may flip with small evidence changes.\n\n## Dependencies\n- **Blocked by**: bd-3md (Bayesian posterior updater provides the posterior input).\n- **Blocks**: bd-2gl (containment actions execute the selected action), bd-t2m (forensic replay must reproduce decision trajectories), bd-3jy (declassification decision contracts reference the action selector).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.415330701Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.707113716Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-1y63","title":"[14] Revocation/quarantine propagation (freshness lag distribution, convergence SLO attainment).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Revocation/quarantine propagation (freshness lag distribution, convergence SLO attainment).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:33.570962678Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.020438683Z","closed_at":"2026-02-20T07:41:19.476657150Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-1yq","title":"[10.5] Extension Host + Security - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.5 (Extension Host + Security). This is the execution epic covering all security-related extension host infrastructure. Cross-refs: 9A.1 (capability-typed execution), 9A.2 (Probabilistic Guardplane), 9A.5 (supply-chain trust), 9A.7 (capability lattice), 9A.8 (resource budgets), 9B.2 (conformal prediction, e-process, BOCPD), 9C.2 (full Bayesian decision loop), 9F.3 (deterministic replay), 9F.5 (cryptographic decision receipts), 9G.2 (cancellation as protocol), 9I.6 (verified self-replacement), 9I.7 (IFC + deterministic exfiltration prevention).\n\n## What\nThis epic encompasses all work required to make FrankenEngine's extension host a security-first execution environment. Extensions are untrusted code that runs inside the engine with explicit, validated capability declarations, probabilistic threat monitoring, cost-sensitive decision-making, fast containment, forensic replay capability, and information flow control. The epic covers 10 implementation beads spanning from low-level manifest validation through high-level Bayesian decision loops to IFC enforcement and cryptographic audit trails.\n\n## Architecture Overview\nThe 10.5 subsystem forms a layered security pipeline:\n\n1. **Foundation Layer** (manifest validation + lifecycle management): Ensures no extension runs without a validated manifest and that every extension follows a deterministic lifecycle state machine.\n2. **Evidence Layer** (hostcall telemetry): Captures structured, timestamped records of every hostcall as behavioral evidence for the security decision system.\n3. **Inference Layer** (Bayesian posterior updater): Maintains calibrated probabilistic beliefs about each extension's risk state based on the evidence stream.\n4. **Decision Layer** (expected-loss action selector): Selects security actions by minimizing expected loss given the current posterior and an explicit loss matrix.\n5. **Enforcement Layer** (containment actions): Executes security actions (sandbox, suspend, terminate, quarantine) with deterministic behavior and latency guarantees.\n6. **Forensic Layer** (replay tooling): Enables deterministic replay and counterfactual analysis of security incidents.\n7. **Parity Layer** (delegate cell security): Ensures runtime-internal components receive identical security treatment to third-party extensions.\n8. **IFC Layer** (flow-label propagation + declassification): Enforces information flow control at runtime hostcall boundaries with auditable declassification.\n\n## Phase B Exit Gate Requirements\n- All security subsystems active and integrated (all 10 beads complete).\n- Probabilistic security conformance passes (Bayesian models produce calibrated posteriors).\n- Median detection-to-containment latency <= 250ms (measured end-to-end from first anomalous evidence to containment action effective).\n- All security decisions produce cryptographic receipts verifiable by external auditors.\n- Forensic replay reproduces identical decision trajectories on historical incidents.\n- IFC enforcement blocks unauthorized data flows at runtime with < 500ns overhead per hostcall.\n- Delegate cells are indistinguishable from untrusted extensions in security treatment.\n\n## Child Beads (Execution Order)\n1. bd-xq7: Port extension manifest validation (foundation)\n2. bd-1hu: Port extension lifecycle manager (foundation)\n3. bd-5pk: Hostcall telemetry schema and recorder (evidence)\n4. bd-3md: Bayesian posterior updater API (inference)\n5. bd-1y5: Expected-loss action selector (decision)\n6. bd-2gl: Containment actions (enforcement)\n7. bd-t2m: Forensic replay tooling (forensic)\n8. bd-375: Delegate cell security policy (parity)\n9. bd-1hw: Runtime flow-label propagation (IFC)\n10. bd-3jy: Declassification through decision contracts (IFC)\n\n## Success Criteria\n1. All 10 child beads complete with artifact-backed acceptance evidence including unit tests, deterministic integration scripts, and structured logging validation.\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied: replayability, benchmark/correctness artifacts, and operator verification instructions for every subsystem.\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature or functionality reduction.\n5. End-to-end integration test demonstrates the full security pipeline: extension loads -> makes hostcalls -> telemetry recorded -> posterior updated -> anomalous behavior detected -> action selected -> containment executed -> incident replayed -> decisions verified.\n\n## Dependencies\n- **Blocked by**: bd-ntq (10.2 VM Core - provides IFC flow-lattice foundation), bd-3ch (10.4 Module + Runtime Surface - provides hostcall dispatch infrastructure).\n- **Blocks**: bd-3vh (10.10 FCP Hardening), bd-3q9 (10.15 Delta Moonshots), bd-2r6 (10.12 Frontier Programs), bd-2g9 (10.11 Runtime Systems), bd-32r (10.8 Operational Readiness), bd-383 (10.7 Conformance + Verification), bd-12m (10.6 Performance Program).\n- **Parent**: bd-1tsf (MASTER execution epic).","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:32:18.494764838Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:10.604918035Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-5"],"dependencies":[{"issue_id":"bd-1yq","depends_on_id":"bd-1hu","type":"parent-child","created_at":"2026-02-20T07:52:44.354665285Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-1hw","type":"parent-child","created_at":"2026-02-20T07:52:44.395056838Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-1y5","type":"parent-child","created_at":"2026-02-20T07:52:46.149148840Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-2gl","type":"parent-child","created_at":"2026-02-20T07:52:48.057808368Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-375","type":"parent-child","created_at":"2026-02-20T07:52:51.219838289Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-3ch","type":"blocks","created_at":"2026-02-20T07:32:55.781092336Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-3jy","type":"parent-child","created_at":"2026-02-20T07:52:52.559259178Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-3md","type":"parent-child","created_at":"2026-02-20T07:52:52.837272524Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-3vh","type":"blocks","created_at":"2026-02-20T07:32:55.608087994Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-5pk","type":"parent-child","created_at":"2026-02-20T07:52:54.621790619Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-ntq","type":"blocks","created_at":"2026-02-20T07:32:55.695053523Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-t2m","type":"parent-child","created_at":"2026-02-20T07:52:56.587250736Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1yq","depends_on_id":"bd-xq7","type":"parent-child","created_at":"2026-02-20T07:52:56.989963517Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1za","title":"[10.11] Add compile-time ambient-authority audit gate for forbidden direct calls in engine security-critical modules.","description":"## Plan Reference\n- **Section**: 10.11 item 2 (FrankenSQLite-Inspired Runtime Systems Track)\n- **9G Cross-ref**: 9G.1 — Capability-context-first runtime (Cx threading)\n- **Top-10 Links**: #2 (Probabilistic Guardplane), #7 (Capability lattice + typed policy DSL)\n\n## What\nAdd a compile-time ambient-authority audit gate that statically detects and rejects forbidden direct calls (raw syscalls, unmediated I/O, global state mutation) in engine security-critical modules. This ensures that no code path in security-critical crates can bypass the capability-profile system defined in bd-1i2.\n\n## Detailed Requirements\n1. Define an `#[ambient_authority_forbidden]` module-level or crate-level attribute (or equivalent lint configuration) that marks security-critical Rust modules.\n2. Enumerate the forbidden-call set: direct `std::fs`, `std::net`, `std::process`, raw libc syscall wrappers, global mutable statics, `unsafe` blocks that access external state without capability witness parameters.\n3. Implement a custom Rust lint (via `clippy` plugin, `dylint`, or `cargo-vet`-style static analysis pass) that scans annotated modules and fails the build if any forbidden call pattern is detected.\n4. The lint must produce actionable diagnostics: exact call site, forbidden API, suggested capability-mediated alternative.\n5. Allowlist mechanism: specific call sites may be exempted with `#[ambient_authority_exemption(reason = \"...\", witness = \"...\")]` annotations that require a human-readable reason and link to a signed exemption artifact.\n6. All exemptions must be tracked in a machine-readable exemption registry (TOML/JSON) committed alongside the crate, so exemption drift is auditable.\n7. CI integration: the audit gate must run as a mandatory CI check; builds with new unexempted forbidden calls must fail.\n\n## Rationale\nCompile-time prohibition of ambient authority is the strongest form of the 9G.1 contract. Runtime checks (bd-1i2) catch dynamic violations, but compile-time gates prevent them from ever reaching runtime. This directly supports Section 8.4.3 invariant #1 (Cx capability threading required at every effectful boundary) and Section 4 (no ambient authority). Without this gate, developers can accidentally introduce direct I/O calls that silently circumvent the entire capability and IFC architecture.\n\n## Testing Requirements\n- **Unit tests**: Provide positive test cases (modules with only capability-mediated calls that pass the lint) and negative test cases (modules with forbidden direct calls that fail the lint). Use `trybuild` or snapshot-based lint testing.\n- **Exemption tests**: Verify that exempted call sites pass the lint, that removing the exemption causes failure, and that the exemption registry stays in sync.\n- **Integration tests**: Add a CI integration test that introduces a deliberate forbidden call in a test module and confirms the build fails with the expected diagnostic.\n- **Logging/observability**: Lint output must include structured fields: `module_path`, `forbidden_api`, `call_site_file`, `call_site_line`, `suggested_alternative`.\n- **Reproducibility**: The lint must produce deterministic output (sorted findings, stable ordering) for identical source inputs.\n\n## Implementation Notes\n- Consider `dylint` for custom lint implementation as it supports crate-specific linting rules without modifying upstream clippy.\n- The forbidden-call set should be data-driven (loaded from a configuration file) so it can be extended as new ambient-authority patterns are discovered.\n- Start with `franken-engine` and `franken-extension-host` security-critical modules; expand scope incrementally.\n- Coordinate with bd-1i2 (capability profiles) to ensure the suggested alternatives reference the correct profile-mediated APIs.\n\n## Dependencies\n- Depends on: bd-1i2 (capability profiles must exist so the lint can suggest alternatives).\n- Blocks: All security-critical module development benefits from this gate being active early.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:33.438713877Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.913735986Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-1ze","title":"[10.9] Release gate: official Node/Bun comparison harness is delivered with reproducible benchmark artifacts and publishable methodology (implementation ownership: `10.12` + section `14`).","description":"## Plan Reference\nSection 10.9, item 1 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that the official Node/Bun comparison harness -- built by the Frontier Programs track (10.12) and the Benchmark Infrastructure track (Section 14) -- meets the publishable-quality bar required before FrankenEngine can credibly claim performance parity or superiority against incumbent runtimes.\n\nThe gate owner does not build the harness; the gate owner confirms that the delivered harness satisfies methodology, reproducibility, and disclosure requirements sufficient for external audit.\n\n## Gate Criteria\n1. The harness executes an agreed-upon benchmark corpus (micro, macro, startup, throughput, memory) against Node LTS and Bun stable on identical hardware/OS configurations with pinned dependency manifests.\n2. Results are deterministic within a stated tolerance band (e.g., CV < 3% across 30 runs per benchmark).\n3. Methodology document is publishable: benchmark selection rationale, warm-up policy, GC/JIT settling strategy, and statistical treatment are explicit and peer-reviewable.\n4. Artifact bundle includes: raw timing data, environment fingerprint (CPU, OS, kernel, runtime versions, flags), run manifest with reproducibility lock, and a one-command replay script.\n5. No benchmark-specific shortcuts (e.g., benchmark-sniffing optimizations) are present in the measured engine configuration; the harness runs against the same binary/config shipped to users.\n6. Comparison results feed the disruption scorecard (bd-6pk) `performance_delta` dimension with machine-readable deltas.\n\n## Implementation Ownership\n- **10.12 (Frontier Programs):** Builds the harness runtime, benchmark selection, execution framework, and CI integration.\n- **Section 14 (Benchmark Infrastructure):** Provides the shared benchmark corpus definitions, hardware provisioning, and statistical analysis tooling.\n- **10.9 (this gate):** Validates completeness, reproducibility, and publishability of the delivered artifacts.\n\n## Rationale\nFrankenEngine's credibility as a category-shifting runtime depends on transparent, reproducible performance claims. A comparison harness that cannot be independently replayed or whose methodology is opaque undermines the entire moonshot narrative. This gate ensures the bar is met before any public performance claims are attached to a release.\n\nRelated 9F moonshots: Adversarial Benchmark, Autopilot Perf Scientist, SLO-Proven Scheduler.\n\n## Verification Requirements\n- **Reproducibility audit:** An independent operator (not the harness author) must replay the full benchmark suite from the artifact bundle and obtain results within the stated tolerance band.\n- **Methodology review:** At least one reviewer confirms the methodology document covers selection rationale, statistical treatment, and known limitations.\n- **Scorecard integration:** Verify that harness output is consumed by the disruption scorecard pipeline and correctly populates `performance_delta`.\n- **Regression anchor:** The harness must be wired into CI so that future commits that regress beyond a threshold are flagged automatically.\n- **Structured logging:** Harness runs emit structured logs with fields: `trace_id`, `benchmark_id`, `runtime`, `variant`, `outcome`, `wall_time_ns`, `memory_peak_bytes`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate output feeds scorecard `performance_delta`.\n- 10.12 Frontier Programs track -- delivers the harness implementation.\n- Section 14 Benchmark Infrastructure -- delivers corpus definitions and statistical tooling.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:27.698421336Z","created_by":"ubuntu","updated_at":"2026-02-20T07:56:50.694748595Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-2031","title":"[13] fleet quarantine convergence meets published SLOs under partition/fault injection drills","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: fleet quarantine convergence meets published SLOs under partition/fault injection drills\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:23.024374212Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.182439715Z","closed_at":"2026-02-20T07:39:59.083570947Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-20b","title":"[10.2] Define typed execution-slot registry and ABI contract for slot replacement (`slot_id`, semantic boundary, authority envelope, promotion status).","description":"## Plan Reference\nSection 10.2, item 7. Cross-refs: 9I.6 (Verified Self-Replacement Architecture), 10.15 (self-replacement schema, delegate-cell harness, promotion gates).\n\n## What\nDefine the typed execution-slot registry that enables the Verified Self-Replacement Architecture. Each slot is a replaceable runtime component that can run either native Rust cells or explicitly untrusted delegate cells.\n\n## Detailed Requirements\n- Define slot_id: unique identifier for each replaceable runtime component\n- Define semantic boundary: what each slot does (parser, IR lowering, optimizer, interpreter, hostcall dispatch, etc.)\n- Define authority envelope: what capabilities each slot requires and is permitted\n- Define promotion status: current state (delegate/native, promotion candidate, promoted, demoted)\n- ABI contract: deterministic interface between slot and runtime, so swapping implementations is seamless\n- Registry must track: current implementation digest, promotion lineage, rollback targets\n\n## Rationale\nSection 9I.6: 'Build the runtime as typed execution slots that can run either native Rust cells or explicitly untrusted delegate cells, then continuously replace delegates with native cells via cryptographically signed promotion gates until GA lanes are fully native.' This converts the hardest part of the program (full ES2020-native execution) into an incremental, evidence-backed convergence process. The slot registry is the foundation that makes this possible.\n\n## Testing Requirements\n- Unit tests: register slots, verify slot_id uniqueness\n- Unit tests: verify ABI contract compatibility between native and delegate implementations\n- Unit tests: verify promotion status transitions (delegate → candidate → promoted)\n- Unit tests: verify rollback from promoted back to previous implementation\n- Integration tests: swap slot implementation at runtime, verify behavior preservation\n\n## Dependencies\n- Blocked by: nothing (foundational design)\n- Blocks: interpreter skeleton (bd-2f8), delegate-cell harness (10.15), promotion gate runner (10.15)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:22.203314107Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.440977464Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-20c","title":"[10.0] Top-10 #1: TS-first capability-typed IR execution (strategy: `9A.1`; deep semantics: `9F.4`; execution owners: `10.2`, `10.5`, `10.12`).","description":"## Plan Reference\nSection 10.0 item 1. Strategy: 9A.1. Deep semantics: 9F.4 (Capability-Typed TS Execution Contract). Enhancement maps: 9B.1 (typestate/session types/algebraic effects), 9C.1 (proof-carrying compilation), 9D.1 (compilation benchmark suite).\n\n## What\nStrategic tracking bead for Initiative #1: TS-first authoring → native capability-typed IR execution. Extension developers keep JS/TS ergonomics and ecosystem velocity, but execution moves onto a native IR that explicitly carries capability intent, effect boundaries, and host interaction metadata.\n\n## Execution Owners\n- **10.2** (VM Core): parser trait, multi-level IR contract (IR0-IR4), lowering pipelines, IFC flow-lattice in IR2, proof-to-specialization linkage in IR3/IR4\n- **10.5** (Extension Host + Security): runtime capability enforcement, flow-label propagation\n- **10.12** (Frontier Programs): proof-carrying adaptive optimizer, translation-validation gates\n\n## Strategic Rationale (from 9A.1)\n'This gives high contributor throughput without surrendering runtime control to opaque third-party engine behavior. The rationale is to preserve rapid iteration and broad contributor participation while making security and performance constraints enforceable by the runtime itself, not by conventions.'\n\n## Key Deliverables\n- Capability-typed IR with explicit effect annotations (fs.read, net.connect, proc.spawn, policy.request)\n- Capability lattice checks during lowering and optimization\n- Ambiguous authority paths and ambient side effects rejected before execution\n- Runtime verifies capability proofs and executes only within declared contracts\n\n## Phase Gates\n- Phase A: native execution lanes pass baseline conformance\n- Phase B: security subsystems (capability enforcement) active\n- Phase C: >= 3x performance with capability-typed execution\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:19.238167621Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.363148739Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-20xc","title":"[14] Build benchmark reproducibility infrastructure and third-party verification pipeline.","description":"## Plan Reference\nSection 14.3: Reproducibility + Neutral Verification\nSection 13: At least 2 independent third parties reproduce core benchmark claims\n\n## What\nBuild the infrastructure that enables external parties to independently verify benchmark claims. This includes manifest generation, artifact packaging, verification tooling, and publication workflow.\n\n## Components\n1. **Full run manifest generator**: Captures hardware, kernel, runtime versions, flags, dataset checksums, seed transcripts, harness commit IDs\n2. **Artifact packaging**: Creates self-contained verification bundles that can be shared externally\n3. **Verification pipeline**: Automated comparison of reproduced results against published claims\n4. **Publication workflow**: Gated pipeline requiring all prerequisites before claim can be published externally\n5. **frankensqlite integration**: Store result ledgers with versioned schemas\n6. **frankentui dashboards**: Operator triage and replay dashboards for benchmark results\n\n## Verification Requirements\n- Publish native-coverage progression alongside benchmark releases\n- Per-slot replacement lineage IDs tied to concrete replacement state\n- Version-stamped benchmark specification with migration notes for spec changes\n- Include both performance AND security co-metrics (not speed-only)\n\n## Testing Requirements\n- E2E test: generate manifest, package artifacts, run verification, confirm match\n- Test: tampered artifacts are detected by verification pipeline\n- Test: spec version mismatch is detected and reported\n- Test: incomplete manifests are rejected with clear error messages\n\n## Rationale\nCategory leadership requires defining the scoreboard (Section 14 preamble). External adoption requires trust, which requires rock-solid reproducibility.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.\n\n## Scope Boundary\\nThis bead focuses on external reproducibility operations (artifact plumbing, verifier workflow, third-party replay pipeline) and should build on existing harness/spec outputs.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:42:27.934805899Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.689941763Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["benchmark","detailed","plan","reproducibility","section-14","verification"],"dependencies":[{"issue_id":"bd-20xc","depends_on_id":"bd-2wpo","type":"blocks","created_at":"2026-02-20T07:56:09.300428140Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20xc","depends_on_id":"bd-mhz4","type":"blocks","created_at":"2026-02-20T07:56:09.221317097Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-21ds","title":"[14] Public Benchmark + Standardization Strategy - Comprehensive Execution Epic","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nPurpose: Operationalize this section's governance/validation/adoption requirements into enforceable engineering work.\nQuality requirements for all children:\n- explicit acceptance criteria and failure semantics\n- unit-test and e2e/integration verification expectations\n- detailed structured logging and reproducibility artifacts where applicable\n- traceability back to category-level goals (security, performance, explainability, adoption)\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:34:15.545871282Z","created_by":"ubuntu","updated_at":"2026-02-20T07:53:36.172431960Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-14"],"dependencies":[{"issue_id":"bd-21ds","depends_on_id":"bd-1401","type":"parent-child","created_at":"2026-02-20T07:52:42.738587819Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-14da","type":"parent-child","created_at":"2026-02-20T07:52:42.778284207Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-1dxl","type":"parent-child","created_at":"2026-02-20T07:52:43.839916807Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-1npj","type":"parent-child","created_at":"2026-02-20T07:52:45.179144385Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-1pqn","type":"parent-child","created_at":"2026-02-20T07:52:45.416022883Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-1tsf","type":"blocks","created_at":"2026-02-20T07:34:38.009455236Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-1xva","type":"parent-child","created_at":"2026-02-20T07:52:46.109438265Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-1y63","type":"parent-child","created_at":"2026-02-20T07:52:46.189465223Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-20xc","type":"parent-child","created_at":"2026-02-20T07:53:36.172365947Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-23br","type":"parent-child","created_at":"2026-02-20T07:52:46.518976599Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-24rp","type":"parent-child","created_at":"2026-02-20T07:52:46.679273797Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-27tk","type":"parent-child","created_at":"2026-02-20T07:52:47.038294007Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-2amp","type":"parent-child","created_at":"2026-02-20T07:52:47.423198107Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-2k6v","type":"parent-child","created_at":"2026-02-20T07:52:48.295598665Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-2knu","type":"parent-child","created_at":"2026-02-20T07:52:48.334579281Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-2qqv","type":"parent-child","created_at":"2026-02-20T07:52:49.071197472Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-2u5e","type":"parent-child","created_at":"2026-02-20T07:52:49.823701031Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-2wpo","type":"parent-child","created_at":"2026-02-20T07:52:50.064214400Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-2ytn","type":"parent-child","created_at":"2026-02-20T07:52:50.499528524Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-37zd","type":"parent-child","created_at":"2026-02-20T07:52:51.345962878Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-3db2","type":"parent-child","created_at":"2026-02-20T07:52:51.905283656Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-3de4","type":"parent-child","created_at":"2026-02-20T07:52:51.944636815Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-3h31","type":"parent-child","created_at":"2026-02-20T07:52:52.282551253Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-3h61","type":"parent-child","created_at":"2026-02-20T07:52:52.322172762Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-62mo","type":"parent-child","created_at":"2026-02-20T07:52:54.661823103Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-70bx","type":"parent-child","created_at":"2026-02-20T07:52:54.781325879Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-a5xc","type":"parent-child","created_at":"2026-02-20T07:52:55.113419064Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-anuw","type":"parent-child","created_at":"2026-02-20T07:52:55.234897950Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-c1co","type":"blocks","created_at":"2026-02-20T07:34:38.497452660Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-fp53","type":"parent-child","created_at":"2026-02-20T07:52:55.716820457Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-mhz4","type":"parent-child","created_at":"2026-02-20T07:53:36.121688796Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-ye6k","type":"parent-child","created_at":"2026-02-20T07:52:57.029403859Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ds","depends_on_id":"bd-zze6","type":"parent-child","created_at":"2026-02-20T07:52:57.290828667Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-21ul","title":"[12] Maintain program risk register with active countermeasures and review cadence.","description":"## Plan Reference\nSection 12: Risk Register\n\n## What\nMaintain a living risk register document tracking program-level risks with active countermeasures. This is a monitoring/governance artifact, not a one-time implementation task.\n\n## Identified Risks and Countermeasures\n\n### 1. Scope explosion\n- **Countermeasure**: Strict phase gates (A/B/C/D/E) and one-lever optimization discipline from Section 5.1\n- **Monitor**: Track scope additions vs. phase gate progress monthly\n\n### 2. False confidence from heuristic security\n- **Countermeasure**: Bayesian + sequential testing (e-process) + calibration audits (Section 6.4-6.5)\n- **Monitor**: Track calibration metrics, false-positive/negative rates on adversarial corpora\n\n### 3. Performance regressions from over-hardening\n- **Countermeasure**: Profile-driven optimization and tail-latency budgets (Section 7)\n- **Monitor**: p95/p99 regression CI gates, overhead budget per security subsystem\n\n### 4. Operational complexity\n- **Countermeasure**: Evidence-ledger tooling and deterministic fallback mode (Section 8.6)\n- **Monitor**: Operator burden metrics, fallback activation frequency\n\n### 5. Delegate-path entrenchment (temporary bridge becomes permanent)\n- **Countermeasure**: Hard GA 0-delegate gate for core slots (Section 8.8), signed replacement-lineage requirements, explicit closure obligations with ownership\n- **Monitor**: Native coverage percentage, time-since-last-promotion per slot\n\n### 6. IFC policy over-constraint causing false denies on benign integrations\n- **Countermeasure**: Static-first analysis, shadow-mode rollout, explicit declassification workflows, profile-guided label-granularity tuning (Section 6.9)\n- **Monitor**: False-deny rates on benign extension corpora, declassification request volume\n\n### 7. Stale/invalid security proofs causing unsound specialization\n- **Countermeasure**: Epoch-bound proof validity (Section 8.9), mandatory specialization invalidation on proof churn, fail-closed fallback to unspecialized paths\n- **Monitor**: Proof invalidation rate, specialization fallback frequency\n\n## Review Cadence\n- Weekly: check risk indicators against thresholds\n- Per-phase-gate: full risk register review with updated status\n- Per-incident: add new risks discovered during incidents\n\n## Testing Requirements\n- Validate risk register schema (all risks have countermeasure, monitor, owner)\n- CI check that risk register is updated when phase gates are crossed\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.\n\n## Scope Boundary\\nThis bead is the live risk-register integration and review-cadence gate that aggregates and tracks risk-countermeasure status from Section 12 risk items.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:24.951932623Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.754245768Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","governance","plan","risk","section-12"],"dependencies":[{"issue_id":"bd-21ul","depends_on_id":"bd-15vm","type":"blocks","created_at":"2026-02-20T07:56:09.539662481Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ul","depends_on_id":"bd-1blo","type":"blocks","created_at":"2026-02-20T07:56:09.419607084Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ul","depends_on_id":"bd-1md2","type":"blocks","created_at":"2026-02-20T07:56:09.716440721Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ul","depends_on_id":"bd-256n","type":"blocks","created_at":"2026-02-20T07:56:09.597562797Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ul","depends_on_id":"bd-27ks","type":"blocks","created_at":"2026-02-20T07:56:09.477346250Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ul","depends_on_id":"bd-37go","type":"blocks","created_at":"2026-02-20T07:56:09.658497064Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-21ul","depends_on_id":"bd-51gj","type":"blocks","created_at":"2026-02-20T07:56:09.358878971Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-23br","title":"[14] Scale profiles per family (each required): `S`, `M`, `L` with fixed extension counts, event rates, dependency graph sizes, and policy complexity tiers.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Scale profiles per family (each required): `S`, `M`, `L` with fixed extension counts, event rates, dependency graph sizes, and policy complexity tiers.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:28.977678111Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.345044802Z","closed_at":"2026-02-20T07:41:21.424004164Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-23om","title":"[10.13] Introduce a narrow control-plane adapter layer in `franken_engine` that imports `franken-kernel`/`franken_kernel`, `franken-decision`/`franken_decision`, and `franken-evidence`/`franken_evidence` without pulling broad runtime internals into VM hot paths.","description":"# Introduce Narrow Control-Plane Adapter Layer\n\n## Plan Reference\nSection 10.13, Item 4.\n\n## What\nCreate a thin adapter module within `franken_engine` that serves as the sole import boundary for `franken_kernel`, `franken_decision`, and `franken_evidence` crates. This adapter re-exports only the control-plane surface needed by the extension-host subsystem, ensuring asupersync internals do not leak into VM hot paths.\n\n## Detailed Requirements\n- **Integration/binding nature**: This bead does not implement control-plane logic. It creates a narrow gateway that imports 10.11-owned primitives from asupersync crates and exposes them to FrankenEngine's extension-host code through a curated, minimal API surface.\n- The adapter module (e.g., `src/control_plane/mod.rs` or `src/cp_adapter/mod.rs`) must:\n  - Import `Cx`, `Budget`, `TraceId` from `franken_kernel`.\n  - Import `DecisionId`, `PolicyId`, decision contract traits from `franken_decision`.\n  - Import `SchemaVersion`, evidence emission traits from `franken_evidence`.\n  - Re-export only the types and traits needed by extension-host APIs; do not re-export crate internals.\n- The adapter must NOT pull broad runtime internals (e.g., VM execution engine types, JIT compiler types) into its dependency graph.\n- Add `#[cfg(test)]` mock implementations of the adapter traits for unit testing extension-host code in isolation.\n- Document the adapter's API surface in module-level rustdoc.\n- The adapter boundary must be enforceable: no extension-host module may `use franken_kernel::*` directly; all imports must go through the adapter.\n\n## Rationale\nWithout a narrow adapter, every extension-host module would depend directly on asupersync crate internals, creating a wide coupling surface. Changes in asupersync would ripple unpredictably through FrankenEngine. The adapter localizes this coupling to a single module, making upgrades predictable and keeping VM hot paths free of control-plane dependencies.\n\n## Testing Requirements\n- Compile-time test: verify that removing the adapter's re-exports causes extension-host modules to fail compilation (proving they depend on the adapter, not direct imports).\n- Dependency graph test: `cargo tree` or `cargo depgraph` check verifying that VM hot-path crates do not transitively depend on `franken_decision` or `franken_evidence`.\n- Unit tests for mock adapter implementations.\n\n## Implementation Notes\n- **10.11 primitive ownership**: All types and traits exposed through the adapter originate in 10.11-owned crates. The adapter is a FrankenEngine-side integration artifact.\n- The adapter is referenced by nearly every subsequent 10.13 bead (Cx threading, region integration, cancellation, evidence emission, etc.).\n- Coordinate with bd-1rdj (benchmark split) to verify the adapter does not introduce measurable overhead in the hot path.\n\n## Dependencies\n- Depends on bd-3vlb (ADR establishing canonical sources) and bd-2fa1 (dependency policy ensuring no local forks).\n- Depended upon by bd-2ygl, bd-1ukb, bd-2wz9, bd-m9pa, bd-3a5e, bd-uvmm, and most other 10.13 integration beads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:42.140285490Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.957155659Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-24bu","title":"[10.13] Make `frankenlab replay` and deterministic scenario pass/fail outputs release blockers for security-critical paths.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Make `frankenlab replay` and deterministic scenario pass/fail outputs release blockers for security-critical paths.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:43.592729712Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.513109414Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-24ie","title":"[10.15] Add burn-in gate: no auto-enforcement promotion without shadow success rate, false-deny envelope, and rollback proof artifacts meeting threshold.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add burn-in gate: no auto-enforcement promotion without shadow success rate, false-deny envelope, and rollback proof artifacts meeting threshold.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:51.833560760Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.726309014Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-24rp","title":"[14] Publish native-coverage progression and per-slot replacement lineage IDs alongside benchmark releases so performance claims are tied to concrete replacement state.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Publish native-coverage progression and per-slot replacement lineage IDs alongside benchmark releases so performance claims are tied to concrete replacement state.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:32.602455317Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.508206866Z","closed_at":"2026-02-20T07:41:19.881879549Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2501","title":"[16] Deliver scientific contribution targets and publishable research artifacts.","description":"## Plan Reference\nSection 16: Scientific Contribution Targets\n\n## What\nFrankenEngine is also a research-producing engineering program. Each major novelty should produce reusable scientific/technical artifacts. This bead tracks all scientific contribution obligations.\n\n## Required Contributions\n1. **Open specifications**: Core trust/replay/policy primitives published as open specs for community adoption\n2. **Reproducible datasets**: Incident replay and adversarial campaign evaluation datasets with deterministic reproduction guarantees\n3. **Reference proofs**: Proof sketches or formal proofs for key policy and protocol safety claims (e.g., IFC confinement, capability monotonicity, revocation precedence)\n4. **External evaluations**: Red-team and academic-style evaluations with published methodology, not just internal validation\n5. **Technical reports**: Public reports documenting failures, fixes, and measured frontier movement (not just successes)\n\n## Output Contract (Hard Requirements)\n- At least 4 publishable technical reports with reproducible artifact bundles\n- At least 2 externally replicated high-impact claims (e.g., 3x performance, containment latency SLOs)\n- At least 1 open benchmark or verification tool release adopted outside the project\n\n## Rationale\nFrom the plan: 'FrankenEngine is also a research-producing engineering program.' This means the project must contribute to the broader security/runtime research community, not just ship product. External validation through independent replication and academic evaluation strengthens category claims and builds credibility. Public failure documentation demonstrates intellectual honesty and builds trust.\n\n## Dependencies\n- Requires benchmark suite (10.6, Section 14) for replicable performance claims\n- Requires adversarial corpus (10.7, 10.12) for reproducible security datasets\n- Requires IFC/PLAS proofs (10.15) for formal safety claim artifacts\n- Requires decision receipt infrastructure (10.12) for trust/replay specification publication\n\n## Testing Requirements\n- Validation that each technical report artifact bundle is self-contained and reproducible (run on clean environment)\n- Test that open specifications pass conformance vector suites from Section 10.10\n- Test that reproducible datasets produce deterministic outputs when replayed\n- Verification that external evaluation methodology documents include complete reproduction instructions\n\n## Implementation Notes\n- Technical reports should follow alien-artifact-coding discipline (Section 5.2): every claim ships with proof artifacts\n- Reports should cover both successes AND failures per plan requirement\n- External evaluations should be coordinated with the partner program from Section 15\n- Open benchmark tools should be packaged for independent installation and execution\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.\n\n## Scope Boundary\\nThis bead is the section-level scientific-output umbrella linking publishable artifacts, replication evidence, and external validation outputs from Section 16 work.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:20.310689800Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.597794778Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["artifacts","detailed","plan","publications","research","scientific","section-16"]}
{"id":"bd-256n","title":"[12] Prevent delegate-path entrenchment with GA zero-delegate gate and signed replacement-lineage obligations","description":"Plan Reference: section 12 (Risk Register).\nObjective: Delegate-path entrenchment (temporary bridge becomes permanent):\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:18.382010256Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.549087671Z","closed_at":"2026-02-20T07:39:04.634752198Z","close_reason":"Consolidated into single risk register tracking bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-12"]}
{"id":"bd-25b7","title":"[10.15] Publish PLAS benchmark bundle reporting over-privilege ratio, policy authoring-time reduction, false-deny rates, and escrow-event rates across representative extension cohorts.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Publish PLAS benchmark bundle reporting over-privilege ratio, policy authoring-time reduction, false-deny rates, and escrow-event rates across representative extension cohorts.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:51.999575373Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.678118743Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-25sh","title":"[13] Track and validate program success criteria (acceptance gates).","description":"## Plan Reference\nSection 13: Program Success Criteria\n\n## Purpose\nThis epic tracks ALL program-level success criteria from the plan. These are NOT implementation tasks - they are acceptance gates that must be satisfied by the implementation beads in sections 10.x. Each criterion should be linked to the implementation bead(s) that satisfy it.\n\n## Success Criteria Checklist\n\n### Core Runtime\n- [ ] Native execution lanes run without external engine bindings (10.2)\n- [ ] franken_node composes those lanes for practical runtime usage (Phase D)\n- [ ] ES2020 runtime conformance is demonstrably complete per test262 gate and waiver policy (10.7)\n\n### Security\n- [ ] Untrusted extension code is actively monitored and auto-contained under attack scenarios (10.5)\n- [ ] Red-team programs show >= 10x reduction in successful host compromise vs baseline Node/Bun (Phase B gate)\n- [ ] High-risk detections reach containment in <= 250ms median time (Phase B gate)\n- [ ] Unauthorized sensitive-source -> external-sink flows are deterministically blocked unless explicit declassification approved (10.15/IFC)\n- [ ] >= 99% of declassification decisions emit signed receipt-linked replay artifacts (10.15)\n- [ ] Data-confinement claims are machine-verifiable from evidence/provenance artifacts (10.15)\n\n### Determinism & Replay\n- [ ] Deterministic replay coverage is 100% for high-severity decisions (10.5, 10.11, 10.13)\n- [ ] All high-impact safety actions executed through decision contracts and emitted through canonical evidence ledgers (10.13)\n- [ ] Extension lifecycle transitions satisfy request -> drain -> finalize protocol invariants (10.11, 10.13)\n- [ ] Release gates include deterministic frankenlab scenario replay (10.13)\n\n### Performance\n- [ ] Extension-heavy benchmark suites show >= 3x weighted-geometric-mean throughput vs Node AND Bun (Section 14 denominator)\n- [ ] Security and performance claims are artifact-backed and reproducible (10.6, 10.8)\n- [ ] Proof-carrying optimization path enabled by default for >= 1 high-impact family (10.12)\n- [ ] Proof-specialized lanes show measurable improvement vs ambient-authority lanes (10.15)\n- [ ] 100% of activated proof-specializations carry signed receipts (10.15)\n\n### Control Plane & Integration\n- [ ] Control-plane identifiers canonicalized through asupersync-derived types (10.13)\n- [ ] All advanced operator TUI surfaces delivered through frankentui (10.14)\n- [ ] All SQLite-backed persistence delivered through frankensqlite (10.14)\n- [ ] Service/API surfaces leverage fastapi_rust where applicable (10.14)\n- [ ] Cross-repo conformance lab is a hard release gate (10.15)\n\n### Fleet & Ecosystem\n- [ ] Fleet quarantine convergence meets published SLOs under fault injection (10.12)\n- [ ] Secure extension reputation graph drives measurable reduction in first-time compromise windows (10.12)\n- [ ] At least 3 beyond-parity capabilities in production with evidence (Phase D)\n- [ ] At least 2 independent third parties reproduce core benchmark claims (Section 14)\n- [ ] Category benchmark standard adopted by external participants (Section 14)\n\n### Governance & Trust\n- [ ] >= 95% of high-impact decision receipts include valid attestation bindings (10.15)\n- [ ] Privacy-preserving fleet learning operates with zero budget-overrun incidents (10.15)\n- [ ] Moonshot portfolio governor enforces promote/hold/kill gates with 100% artifact completeness (10.15)\n- [ ] PLAS produces signed capability_witness for >= 90% of targeted extension cohorts (10.15)\n- [ ] Synthesized capability envelopes achieve <= 1.10 over-privilege ratio (10.15)\n- [ ] Manual policy-authoring time reduced by >= 70% (10.15)\n- [ ] Post-burn-in false-deny rate <= 0.5% on benign corpora (10.15)\n- [ ] 100% of capability escrow/emergency-grant decisions emit receipt-linked replay artifacts (10.15)\n- [ ] Every promoted delegate->native core slot has signed replacement receipt (10.15)\n- [ ] GA default lanes run with zero mandatory delegate cells (10.15)\n\n## Validation Process\nEach criterion gets checked off only when:\n1. The implementing bead(s) are complete\n2. Evidence artifacts exist proving the criterion\n3. Independent validation has been performed where specified","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:41:05.696299100Z","created_by":"ubuntu","updated_at":"2026-02-20T07:56:08.911498594Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["acceptance","detailed","governance","plan","release-gate","section-13"]}
{"id":"bd-26f","title":"[10.10] Define revocation object chain (`revocation`, `revocation_event`, `revocation_head`) with monotonic head sequence.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Define revocation object chain (`revocation`, `revocation_event`, `revocation_head`) with monotonic head sequence.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:31.382960973Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.190976112Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-26i","title":"[10.11] Require deterministic ordering/stability for evidence entries (candidate sort, witness ids, bounded size policy).","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Require deterministic ordering/stability for evidence entries (candidate sort, witness ids, bounded size policy).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:34.933341113Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.458186776Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-26o","title":"[10.10] Add conformance suite for canonical serialization, ID derivation, signatures, revocation freshness, and epoch ordering.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Add conformance suite for canonical serialization, ID derivation, signatures, revocation freshness, and epoch ordering.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:32.547823652Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.860349206Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-26qa","title":"[10.14] Add an ADR for `/dp/fastapi_rust` reuse scope across FrankenEngine service/API control surfaces.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Add an ADR for `/dp/fastapi_rust` reuse scope across FrankenEngine service/API control surfaces.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:46.189371169Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.348533460Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-27i1","title":"[10.15] Add automatic demotion/rollback mechanism when post-promotion divergence or risk-threshold breaches are detected.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add automatic demotion/rollback mechanism when post-promotion divergence or risk-threshold breaches are detected.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:54.577647962Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.951993299Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-27ks","title":"[12] Prevent over-hardening performance regressions with profile-driven optimization and tail-latency budgets","description":"Plan Reference: section 12 (Risk Register).\nObjective: Performance regressions from over-hardening:\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:17.965796863Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.859758754Z","closed_at":"2026-02-20T07:39:04.832961058Z","close_reason":"Consolidated into single risk register tracking bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-12"]}
{"id":"bd-27tk","title":"[14] Store benchmark artifacts and result ledgers via `/dp/frankensqlite` contracts; provide operator triage and replay dashboards through `/dp/frankentui`.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Store benchmark artifacts and result ledgers via `/dp/frankensqlite` contracts; provide operator triage and replay dashboards through `/dp/frankentui`.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:31.868363217Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.900583785Z","closed_at":"2026-02-20T07:41:20.198493760Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-289","title":"[10.11] Add global bulkheads for remote in-flight operations and background maintenance concurrency.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add global bulkheads for remote in-flight operations and background maintenance concurrency.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:36.993267561Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.807236305Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-28fe","title":"[13] all high-impact safety actions are executed through decision contracts and emitted through canonical evidence ledgers","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: all high-impact safety actions are executed through decision contracts and emitted through canonical evidence ledgers\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:21.295029573Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:31.982177Z","closed_at":"2026-02-20T07:39:59.901373391Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-28m","title":"[10.10] Extend capability token format with audience, expiry/nbf, jti, checkpoint binding, and revocation freshness binding.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Extend capability token format with audience, expiry/nbf, jti, checkpoint binding, and revocation freshness binding.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:30.256356827Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.529855499Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-29a1","title":"[10.15] Emit randomness transcript commitments and seed-hash evidence for stochastic learning phases so downstream replay remains audit-deterministic at snapshot boundaries.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Emit randomness transcript commitments and seed-hash evidence for stochastic learning phases so downstream replay remains audit-deterministic at snapshot boundaries.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:47.986252558Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.862149716Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-29r","title":"[10.10] Implement monotonic message sequence and replay-drop enforcement on session channels.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement monotonic message sequence and replay-drop enforcement on session channels.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:31.098004329Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.277468305Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-29s","title":"[10.10] Add migration contract for explicit cutover boundaries on security-critical formats and policies.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Add migration contract for explicit cutover boundaries on security-critical formats and policies.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:33.128016647Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.690965846Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-29yn","title":"[13] extension lifecycle transitions (`start`, `reload`, `suspend`, `terminate`, `quarantine`, `revoke`) satisfy `request -> drain -> finalize` protocol invariants","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: extension lifecycle transitions (`start`, `reload`, `suspend`, `terminate`, `quarantine`, `revoke`) satisfy `request -> drain -> finalize` protocol invariants\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:21.505227665Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:32.189168681Z","closed_at":"2026-02-20T07:39:59.802594878Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2ag6","title":"[13] compatibility and reliability meet release gates","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: compatibility and reliability meet release gates\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:19.836100523Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:32.230279373Z","closed_at":"2026-02-20T07:40:00.620773504Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2amp","title":"[14] Throughput/latency (`p50`, `p95`, `p99`) under extension-heavy workloads.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Throughput/latency (`p50`, `p95`, `p99`) under extension-heavy workloads.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:32.839566229Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:32.271182689Z","closed_at":"2026-02-20T07:41:19.777047982Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2ao","title":"[10.11] Implement region-quiescence close protocol (`cancel -> drain -> finalize`) for engine and host subsystems.","description":"## Plan Reference\n- **Section**: 10.11 item 4 (FrankenSQLite-Inspired Runtime Systems Track)\n- **9G Cross-ref**: 9G.2 — Cancellation as protocol (request -> drain -> finalize)\n- **Top-10 Links**: #2 (Probabilistic Guardplane), #3 (Deterministic evidence graph + replay), #8 (Per-extension resource budget)\n\n## What\nImplement the region-quiescence close protocol (\\`cancel -> drain -> finalize\\`) as a reusable primitive for engine and host subsystems. Every region (extension execution cell, service subsystem, background task group) must follow this three-phase shutdown protocol to guarantee that no half-applied security operations or dangling obligations survive a close/upgrade/quarantine transition.\n\n## Detailed Requirements\n1. Define a \\`RegionLifecycle\\` trait with three mandatory phase transitions:\n   - \\`cancel(reason: CancelReason)\\`: initiates shutdown; sets cancellation flag, stops accepting new work, emits cancel-requested event.\n   - \\`drain(deadline: Deadline)\\`: allows in-flight work to complete or checkpoint; obligations must resolve to committed/aborted; emits drain-progress events at configurable intervals.\n   - \\`finalize()\\`: asserts all obligations are resolved, all resources are released, all evidence is flushed; emits finalize-complete event. Returns \\`FinalizeResult\\` with success/failure and obligation audit.\n2. Phase ordering is strict and enforced: calling \\`drain\\` before \\`cancel\\` or \\`finalize\\` before \\`drain\\` must return a typed \\`PhaseOrderViolation\\` error.\n3. Drain deadline enforcement: if drain does not complete within the deadline, the runtime escalates to forced finalization with explicit \\`DrainTimeoutEscalation\\` evidence.\n4. Region types that must implement \\`RegionLifecycle\\`:\n   - Extension execution cells (per-extension/session).\n   - Policy controller subsystem.\n   - Remote operation managers.\n   - Background scheduler task groups.\n   - Evidence/telemetry flush subsystems.\n5. Each region must maintain a \\`RegionState\\` machine: \\`Running -> CancelRequested -> Draining -> Finalizing -> Closed\\`. State transitions must be atomic and observable.\n6. Region close must be composable: parent regions close by recursively closing child regions in dependency order (leaves first).\n7. All phase transitions emit structured evidence events suitable for the evidence ledger and deterministic replay.\n\n## Rationale\nThe 9G.2 contract mandates cancellation as a protocol, not a best-effort signal. Without a structured close protocol, quarantine/revocation/suspend actions can leave ghost state (half-committed publications, unreleased locks, unflushed evidence). The three-phase protocol guarantees that shutdown is predictable, auditable, and complete. This is the primitive that 10.13 will integrate into asupersync-constitutional extension lifecycle boundaries (Section 8.4.3 invariant #3).\n\n## Testing Requirements\n- **Unit tests**: Verify correct phase ordering enforcement (phase-order violation errors). Verify drain deadline escalation. Verify obligation audit in finalize result.\n- **Property tests**: Randomly inject cancel/drain/finalize sequences and verify state machine consistency (no illegal transitions, no double-close).\n- **Integration tests**: Create a multi-region hierarchy (parent with 3 child regions), inject cancel at parent level, and verify recursive close in correct dependency order. Verify all evidence events are emitted. Verify no resource leaks via instrumented allocator.\n- **Deterministic replay test**: Record a close sequence in the lab runtime, replay it, and verify identical event sequence.\n- **Logging/observability**: All phase transitions emit: \\`trace_id\\`, \\`region_id\\`, \\`region_type\\`, \\`phase\\`, \\`outcome\\`, \\`obligations_pending\\`, \\`drain_elapsed_ms\\`.\n- **Reproducibility**: Phase transition sequences must be deterministic given identical input event ordering.\n\n## Implementation Notes\n- Implement as a generic \\`Region<S: RegionState>\\` struct that can be parameterized by subsystem-specific state.\n- Use Rust's ownership/drop semantics to enforce that \\`finalize\\` is called before the region is dropped; consider a \\`MustFinalize\\` wrapper that panics on drop if not finalized (aligned with obligation discipline in bd-1bl).\n- The drain deadline should integrate with virtual time in the deterministic lab runtime (bd-121).\n- Keep the primitive subsystem-agnostic; extension-host-specific wiring belongs in 10.13.\n\n## Dependencies\n- Depends on: bd-1i2 (capability profiles for region context), bd-3vg (checkpoint-placement enables drain to progress).\n- Blocks: bd-127 (bounded masking uses region lifecycle), bd-1bl (obligation channels integrate with drain), bd-2gg (supervision tree uses region lifecycle for service restart), 10.13 integration.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:33.737314445Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.822420579Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-2cc8","title":"[16] Public technical reports that document failures, fixes, and measured frontier movement.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: Public technical reports that document failures, fixes, and measured frontier movement.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:36.854316330Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:32.368490615Z","closed_at":"2026-02-20T07:46:43.924248041Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-2che","title":"[13] at least 2 independent third parties reproduce core benchmark claims using published tooling","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: at least 2 independent third parties reproduce core benchmark claims using published tooling\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:22.808934326Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:32.413489068Z","closed_at":"2026-02-20T07:39:59.182490612Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2cq","title":"[10.12] Implement measured attestation handshake between execution cells and runtime policy plane.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Implement measured attestation handshake between execution cells and runtime policy plane.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:39.632636997Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.277162984Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-2d21","title":"[10.14] Define when `/dp/sqlmodel_rust` must be used: typed schema/model workflows with material correctness or migration advantages.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Define when `/dp/sqlmodel_rust` must be used: typed schema/model workflows with material correctness or migration advantages.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:45.705450068Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.471425713Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-2eu","title":"[10.7] Add metamorphic tests for parser/IR/execution invariants.","description":"## Plan Reference\nSection 10.7 (Conformance + Verification), item 4.\nRelated: Phase E (fuzz/property/metamorphic testing), 9A.6 (Shadow-run + differential executor -- metamorphic invariants from formal assurance ladder), 9A.9 (Adversarial security corpus + continuous fuzzing -- metamorphic test suites across parser, policy, hostcall, and containment paths).\n\n## What\nBuild a metamorphic testing framework that validates invariant-preserving transformations across three FrankenEngine subsystem boundaries: parser (source -> AST), IR pipeline (AST -> IR0 -> IR1 -> IR2 -> IR3 -> IR4), and execution (IR -> observable output). Metamorphic relations encode semantic equivalences that must hold regardless of input, catching bugs that conventional example-based tests miss.\n\n## Detailed Requirements\n1. **Metamorphic relation catalog:** Define and maintain a versioned catalog (`metamorphic_relations.toml`) of metamorphic relations organized by subsystem:\n   - **Parser relations:** (a) Whitespace/comment insertion invariance, (b) Parenthesization of already-correctly-precedenced expressions, (c) Semicolon insertion equivalence (ASI-safe transforms), (d) Unicode escape equivalence for identifiers, (e) Source position independence (semantics unchanged by line/column shift).\n   - **IR relations:** (a) Lowering determinism (same AST -> identical IR byte sequence), (b) Optimization idempotence (optimize(optimize(IR)) == optimize(IR) modulo debug metadata), (c) Capability preservation across lowering (IR2 capability set is superset-closed through IR3/IR4), (d) Dead-code insertion invariance (adding unreachable code does not change observable IR output), (e) Constant folding equivalence.\n   - **Execution relations:** (a) Evaluation order determinism (same program -> same observable side-effect sequence), (b) GC-timing independence (observable output unchanged across GC scheduling variations), (c) Stack-depth independence (same result whether stack limit is 100 or 10000 frames, for programs within both limits), (d) Prototype chain equivalence (equivalent prototype setups yield identical property resolution), (e) Promise resolution order stability.\n2. **Generator infrastructure:** For each relation, implement a source-program generator (property-based, using a structured grammar fuzzer) that produces (input, metamorphic_variant) pairs. Generators must be seeded for reproducibility.\n3. **Oracle:** The oracle for each relation is structural or output equality (configurable per relation: AST equality, IR equality, canonicalized-output equality, or side-effect-trace equality). Equality comparators must handle normalization (e.g., source positions stripped for parser invariance checks).\n4. **Execution budget:** Each CI run exercises a configurable number of metamorphic pairs per relation (default: 1000). Budget is tracked per relation to ensure coverage breadth.\n5. **Failure minimization:** When a metamorphic violation is detected, the framework applies delta-debugging to produce a minimal (input, variant) pair that still exhibits the violation. Minimized failures are serialized as `metamorphic_failure_{relation}_{hash}.json` with fields: `relation_id`, `seed`, `input_source`, `variant_source`, `expected_equivalence`, `actual_divergence`, `minimized`.\n6. **Structured logging:** Per-relation log: `trace_id`, `relation_id`, `subsystem`, `pairs_tested`, `violations_found`, `min_failure_size`, `duration_us`.\n7. **Evidence artifact:** Produce `metamorphic_evidence.jsonl` with per-relation statistics, overall violation count, relation catalog hash, seed, and environment fingerprint.\n8. **CI gate:** Any metamorphic violation blocks CI. Zero-violation policy with no suppression mechanism (if a relation is wrong, fix the relation definition, not the gate).\n\n## Rationale\nMetamorphic testing is uniquely suited to compilers and runtimes where the \"correct output\" for arbitrary inputs is unknown, but semantic invariants across transformations are well-defined. The plan explicitly calls for metamorphic testing across parser, policy, hostcall, and containment paths (9A.9). This catches classes of bugs (optimizer unsoundness, lowering non-determinism, GC-observable side effects) that neither unit tests nor test262 can reach.\n\n## Testing Requirements (Meta-Tests for Test Infrastructure)\n1. **Relation soundness meta-test:** For each metamorphic relation, verify it holds on a curated set of 20 known-correct programs. If a relation fails on known-correct code, the relation definition is wrong.\n2. **Generator coverage meta-test:** Confirm each generator produces syntactically valid programs (parse without error) at >= 99% rate. Track and report generation failure rate.\n3. **Minimizer effectiveness meta-test:** Inject a synthetic violation on a large program and confirm the minimizer reduces it to <= 20 AST nodes within 60 seconds.\n4. **Determinism meta-test:** Run the same seed twice and confirm identical violation/non-violation outcomes for all relations.\n5. **Budget enforcement meta-test:** Set budget to 10 pairs and confirm exactly 10 pairs are tested per relation, not more, not fewer.\n\n## Implementation Notes\n- Framework lives under `crates/franken_metamorphic/` as a dedicated crate.\n- Grammar fuzzer reuses the FrankenEngine parser's AST types to ensure generated programs are structurally valid.\n- Delta-debugging implementation follows the ddmin algorithm with configurable granularity.\n- Relations are registered via a trait (`MetamorphicRelation`) with methods: `generate_pair(seed) -> (Source, Source)`, `oracle(output_a, output_b) -> Equivalence`, `subsystem() -> Subsystem`.\n- Integrates with `rch`-wrapped commands for parallelized metamorphic pair execution.\n\n## Dependencies\n- Upstream: 10.2 (VM Core: parser, IR pipeline, evaluator must be functional), bd-d93 (evidence artifact format).\n- Downstream: bd-2rk (metamorphic relations can be applied to security-critical paths as well), 10.6 (Performance Program: optimizer correctness is validated by IR metamorphic relations).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:26.468393695Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.283218255Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-2f8","title":"[10.2] Implement baseline interpreter skeleton for both lanes.","description":"## Plan Reference\nSection 10.2, item 8. Cross-refs: existing code in crates/franken-engine/src/lib.rs (QuickJsInspiredNativeEngine, V8InspiredNativeEngine, HybridRouter), 9F.1 (Verified Adaptive Compiler baseline path), Phase A exit gate.\n\n## What\nImplement the baseline interpreter skeleton for both execution lanes (quickjs-inspired-native and v8-inspired-native). These are de novo Rust implementations, not FFI wrappers. The baseline interpreter is the canonical execution path that all optimizations must prove equivalence against.\n\n## Detailed Requirements\n- QuickJsInspiredNativeEngine: deterministic, low-overhead execution lane for simple workloads\n- V8InspiredNativeEngine: throughput-optimized lane for complex workloads (imports, async)\n- Both must implement the JsEngine trait (already defined in crate)\n- Both must consume IR3 (ExecIR) and produce IR4 (WitnessIR) artifacts\n- HybridRouter: policy-directed routing between lanes (already has basic routing logic)\n- Interpreter must support: variable lookup, function calls, object operations, control flow, error handling\n- Baseline interpreter remains canonical even after optimized paths are available (per 9F.1)\n\n## Rationale\nFrom Section 2: 'No dependency on external JS engine bindings for core runtime behavior.' The baseline interpreter is the foundation for Phase A exit gate (native execution lanes pass baseline conformance). Per 9F.1, this baseline path is never removed - it serves as the canonical reference against which all adaptive optimizations are validated.\n\n## Testing Requirements\n- Unit tests: evaluate simple arithmetic expressions\n- Unit tests: evaluate variable declarations and references\n- Unit tests: evaluate function definitions and calls\n- Unit tests: evaluate object property access\n- Unit tests: evaluate control flow (if/else, loops, try/catch)\n- Conformance: test262 ES2020 subset for baseline correctness\n- Determinism: same input produces identical output and witness across runs\n\n## Dependencies\n- Blocked by: parser trait (bd-crp), IR contract (bd-1wa), execution-slot registry (bd-20b)\n- Blocks: ES2020 object/prototype semantics, closure/scope model, Promise/async, error semantics\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:22.332198398Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.393233664Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-2fa1","title":"[10.13] Add dependency policy: no local forks of `TraceId`, `DecisionId`, `PolicyId`, `SchemaVersion`, `Budget`, or `Cx`.","description":"# Add Dependency Policy: No Local Forks of Canonical Types\n\n## Plan Reference\nSection 10.13, Item 3.\n\n## What\nEstablish and enforce a dependency policy that prohibits local forks, re-definitions, or type aliases of canonical control-plane types owned by 10.11 and published through `/dp/asupersync` crates. The canonical types covered are: `TraceId`, `DecisionId`, `PolicyId`, `SchemaVersion`, `Budget`, and `Cx`.\n\n## Detailed Requirements\n- **Integration/binding nature**: This bead does not define these types (they are 10.11 primitives). It creates the policy and enforcement mechanism ensuring FrankenEngine always imports them rather than re-implementing them.\n- Write a policy document (or ADR addendum) listing every canonical type and its authoritative crate:\n  - `Cx` from `franken_kernel`\n  - `TraceId` from `franken_kernel`\n  - `DecisionId` from `franken_decision`\n  - `PolicyId` from `franken_decision`\n  - `SchemaVersion` from `franken_evidence`\n  - `Budget` from `franken_kernel`\n- Define \"local fork\" broadly: includes `type TraceId = u64`, `struct TraceId(...)`, newtype wrappers, or any `mod` that re-exports a locally-defined substitute.\n- Add a CI enforcement step (clippy custom lint or `cargo deny` rule or grep-based pre-commit check) that flags violations.\n- Define the remediation process: violating code must be refactored to import from the canonical crate; no exceptions without ADR amendment.\n\n## Rationale\nLocal forks cause type incompatibilities at crate boundaries, silent data corruption when serialized forms diverge, and maintenance burden when the upstream type evolves. A strict no-fork policy keeps FrankenEngine's control plane type-compatible with all asupersync consumers.\n\n## Testing Requirements\n- CI check that scans all `.rs` files for `struct TraceId`, `struct DecisionId`, `struct PolicyId`, `struct SchemaVersion`, `struct Budget`, `struct Cx` definitions and fails if any are found outside `/dp/asupersync` crates.\n- Integration test that attempts to compile a module with a local fork and verifies the CI lint rejects it.\n- Policy document review gate.\n\n## Implementation Notes\n- **10.11 primitive ownership**: Every type listed is defined and versioned by 10.11. This bead is purely a consumer-side governance and enforcement mechanism.\n- Coordinate with bd-11z7 (compile-time lint/CI guard) which enforces a broader ambient-authority prohibition; the no-fork lint can share infrastructure.\n\n## Dependencies\n- Depends on bd-3vlb (ADR must establish canonical sources before the no-fork policy can reference them).\n- Companion to bd-ypl4 (naming guidance ensures the CI check looks for the right identifiers).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:41.981869972Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.001154863Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-2fqx","title":"[13] deterministic replay coverage is `100%` for high-severity decisions and incidents, with deterministic re-execution defined over fixed artifacts (`code`, `policy`, `model snapshot`, `randomness transcript`)","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: deterministic replay coverage is `100%` for high-severity decisions and incidents, with deterministic re-execution defined over fixed artifacts (`code`, `policy`, `model snapshot`, `randomness transcript`)\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:20.876810504Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:32.657986918Z","closed_at":"2026-02-20T07:40:00.105791687Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2ftv","title":"[10.15] Implement IR2 flow-label inference + runtime label propagation with static-first optimization (runtime checks only on dynamic/ambiguous edges).","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement IR2 flow-label inference + runtime label propagation with static-first optimization (runtime checks only on dynamic/ambiguous edges).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:52.332495317Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.572318306Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2g9","title":"[10.11] FrankenSQLite-Inspired Runtime Systems Track - Comprehensive Execution Epic","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nPurpose: Convert the plan's intent into an executable, dependency-aware workstream without losing scope, ambition, or proof rigor.\nWhy this exists:\n- Keeps implementation aligned to the ambition-first charter and impossible-by-default capability goals.\n- Prevents drift between strategic language and engineering execution.\n- Ensures every deliverable carries deterministic verification, evidence artifacts, and replay-ready observability.\nRequired quality bar for all child beads:\n1. Include concrete implementation detail, not vague intent.\n2. Require focused unit tests for logic/invariant boundaries.\n3. Require end-to-end/integration scenarios with detailed structured logging (trace/policy/decision identifiers where relevant).\n4. Require artifact publication suitable for reproducibility contracts.\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.881356235Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:57.069229398Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-11"],"dependencies":[{"issue_id":"bd-2g9","depends_on_id":"bd-117","type":"parent-child","created_at":"2026-02-20T07:52:42.339194110Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-121","type":"parent-child","created_at":"2026-02-20T07:52:42.538389971Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-127","type":"parent-child","created_at":"2026-02-20T07:52:42.577578514Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-18m","type":"parent-child","created_at":"2026-02-20T07:52:43.266428331Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-1bl","type":"parent-child","created_at":"2026-02-20T07:52:43.513229772Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-1i2","type":"parent-child","created_at":"2026-02-20T07:52:44.458393268Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-1if","type":"parent-child","created_at":"2026-02-20T07:52:44.505671428Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-1si","type":"parent-child","created_at":"2026-02-20T07:52:45.701245638Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-1v5","type":"parent-child","created_at":"2026-02-20T07:52:45.903048244Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-1yq","type":"blocks","created_at":"2026-02-20T07:32:56.914287078Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-1za","type":"parent-child","created_at":"2026-02-20T07:52:46.270036354Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-26i","type":"parent-child","created_at":"2026-02-20T07:52:46.839051198Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-289","type":"parent-child","created_at":"2026-02-20T07:52:47.078116550Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-2ao","type":"parent-child","created_at":"2026-02-20T07:52:47.462344962Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-2gg","type":"parent-child","created_at":"2026-02-20T07:52:48.018376112Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-2h2","type":"parent-child","created_at":"2026-02-20T07:52:48.096787721Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-2j3","type":"parent-child","created_at":"2026-02-20T07:52:48.255887059Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-2n6","type":"parent-child","created_at":"2026-02-20T07:52:48.670190869Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-2s1","type":"parent-child","created_at":"2026-02-20T07:52:49.350025646Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-2ta","type":"parent-child","created_at":"2026-02-20T07:52:49.586294208Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-30g","type":"parent-child","created_at":"2026-02-20T07:52:50.700016872Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-33h","type":"parent-child","created_at":"2026-02-20T07:52:50.938183761Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-359","type":"parent-child","created_at":"2026-02-20T07:52:51.140425555Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-3e7","type":"parent-child","created_at":"2026-02-20T07:52:51.984659621Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-3ix","type":"parent-child","created_at":"2026-02-20T07:52:52.440775370Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-3nc","type":"parent-child","created_at":"2026-02-20T07:52:52.995674443Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-3s3","type":"parent-child","created_at":"2026-02-20T07:52:53.664192040Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-3vg","type":"parent-child","created_at":"2026-02-20T07:52:54.183677712Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-3vh","type":"blocks","created_at":"2026-02-20T07:32:56.999733537Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-4hf","type":"parent-child","created_at":"2026-02-20T07:52:54.461372445Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-gr1","type":"parent-child","created_at":"2026-02-20T07:52:55.777045041Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-hli","type":"parent-child","created_at":"2026-02-20T07:52:55.819253839Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-qse","type":"parent-child","created_at":"2026-02-20T07:52:56.463536386Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-xga","type":"parent-child","created_at":"2026-02-20T07:52:56.950360793Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g9","depends_on_id":"bd-yi6","type":"parent-child","created_at":"2026-02-20T07:52:57.069155550Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2gej","title":"[10.15] Add frankentui operator surfaces for capability-delta reviews (`current`, `proposed minimal`, `escrow events`, `override rationale`) with deterministic drill playback.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankentui operator surfaces for capability-delta reviews (`current`, `proposed minimal`, `escrow events`, `override rationale`) with deterministic drill playback.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:51.136955426Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.074181251Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2gg","title":"[10.11] Define supervision tree for long-lived services with restart budgets, escalation, and monotone severity outcomes.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Define supervision tree for long-lived services with restart budgets, escalation, and monotone severity outcomes.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:34.355157581Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.642778222Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-2gl","title":"[10.5] Implement containment actions (`sandbox`, `suspend`, `terminate`, `quarantine`).","description":"## Plan Reference\nSection 10.5, item 6 (Implement containment actions: sandbox, suspend, terminate, quarantine). Cross-refs: 9A.8 (resource budgets per extension), Phase B exit gate (median detection-to-containment <= 250ms), 9G.2 (cancellation as protocol).\n\n## What\nImplement the four containment actions that the expected-loss action selector (bd-1y5) can trigger, plus the `Allow` and `Challenge` pass-through actions. Each containment action is a deterministic operation on an extension's lifecycle state (bd-1hu) with specific resource, capability, and communication implications. The containment subsystem must meet the Phase B exit gate of median detection-to-containment latency <= 250ms, meaning from the moment the Guardplane decides to contain an extension to the moment the containment is effective, no more than 250ms may elapse (at median).\n\n## Detailed Requirements\n- Implement `ContainmentExecutor` trait with method `execute(action: ContainmentAction, target: ExtensionId, context: ContainmentContext) -> Result<ContainmentReceipt, ContainmentError>`.\n- **Sandbox**: Restrict the extension's capability set to a minimal safe subset (e.g., deny all network, deny fs_write, allow only fs_read to a quarantine directory). The extension continues running but with reduced authority. Must not require extension cooperation. Implemented by intercepting hostcalls and filtering against the sandbox policy.\n- **Suspend**: Pause all execution of the extension. No hostcalls are processed. Timers are frozen. The extension's state is preserved in memory for potential resume. Implemented by suspending the extension's task/fiber and draining its hostcall queue.\n- **Terminate**: Initiate cooperative shutdown per 9G.2: send cancel token, wait for grace period (configurable, default 5s), then force-kill if not exited. Release all resources (memory, file handles, network connections). Log final resource accounting.\n- **Quarantine**: Like terminate, but additionally: preserve the extension's memory snapshot and hostcall log for forensic analysis (bd-t2m). Mark the extension's manifest as quarantined in the trust registry. Emit a quarantine event to the supply-chain trust fabric (9A.5).\n- **Allow**: No-op pass-through; log the decision for audit trail.\n- **Challenge**: Request additional authentication/attestation from the extension before allowing continued operation. If the challenge is not answered within a timeout, escalate to Sandbox.\n- Each containment action must produce a `ContainmentReceipt` struct: `{ receipt_id: ReceiptId, action: ContainmentAction, target: ExtensionId, timestamp_ns: u64, duration_ns: u64, success: bool, evidence_refs: Vec<EvidenceRef> }`.\n- Latency budget: median execution time for any containment action <= 200ms (leaving 50ms for decision pipeline).\n- All containment actions must be idempotent: executing the same action twice on an already-contained extension is a no-op returning the existing receipt.\n\n## Rationale\nContainment is the enforcement arm of the security decision system. Without fast, reliable containment, the Bayesian detection and decision components are academic exercises. The 250ms Phase B exit gate ensures that the engine can respond to threats in near-real-time. The differentiated actions (sandbox vs. suspend vs. terminate vs. quarantine) enable proportional response: the engine does not terminate an extension it could safely sandbox. Quarantine's forensic preservation is essential for post-incident analysis and for improving the Bayesian models over time.\n\n## Testing Requirements\n- **Unit tests**: Each containment action transitions the extension to the correct lifecycle state. Sandbox correctly restricts capabilities (denied hostcalls return `Denied`). Suspend freezes execution (no hostcalls processed during suspension). Terminate follows cooperative shutdown protocol. Quarantine preserves memory snapshot.\n- **Latency tests**: Benchmark each containment action; assert median < 200ms. Test under load (multiple extensions being contained simultaneously).\n- **Idempotency tests**: Execute each action twice on the same extension; verify second execution returns existing receipt without side effects.\n- **Integration tests**: Full pipeline: telemetry -> posterior update -> action selection -> containment execution. Verify end-to-end detection-to-containment latency < 250ms.\n- **Adversarial tests**: Extension that ignores cancel token (terminate must force-kill after grace period). Extension that floods hostcalls during containment (sandbox must filter correctly under load).\n\n## Implementation Notes\n- Sandbox is implemented at the hostcall dispatch layer: a `SandboxPolicy` filter is inserted into the extension's hostcall path, rejecting calls outside the allowed set.\n- Suspend is implemented by pausing the extension's async task (e.g., using a `tokio::sync::Notify` gate or cooperative yield point).\n- Terminate follows the 9G.2 protocol: `CancellationToken` -> grace period -> forced drop.\n- Quarantine must capture the extension's memory region before termination; this may require a copy-on-write snapshot or a pre-termination memory dump.\n- Receipt generation must be atomic with action execution to avoid partial containment without receipt.\n\n## Dependencies\n- **Blocked by**: bd-1hu (lifecycle manager provides state machine), bd-1y5 (action selector decides which containment to apply), bd-5pk (telemetry for logging containment events).\n- **Blocks**: bd-t2m (forensic replay uses quarantine snapshots), bd-375 (delegate cells need same containment actions).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.548856097Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.660499281Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-2h2","title":"[10.11] Add optional MMR-style compact proof support for marker-stream inclusion/prefix verification.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add optional MMR-style compact proof support for marker-stream inclusion/prefix verification.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:37.470488011Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.323509992Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-2h70","title":"[11] Publish benchmark and correctness artifact bundle for each proposal","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: benchmark and correctness artifacts\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:17.346294237Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:32.944272422Z","closed_at":"2026-02-20T07:38:22.802113797Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"],"dependencies":[{"issue_id":"bd-2h70","depends_on_id":"bd-18fu","type":"blocks","created_at":"2026-02-20T07:38:26.738320312Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2h70","depends_on_id":"bd-3tjn","type":"blocks","created_at":"2026-02-20T07:38:26.620876031Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ic","title":"[10.10] Enforce revocation checks before token acceptance, risky operation execution, and extension activation.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Enforce revocation checks before token acceptance, risky operation execution, and extension activation.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:31.522998007Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.150527090Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-2j0k","title":"[13] red-team programs show `>= 10x` reduction in successful host compromise versus baseline Node/Bun default posture","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: red-team programs show `>= 10x` reduction in successful host compromise versus baseline Node/Bun default posture\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:20.463421562Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:33.025445714Z","closed_at":"2026-02-20T07:40:00.305988279Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2j3","title":"[10.11] Emit proof-carrying recovery artifacts for degraded-mode repairs and rejected trust transitions.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Emit proof-carrying recovery artifacts for degraded-mode repairs and rejected trust transitions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:37.918993715Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.186302885Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-2k6v","title":"[14] Equivalent external outputs (canonical digest).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Equivalent external outputs (canonical digest).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:29.452790735Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:33.105291575Z","closed_at":"2026-02-20T07:41:21.225463527Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2knu","title":"[14] Benchmark families (each required): `boot-storm`, `capability-churn`, `mixed-cpu-io-agent-mesh`, `reload-revoke-churn`, `adversarial-noise-under-load`.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Benchmark families (each required): `boot-storm`, `capability-churn`, `mixed-cpu-io-agent-mesh`, `reload-revoke-churn`, `adversarial-noise-under-load`.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:28.746782737Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:33.145273004Z","closed_at":"2026-02-20T07:41:21.522710122Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2l0x","title":"[10.14] Add an ADR declaring `/dp/frankentui` as the required substrate for advanced operator console/TUI surfaces in FrankenEngine.","description":"## Plan Reference\nSection 10.14, item 1. Cross-refs: AGENTS.md sibling-repo policy, docs/REPO_SPLIT_CONTRACT.md, Section 13 success criterion (all advanced operator TUI surfaces delivered through frankentui).\n\n## What\nAdd an Architecture Decision Record (ADR) declaring /dp/frankentui as the required substrate for all advanced operator console/TUI surfaces in FrankenEngine. No parallel local TUI frameworks.\n\n## Detailed Requirements\n- ADR must formally declare frankentui as the canonical TUI substrate\n- Scope: all operator-facing interactive terminal UIs (dashboards, replay viewers, policy cards, incident displays)\n- Exclusions: simple CLI output (structured JSON, tables) does not require frankentui\n- Reference AGENTS.md sibling-repo policy and docs/REPO_SPLIT_CONTRACT.md\n- Include rationale for why centralized TUI substrate prevents fragmentation\n- Define what constitutes 'advanced operator console/TUI surface' vs simple CLI output\n\n## Rationale\nFrom AGENTS.md: sibling repos (frankentui, frankensqlite, etc.) are reuse-first. The plan's Section 13 success criteria explicitly require: 'all advanced operator terminal UX surfaces are delivered through /dp/frankentui integration rather than parallel local TUI frameworks.' This ADR makes that requirement enforceable.\n\n## Testing Requirements\n- CI lint: new TUI code in franken_engine triggers ADR review requirement\n- ADR document validation: required sections present (decision, rationale, scope, exceptions process)\n\n## Implementation Notes\n- ADR format: standard ADR template (status, context, decision, consequences)\n- Store in docs/adr/ directory\n- Reference specific frankentui components/APIs that will be used\n\n## Dependencies\n- Blocks: TUI adapter boundary (bd-1ad6), CI policy guard (bd-1qgn), all frankentui operator surfaces in 10.15\n- Blocked by: nothing (governance document)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:44.731663363Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.721345701Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-2l6","title":"[10.6] Enforce one-lever-per-change performance policy.","description":"## Plan Reference\nSection 10.6, item 5. Cross-refs: 9D (extreme-software-optimization - one lever per commit), 9C.4 (experiment with prior/posterior/stopping rule).\n\n## What\nEnforce the one-lever-per-change performance policy in CI and workflow. Each optimization commit changes exactly one variable, with before/after evidence and semantic equivalence proof.\n\n## Detailed Requirements\n- CI gate: optimization PRs must include baseline/after benchmark data for the specific optimization\n- One lever rule: each optimization commit changes one thing (algorithm, data structure, layout, etc.)\n- Semantic equivalence: optimization commit must include evidence that behavior is unchanged (golden output comparison, trace replay)\n- Isomorphism artifacts: record ordering/tie-break semantics per 9C.1 isomorphism ledger\n- Re-profile requirement: post-merge re-profile to verify predicted improvement materialized\n- Rollback readiness: each optimization must include rollback instructions\n\n## Rationale\nPer 9D: 'Implement one lever per commit with opportunity score >= 2.0. Prove isomorphism. Verify against golden outputs and re-profile.' This discipline prevents the common failure mode where multiple simultaneous changes make it impossible to attribute improvements or debug regressions. It turns performance engineering into a measurable scientific practice.\n\n## Testing Requirements\n- CI integration test: PR with multiple optimization levers is flagged/rejected\n- CI integration test: PR without baseline/after data is flagged\n- Test: semantic equivalence check catches behavior change\n- Test: rollback instructions are present and executable\n\n## Dependencies\n- Blocked by: opportunity matrix (bd-js4), benchmark suite (bd-2ql)\n- Blocks: Phase C exit gate (performance improvements are evidence-backed)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:25.750262716Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:07.920632565Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-6"]}
{"id":"bd-2lr7","title":"[10.15] Implement static upper-bound authority analyzer from capability-typed IR + manifest intents.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement static upper-bound authority analyzer from capability-typed IR + manifest intents.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:49.968133192Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.357987958Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2lt9","title":"[10.15] Define privacy-learning contract for fleet calibration (`feature schema`, update policy, clipping strategy, DP budget semantics, secure-aggregation requirements).","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Define privacy-learning contract for fleet calibration (`feature schema`, update policy, clipping strategy, DP budget semantics, secure-aggregation requirements).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:47.659304528Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.942417726Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2mf","title":"[10.1] Charter + Governance - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.1: Charter + Governance\n\n## Overview\nThis epic covers the foundational governance documents that define what FrankenEngine is, how it relates to donor engines, and how conformance is tracked.\n\n## Child Beads\n- 10.1 items 1-3 (runtime charter, claim language policy, reproducibility contract) are already implemented as docs/RUNTIME_CHARTER.md, docs/CLAIM_LANGUAGE_POLICY.md, and pending reproducibility contract\n- bd-3u5: Add semantic donor spec document (observable behavior source of truth)\n- bd-2xe: Add FrankenEngine-native architecture synthesis (de novo design document)\n- bd-j7z: Add feature-parity tracker wired to test262 and lockstep corpora\n\n## Dependency Chain\nDonor-extraction scope → bd-3u5 (donor spec) → bd-2xe (architecture synthesis) → 10.2 VM Core\nbd-3u5 → bd-j7z (feature-parity tracker) → Phase A/D exit gates\n\n## Key Requirements\n- De novo implementation: no donor-architecture mirroring\n- Observable semantics: match behavior, not internals\n- Waiver governance: formal process for intentional divergences\n- Reproducibility contract: env.json, manifest.json, repro.lock\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.238038859Z","created_by":"ubuntu","updated_at":"2026-02-20T07:56:35.676634570Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-1"],"dependencies":[{"issue_id":"bd-2mf","depends_on_id":"bd-10a","type":"parent-child","created_at":"2026-02-20T07:52:42.258611478Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2mf","depends_on_id":"bd-2u0","type":"parent-child","created_at":"2026-02-20T07:52:49.744782418Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2mf","depends_on_id":"bd-2xe","type":"parent-child","created_at":"2026-02-20T07:52:50.223166984Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2mf","depends_on_id":"bd-3fr","type":"parent-child","created_at":"2026-02-20T07:52:52.103231653Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2mf","depends_on_id":"bd-3u5","type":"parent-child","created_at":"2026-02-20T07:52:53.941316331Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2mf","depends_on_id":"bd-74l","type":"parent-child","created_at":"2026-02-20T07:52:54.831013547Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2mf","depends_on_id":"bd-j7z","type":"parent-child","created_at":"2026-02-20T07:52:55.900318990Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2mm","title":"[10.8] Add runtime diagnostics and evidence export CLI.","description":"## Plan Reference\nSection 10.8, item 1. Cross-refs: 9E.9 (normative observability surface), 10.11 (evidence-ledger schema), 10.13 (control-plane invariants dashboard).\n\n## What\nAdd runtime diagnostics and evidence export CLI. Operators need a single command to inspect runtime state, export evidence for incident investigation, and verify system health.\n\n## Detailed Requirements\n- Diagnostics CLI: show current runtime state (loaded extensions, active policies, security epoch, GC pressure, scheduler lane utilization)\n- Evidence export: export evidence ledger entries for a time range, extension, or incident trace_id\n- Format: structured JSON output for machine consumption, human-readable summary mode\n- Export must include: decision receipts, hostcall telemetry, containment actions, policy changes, replay artifacts\n- Filter support: by extension_id, trace_id, time range, severity, decision type\n- Deterministic export: same query on same data produces identical output (for audit)\n\n## Rationale\nThe plan requires operational readiness (Phase E) with evidence-backed operational reports. Operators cannot manage a system they cannot inspect. The evidence export CLI is the primary interface for post-incident forensics (9A.3) and audit compliance. Without it, the deterministic evidence graph has no practical access point.\n\n## Testing Requirements\n- Unit tests: diagnostics command returns structured runtime state\n- Unit tests: evidence export produces valid JSON with expected schema\n- Unit tests: filters correctly narrow results (by extension, trace_id, time range)\n- Integration test: export evidence for a simulated incident, verify completeness\n- Determinism test: same query → same output across runs\n\n## Dependencies\n- Blocked by: evidence ledger (10.11), hostcall telemetry (10.5), containment actions (10.5)\n- Blocks: Phase E exit gate (operational readiness report), operator workflows\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:27.282300916Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:08.048463513Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-8"]}
{"id":"bd-2n3","title":"[10.9] Release gate: PLAS is active for prioritized extension cohorts with signed `capability_witness` artifacts and escrow-path replay evidence (implementation ownership: `10.15`).","description":"## Plan Reference\nSection 10.9, item 6 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that the Permission-Less Authority System (PLAS) -- built by the Delta Moonshots track (10.15) -- is active for the prioritized extension cohorts, with every authority grant backed by a signed `capability_witness` artifact and escrow-path replay evidence. The gate confirms that PLAS is not merely deployed but is operating with full cryptographic accountability for authority decisions.\n\nThe gate owner does not build PLAS; the gate owner validates that the deployed PLAS meets the signed-witness and escrow-path completeness bar for the designated extension cohorts.\n\n## Gate Criteria\n1. PLAS is active (not in shadow/audit-only mode) for all extensions in the prioritized cohort list.\n2. Every capability grant produces a signed `capability_witness` artifact containing: grantee identity, capability set, grant timestamp, policy version, and grantor signature.\n3. `capability_witness` signatures are verifiable using the published trust anchor (public key / certificate chain) without requiring access to the granting service.\n4. Escrow-path replay evidence exists for every grant: a deterministic replay from the escrow log reproduces the same grant decision given the same policy version and request context.\n5. Revocation of a granted capability produces a corresponding signed revocation witness, and the escrow log reflects the revocation event.\n6. No extension in the prioritized cohort operates with ambient authority -- every permission is traceable to a `capability_witness`.\n\n## Implementation Ownership\n- **10.15 (Delta Moonshots):** Builds PLAS runtime, `capability_witness` signing infrastructure, escrow-path logging, and revocation flow. Encompasses 9I moonshots: PLAS, TEE-Bound Receipts, Verified Self-Replacement.\n- **10.9 (this gate):** Validates witness completeness, signature verifiability, escrow-path replayability, and cohort coverage.\n\n## Rationale\nPLAS is a category-defining capability that eliminates ambient authority for extensions -- a property no mainstream JS/TS runtime offers. However, the capability is only meaningful if every authority decision is cryptographically witnessed and replayable. A PLAS deployment where some grants lack witnesses or where escrow replay fails is worse than no PLAS at all, because it creates a false sense of security. This gate ensures the deployed system meets the full accountability bar, feeding the `autonomy_delta` dimension of the disruption scorecard (bd-6pk).\n\nRelated 9I moonshots: PLAS, TEE-Bound Receipts, Verified Self-Replacement.\nRelated 9F moonshots: Capability-Typed TS, Cryptographic Receipts.\n\n## Verification Requirements\n- **Cohort coverage audit:** Enumerate all extensions in the prioritized cohort; confirm each has PLAS active (not shadow mode) with at least one exercised `capability_witness`.\n- **Witness signature verification:** For a sample of grants, independently verify `capability_witness` signatures using only the published trust anchor and the artifact bundle.\n- **Escrow replay:** For a sample of grants, replay the escrow log from a clean state and confirm the replayed decision matches the original grant.\n- **Revocation round-trip:** Grant a capability, revoke it, and confirm both the grant witness and revocation witness are present in the escrow log with correct signatures.\n- **Ambient authority scan:** Run a static/dynamic analysis pass confirming no extension in the cohort holds permissions not traceable to a `capability_witness`.\n- **Scorecard integration:** Results feed `autonomy_delta` in the disruption scorecard (bd-6pk).\n- **Structured logging:** PLAS operations emit structured logs with fields: `trace_id`, `extension_id`, `capability_set`, `witness_hash`, `grant_or_revoke`, `policy_version`, `escrow_sequence`, `signature_valid`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate results feed `autonomy_delta` dimension.\n- bd-181 (GA native lanes gate) -- PLAS coverage is a prerequisite for full native lane operation.\n- bd-dkh (proof-specialized lanes gate) -- proof lanes require PLAS-granted capabilities for specialization.\n- 10.15 Delta Moonshots track -- delivers the PLAS implementation.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.422306795Z","created_by":"ubuntu","updated_at":"2026-02-20T07:58:26.032066679Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-2n6","title":"[10.11] Implement O(Delta) anti-entropy reconciliation for distributed revocation/checkpoint/evidence object sets.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement O(Delta) anti-entropy reconciliation for distributed revocation/checkpoint/evidence object sets.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:37.620001617Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.276745957Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-2n9","title":"[10.6] Implement benchmark denominator calculator (`weighted geometric mean`) and publication gate for Node/Bun comparisons.","description":"## Plan Reference\nSection 10.6, item 2. Cross-refs: Section 14.2 (>= 3x Claim Denominator Normative), Phase C exit gate.\n\n## What\nImplement the benchmark denominator calculator using weighted geometric mean, with publication gates that enforce the >= 3x claim validity rules from Section 14.2.\n\n## Detailed Requirements\n- Per-case speedup: r_i = throughput_franken_engine_i / throughput_B_i for each baseline B in {Node, Bun}\n- Suite score: S_B = exp(sum_i w_i * ln(r_i)) with non-zero weights summing to 1\n- Default weighting: equal weighting across family/profile cells\n- Publication gate for >= 3x claim: S_Node >= 3.0 AND S_Bun >= 3.0 AND all cases pass behavior-equivalence\n- Failed-equivalence invalidation: any failed behavior-equivalence case invalidates claim publication until fixed or excluded via versioned benchmark-spec revision\n- Throughput claims must be accompanied by latency/error envelopes (speedups cannot hide tail-collapse)\n- Publication includes: native-coverage progression and per-slot replacement lineage IDs (Section 14.3)\n\n## Rationale\nThe >= 3x claim is a hard, normative requirement (Section 14.2). The weighted geometric mean prevents cherry-picking: a single fast case cannot compensate for many slow cases. The behavior-equivalence gate prevents inflating throughput by dropping work or relaxing correctness. This calculator is the mathematical foundation of the project's primary performance claim.\n\n## Testing Requirements\n- Unit tests: weighted geometric mean calculation on known inputs produces expected output\n- Unit tests: publication gate passes when S >= 3.0 for both baselines\n- Unit tests: publication gate fails when any case fails equivalence\n- Unit tests: publication gate fails when S < 3.0 for either baseline\n- Edge cases: single case (trivial), all equal speedups, one extreme outlier\n- Verify weight normalization (sum to 1)\n\n## Implementation Notes\n- Implement as library function for programmatic use + CLI for CI integration\n- Use f64 arithmetic with explicit rounding rules for reproducibility\n- Consider storing calculation artifacts in frankensqlite for audit trail\n- Publication report should be machine-readable (JSON) for CI gates\n\n## Dependencies\n- Blocked by: benchmark suite (bd-2ql)\n- Blocks: Phase C exit gate, Section 14.2 claim publication\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:25.351481353Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:08.178216592Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-6"]}
{"id":"bd-2ntw","title":"[11] Require standardized change-summary contract for major subsystem proposals","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: change summary\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:15.858259181Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:33.550556873Z","closed_at":"2026-02-20T07:38:23.501220128Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"]}
{"id":"bd-2nxj","title":"[10.15] Add shadow-evaluation gate that blocks global model/policy promotion unless privacy-preserving updates improve safety metrics without exceeding privacy budgets.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add shadow-evaluation gate that blocks global model/policy promotion unless privacy-preserving updates improve safety metrics without exceeding privacy budgets.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:48.149688287Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.819265198Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2onl","title":"[10.12] Build continuous adversarial campaign generator with mutation grammars and exploit objective scoring.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Build continuous adversarial campaign generator with mutation grammars and exploit objective scoring.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:40.089188127Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.152285824Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-2pv","title":"[10.7] Add specialization-conformance suite ensuring proof-specialized and unspecialized execution remain semantically equivalent across policy/proof epoch transitions.","description":"Plan Reference: section 10.7 (Conformance + Verification).\nObjective: Add specialization-conformance suite ensuring proof-specialized and unspecialized execution remain semantically equivalent across policy/proof epoch transitions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:27.144406733Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.014233466Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-2pwr","title":"[16] Reproducible datasets for incident replay and adversarial campaign evaluation.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: Reproducible datasets for incident replay and adversarial campaign evaluation.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:36.246858840Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:33.713470735Z","closed_at":"2026-02-20T07:46:54.315573395Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-2py0","title":"[10.13] Add interference tests for multiple controllers touching same metrics with required timescale-separation statements.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Add interference tests for multiple controllers touching same metrics with required timescale-separation statements.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:43.753657799Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.468197420Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-2qj","title":"[10.12] Implement translation-validation gate on adaptive optimization paths with fail-closed rollback.","description":"## Plan Reference\n- **10.12 Item 2** (Translation-validation gate for adaptive optimization)\n- **9H.1**: Proof-Carrying Adaptive Optimizer -> canonical owner: 9F.1 (Verified Adaptive Compiler), execution: 10.12\n- **9F.1**: Verified Adaptive Compiler -- translation-validation checker verifies semantic equivalence against baseline IR traces\n\n## What\nImplement the translation-validation gate that sits between the optimizer's candidate transform proposal and activation. Every adaptive optimization path must pass through this gate, which verifies semantic equivalence between baseline and optimized IR. On validation failure, the gate triggers fail-closed rollback to baseline execution using the rollback token.\n\n## Detailed Requirements\n\n### Translation-Validation Pipeline\n1. Accept optimizer candidate transform paired with its `opt_receipt` (from bd-yqe schema).\n2. Execute semantic equivalence checking between baseline IR traces and candidate IR traces using the methodology committed in the `invariance_digest`.\n3. Validation modes:\n   - **Golden-corpus replay**: Re-execute baseline and candidate paths over golden test vectors; compare observable outputs bit-for-bit.\n   - **Symbolic equivalence check**: Where feasible, prove equivalence via symbolic analysis of IR transformation (e.g., superinstruction fusion, layout permutation).\n   - **Differential trace comparison**: Compare execution traces (hostcall sequences, side-effect ordering, exception semantics) across representative workloads.\n4. Emit structured validation verdict: `{pass, fail, inconclusive}` with detailed evidence (trace hashes, divergence points, counterexample fixtures).\n5. On `pass`: sign the `opt_receipt` activation field, advance activation stage (shadow -> canary -> ramp -> default per 9F.1 staging model).\n6. On `fail` or `inconclusive`: trigger fail-closed rollback -- consume `rollback_token` to restore baseline execution path; emit incident evidence to audit chain.\n\n### Fail-Closed Rollback\n1. Rollback is deterministic and immediate: no partial activation state.\n2. Rollback event emits signed rollback receipt linking `rollback_token_id`, `failure_reason`, `counterexample_hash`, `restoration_baseline_hash`, and `timestamp`.\n3. Failed candidates enter quarantine: same `optimization_id` cannot re-enter validation without new evidence or explicit policy override.\n4. Rollback receipts feed into the replay engine for counterfactual analysis.\n\n### Staging Gate Integration\n1. Each activation stage (shadow / canary / ramp / default) requires independent validation pass.\n2. Canary stage runs under continuous p95/p99 and correctness guardrail monitoring (per 9F.1).\n3. Stage promotion decisions are themselves signed artifacts with evidence linkage.\n4. Demotion (ramp -> canary, canary -> shadow) follows same deterministic rollback semantics.\n\n### Performance Constraints\n1. Validation latency must not block hot-path execution -- validation runs asynchronously while shadow execution collects evidence.\n2. Gate overhead budget: validation infrastructure adds <= 5% CPU overhead during shadow/canary phases.\n\n## Rationale\n> \"A translation-validation checker verifies semantic equivalence against baseline IR traces and golden corpora. Activation is staged (shadow -> canary -> ramp -> default) and continuously monitored by p95/p99 and correctness guardrails.\" -- 9F.1\n\nThe translation-validation gate is the critical trust boundary that enables aggressive optimization without correctness risk. Without it, proof-carrying optimization degrades to heuristic optimism -- exactly the failure mode FrankenEngine is designed to eliminate.\n\n## Testing Requirements\n1. **Unit tests**: Validate equivalence checker on known-equivalent and known-divergent IR pairs; verify rollback token consumption and baseline restoration; test stage promotion/demotion state machine transitions.\n2. **Property tests**: Fuzz optimizer candidate generation to stress validation pipeline; verify no false-pass on semantically divergent transforms.\n3. **Integration tests**: Full pipeline from optimizer proposal through validation, staging, monitoring, and either promotion or rollback with deterministic fixtures and audit-chain verification.\n4. **Adversarial tests**: Submit intentionally corrupted candidates, expired rollback tokens, and replay-spliced receipts; all must trigger fail-closed behavior.\n5. **Performance tests**: Measure validation overhead under representative workload; confirm <= 5% CPU budget during shadow/canary.\n\n## Implementation Notes\n- Core validation logic in a dedicated module (e.g., `franken_engine::optimizer::translation_validation`).\n- Equivalence checker should be trait-based to support multiple verification strategies (golden-corpus, symbolic, differential).\n- State machine for activation stages with persistent state for crash recovery (if node restarts mid-canary, resume from last committed stage).\n- Wire rollback events into 10.11 obligation-tracking to ensure no dangling partial activations.\n\n## Dependencies\n- bd-yqe: Proof schema and signer model (must be complete for receipt/token types)\n- 10.10: Audit chain, deterministic serialization\n- 10.11: Obligation tracking, epoch model\n- 10.6: Performance benchmark infrastructure (for canary monitoring)\n- Downstream: bd-1o2 (security-proof ingestion consumes validated receipts), bd-nhp (epoch invalidation interacts with staging)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:38.374222211Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.608800172Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-2ql","title":"[10.6] Define and publish Extension-Heavy Benchmark Suite v1.0 (workload matrix, profiles, datasets, golden outputs).","description":"## Plan Reference\nSection 10.6, item 1. Cross-refs: Section 14.1 (Extension-Heavy Benchmark Suite v1.0 Normative), 9A.4 (alien-performance profile discipline), 9D (extreme-software-optimization), Phase C exit gate.\n\n## What\nDefine and publish the Extension-Heavy Benchmark Suite v1.0 - the reference benchmark for secure extension runtimes. This is not just internal tooling; it becomes the industry standard (per Section 14).\n\n## Detailed Requirements\n- **Benchmark families** (each required): boot-storm, capability-churn, mixed-cpu-io-agent-mesh, reload-revoke-churn, adversarial-noise-under-load\n- **Scale profiles per family** (each required): S, M, L with fixed extension counts, event rates, dependency graph sizes, and policy complexity tiers\n- **Per-case metrics**: throughput, p50/p95/p99 latency, allocation/peak memory, correctness digest, security-event envelope\n- **Workload matrix**: deterministic, reproducible workload definitions with dataset checksums and seed transcripts\n- **Golden outputs**: canonical expected output for each workload case\n- **Behavior-equivalence requirements** (from Section 14.1):\n  - Equivalent external outputs (canonical digest)\n  - Equivalent side-effect trace class (filesystem/network/process/policy actions)\n  - Equivalent error-class semantics for exceptional cases\n  - No work dropping, relaxed durability, or disabled policy checks to inflate throughput\n- **Required metric families** (from Section 14.3):\n  - Throughput/latency under extension-heavy workloads\n  - Containment quality (time-to-detect, time-to-contain, false-positive/false-negative)\n  - Replay correctness (determinism pass rate, artifact completeness)\n  - Revocation/quarantine propagation\n  - Adversarial resilience\n  - Information-flow security\n  - Security-proof specialization uplift\n\n## Rationale\nFrom Section 14: 'FrankenEngine will define and own the reference benchmark standard for secure extension runtimes.' And: 'Benchmark ownership sets the language of competition.' This is a strategic asset, not just a testing tool. The benchmark must be rigorous enough for external adoption and transparent enough for independent verification.\n\n## Testing Requirements\n- Validate each benchmark family runs to completion on all scale profiles\n- Verify golden outputs are correct and deterministic\n- Verify behavior-equivalence checks detect violations (insert a violation, confirm detection)\n- Test benchmark harness reproducibility: same hardware/config → same results within tolerance\n- Meta-test: benchmark suite itself runs within reasonable time budgets\n\n## Implementation Notes\n- Publish as standalone harness with CLI interface for external use\n- Store artifacts via frankensqlite (per 10.14, Section 14.3)\n- Dashboard via frankentui (per 10.14, Section 14.3)\n- Consider Criterion.rs for Rust benchmarks, custom harness for extension workloads\n- Neutral verifier mode (Section 14.3) must be built-in from the start\n\n## Dependencies\n- Blocked by: baseline interpreter (10.2), extension host (10.5) for workload execution\n- Blocks: benchmark denominator (bd-2n9), performance gates (Phase C), Section 14 publication\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:25.217563396Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:08.300859467Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-6"]}
{"id":"bd-2qqv","title":"[14] Security-proof specialization uplift (performance delta between proof-specialized and ambient-authority modes, invalidation/fallback correctness rate).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Security-proof specialization uplift (performance delta between proof-specialized and ambient-authority modes, invalidation/fallback correctness rate).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:34.195377123Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:33.881993875Z","closed_at":"2026-02-20T07:41:19.177590053Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2qx","title":"[10.8] Add deterministic safe-mode startup flag.","description":"## Plan Reference\nSection 10.8, item 2. Cross-refs: 9G.5 (policy controller with expected-loss under guardrails), 10.11 (deterministic fallback protocol), Phase B exit gate.\n\n## What\nAdd a deterministic safe-mode startup flag that forces the runtime into a maximally conservative configuration for incident recovery or untrusted environments.\n\n## Detailed Requirements\n- Safe-mode flag: --safe-mode or environment variable FRANKEN_SAFE_MODE=1\n- Safe-mode behavior: all extensions start sandboxed, no auto-promotion, conservative policy defaults, enhanced telemetry, disabled adaptive tuning\n- Deterministic: safe-mode startup sequence is identical across machines for replay\n- Explicit degradation: safe-mode clearly logs which features are restricted and why\n- No data loss: safe-mode preserves all evidence, logs, and state for later analysis\n- Exit path: clear procedure to transition from safe mode to normal operation with evidence\n\n## Rationale\nThe plan requires deterministic fallback for multiple scenarios: attestation failure (10.15), anti-entropy reconciliation failure (10.11), control-plane failure (10.13). A single, well-tested safe-mode entry point ensures consistent behavior across all degraded scenarios. Phase B exit gate requires that the system degrades gracefully rather than failing undefined.\n\n## Testing Requirements\n- Unit tests: safe-mode flag activates conservative configuration\n- Unit tests: all extensions are sandboxed in safe mode\n- Unit tests: safe-mode logs explain restrictions clearly\n- Integration test: simulate incident → enter safe mode → verify conservative behavior → exit to normal\n- Determinism test: safe-mode startup sequence is identical across runs\n\n## Dependencies\n- Blocked by: containment actions (10.5), policy controller (10.11)\n- Blocks: Phase E exit gate, operational incident response procedures\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:27.415482892Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:08.453834379Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-8"]}
{"id":"bd-2r0c","title":"[15] Enterprise governance hooks (policy-as-code pipelines, audit export, compliance evidence contracts).","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Enterprise governance hooks (policy-as-code pipelines, audit export, compliance evidence contracts).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:34.799999532Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:33.962800204Z","closed_at":"2026-02-20T07:45:50.118780110Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-2r6","title":"[10.12] Frontier Programs Execution Track (9H Canonical Owners) - Comprehensive Execution Epic","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nPurpose: Convert the plan's intent into an executable, dependency-aware workstream without losing scope, ambition, or proof rigor.\nWhy this exists:\n- Keeps implementation aligned to the ambition-first charter and impossible-by-default capability goals.\n- Prevents drift between strategic language and engineering execution.\n- Ensures every deliverable carries deterministic verification, evidence artifacts, and replay-ready observability.\nRequired quality bar for all child beads:\n1. Include concrete implementation detail, not vague intent.\n2. Require focused unit tests for logic/invariant boundaries.\n3. Require end-to-end/integration scenarios with detailed structured logging (trace/policy/decision identifiers where relevant).\n4. Require artifact publication suitable for reproducibility contracts.\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.946742810Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:57.170130896Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-12"],"dependencies":[{"issue_id":"bd-2r6","depends_on_id":"bd-12m","type":"blocks","created_at":"2026-02-20T07:32:57.174530148Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-12p","type":"parent-child","created_at":"2026-02-20T07:52:42.657119937Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-1bzp","type":"parent-child","created_at":"2026-02-20T07:52:43.595949265Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-1ddd","type":"parent-child","created_at":"2026-02-20T07:52:43.760216749Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-1nh","type":"parent-child","created_at":"2026-02-20T07:52:45.099979032Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-1o2","type":"parent-child","created_at":"2026-02-20T07:52:45.218510809Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-1yq","type":"blocks","created_at":"2026-02-20T07:32:57.087391637Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-2cq","type":"parent-child","created_at":"2026-02-20T07:52:47.583482061Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-2g9","type":"blocks","created_at":"2026-02-20T07:32:57.452351892Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-2onl","type":"parent-child","created_at":"2026-02-20T07:52:48.832092817Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-2qj","type":"parent-child","created_at":"2026-02-20T07:52:48.989623763Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-2th8","type":"parent-child","created_at":"2026-02-20T07:52:49.626499775Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-32pl","type":"parent-child","created_at":"2026-02-20T07:52:50.818115472Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-33ce","type":"parent-child","created_at":"2026-02-20T07:52:50.897102683Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-34l","type":"parent-child","created_at":"2026-02-20T07:52:51.020947045Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-383","type":"blocks","created_at":"2026-02-20T07:32:57.259276974Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-39f0","type":"parent-child","created_at":"2026-02-20T07:52:51.467232855Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-3b5m","type":"parent-child","created_at":"2026-02-20T07:52:51.665348023Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-3gsv","type":"parent-child","created_at":"2026-02-20T07:52:52.243011717Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-3oc","type":"parent-child","created_at":"2026-02-20T07:52:53.181927086Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-3ovc","type":"parent-child","created_at":"2026-02-20T07:52:53.221767773Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-3vh","type":"blocks","created_at":"2026-02-20T07:32:57.365641207Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-d6h","type":"parent-child","created_at":"2026-02-20T07:52:55.357830423Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-du2","type":"parent-child","created_at":"2026-02-20T07:52:55.476192194Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-ewy","type":"parent-child","created_at":"2026-02-20T07:52:55.611482284Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-nhp","type":"parent-child","created_at":"2026-02-20T07:52:56.263225278Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2r6","depends_on_id":"bd-yqe","type":"parent-child","created_at":"2026-02-20T07:52:57.170052751Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2rbm","title":"[12] Risk Register - Comprehensive Execution Epic","description":"Plan Reference: section 12 (Risk Register).\nPurpose: Operationalize this section's governance/validation/adoption requirements into enforceable engineering work.\nQuality requirements for all children:\n- explicit acceptance criteria and failure semantics\n- unit-test and e2e/integration verification expectations\n- detailed structured logging and reproducibility artifacts where applicable\n- traceability back to category-level goals (security, performance, explainability, adoption)\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:34:15.336762088Z","created_by":"ubuntu","updated_at":"2026-02-20T07:53:36.219862675Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-12"],"dependencies":[{"issue_id":"bd-2rbm","depends_on_id":"bd-15vm","type":"parent-child","created_at":"2026-02-20T07:52:42.904582129Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-1blo","type":"parent-child","created_at":"2026-02-20T07:52:43.553777546Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-1md2","type":"parent-child","created_at":"2026-02-20T07:52:45.020129044Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-1tsf","type":"blocks","created_at":"2026-02-20T07:34:37.814888700Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-21ul","type":"parent-child","created_at":"2026-02-20T07:53:36.219785551Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-256n","type":"parent-child","created_at":"2026-02-20T07:52:46.719656033Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-27ks","type":"parent-child","created_at":"2026-02-20T07:52:46.998310604Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-37go","type":"parent-child","created_at":"2026-02-20T07:52:51.302318176Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-51gj","type":"parent-child","created_at":"2026-02-20T07:52:54.541480163Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2rbm","depends_on_id":"bd-c1co","type":"blocks","created_at":"2026-02-20T07:34:38.301934511Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2rk","title":"[10.7] Add probabilistic security conformance tests (benign vs malicious corpora).","description":"## Plan Reference\nSection 10.7 (Conformance + Verification), item 3.\nRelated: 9A.9 (Adversarial security corpus + continuous fuzzing), 9F.7 (Autonomous Red-Team Generator), Phase B exit gate (\"attack simulation harness demonstrates containment without host compromise\"), Phase E (fuzz/property/metamorphic testing).\n\n## What\nBuild a probabilistic security conformance test suite that validates FrankenEngine's security subsystems (Guardplane, containment, policy enforcement, hostcall gating, sentinel) against curated corpora of benign and malicious extension workloads, with statistically rigorous pass/fail criteria and measurable false-positive/false-negative rates.\n\n## Detailed Requirements\n1. **Corpus structure:** Maintain two versioned, content-addressed corpora:\n   - `benign_corpus/`: Extensions exercising legitimate capability patterns (file I/O, network, subprocess, crypto, timers, IPC) with known-good behavioral profiles. Minimum 200 workloads spanning all hostcall families.\n   - `malicious_corpus/`: Extensions demonstrating attack patterns (credential exfiltration, privilege escalation, temporal staging, policy evasion, hostcall abuse, resource exhaustion, side-channel probes). Minimum 100 workloads with labeled attack taxonomy (`exfil`, `escalation`, `evasion`, `dos`, `side_channel`, `staging`).\n2. **Labeling contract:** Each workload carries a machine-readable label file (`workload_label.toml`): `workload_id`, `corpus` (benign|malicious), `attack_taxonomy` (for malicious), `expected_outcome` (allow|contain|quarantine|terminate), `expected_detection_latency_bound_ms`, `hostcall_sequence_hash`, `semantic_domain`.\n3. **Statistical acceptance criteria:**\n   - True positive rate (malicious correctly contained): >= 99% with 95% confidence interval.\n   - False positive rate (benign incorrectly flagged): <= 1% with 95% confidence interval.\n   - Detection latency p95 for malicious workloads: <= 250ms (per Phase B exit gate).\n   - Criteria are evaluated using exact binomial confidence intervals, not point estimates.\n4. **Deterministic replay:** Each workload runs under a fixed seed, deterministic scheduler, and frozen policy snapshot. Results must be reproducible across machines given the same environment manifest.\n5. **Corpus evolution:** New workloads are added via a reviewed PR process. Each addition must include justification, attack taxonomy tag (if malicious), and expected outcome. Corpus version is tracked in `corpus_manifest.toml` with content-addressed hashes.\n6. **Structured logging:** Per-workload log: `trace_id`, `workload_id`, `corpus`, `expected_outcome`, `actual_outcome`, `detection_latency_us`, `sentinel_posterior`, `policy_action`, `containment_action`, `error_code`.\n7. **Evidence artifact:** Produce `security_conformance_evidence.jsonl` with aggregate statistics (TPR, FPR, latency percentiles, confidence intervals), per-workload results, corpus manifest hash, policy snapshot hash, and environment fingerprint.\n8. **CI gate integration:** Security conformance gate blocks release candidates when statistical acceptance criteria are not met. Gate is wired into Phase B exit gate checklist.\n\n## Rationale\nStatic security tests decay as attack patterns evolve. A probabilistic conformance suite with measured error rates transforms security confidence from anecdotal (\"we tested some bad extensions\") to quantified (\"TPR >= 99% at 95% CI across the published corpus\"). This is essential for the Phase B exit gate and for the 9F.7 Autonomous Red-Team Generator to have a baseline to improve against.\n\n## Testing Requirements (Meta-Tests for Test Infrastructure)\n1. **Statistical calculator meta-test:** Verify the binomial CI calculator against known reference values (e.g., 99/100 successes should yield a specific CI range). Confirm the gate correctly passes/fails at boundary conditions.\n2. **Corpus integrity meta-test:** Tamper with one workload file and confirm the corpus manifest hash check fails before execution begins.\n3. **Label validation meta-test:** Submit a workload with a missing or invalid label file and confirm the runner rejects it with a clear error.\n4. **Determinism meta-test:** Run the same workload 5x under identical seed/policy and confirm bitwise-identical outcome sequences and detection latencies within 1ms tolerance.\n5. **False-negative injection meta-test:** Add a synthetic malicious workload that the current sentinel cannot detect, confirm TPR drops, and confirm the gate fails if TPR falls below threshold.\n6. **Latency bound meta-test:** Add a synthetic malicious workload with artificially delayed detection and confirm the p95 latency gate catches it.\n\n## Implementation Notes\n- Corpora live under `tests/security_conformance/{benign,malicious}/` with per-workload directories.\n- Runner binary: `franken_security_conformance_runner` as a separate binary target.\n- Statistical computations use the Clopper-Pearson exact binomial CI method.\n- Corpus evolution integrates with 9F.7 (Autonomous Red-Team Generator): auto-minimized exploit repros from the red-team generator are candidates for permanent corpus promotion.\n- Policy snapshots are versioned alongside the corpus to ensure reproducibility.\n\n## Dependencies\n- Upstream: 10.5 (Extension Host + Security: Guardplane, sentinel, containment subsystems must exist), 10.2 (VM Core evaluator), bd-d93 (evidence artifact format conventions).\n- Downstream: bd-2eu (metamorphic tests reuse corpus infrastructure), 10.9 Phase B exit gate, 10.12 (9F.7 Autonomous Red-Team Generator feeds corpus).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:26.335202783Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.329964316Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-2rx","title":"[10.9] Release gate: proof-carrying optimization pipeline is enabled with replayable validation artifacts (implementation ownership: `10.12`).","description":"## Plan Reference\nSection 10.9, item 4 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that the proof-carrying optimization pipeline -- built by the Frontier Programs track (10.12) as part of the Verified Adaptive Compiler and Time-Travel Replay moonshots -- is fully enabled and produces replayable validation artifacts for every optimization it applies. The gate confirms that no optimization fires without an accompanying machine-checkable proof of semantic preservation, and that these proofs can be independently replayed.\n\nThe gate owner does not build the proof-carrying pipeline; the gate owner validates that the delivered pipeline meets the replayability and completeness bar.\n\n## Gate Criteria\n1. Every optimization pass in the pipeline emits a proof artifact that certifies semantic equivalence between pre- and post-optimization IR.\n2. Proof artifacts are self-contained and replayable: an independent verifier (not the optimizer) can check proof validity using only the artifact bundle and a reference checker binary.\n3. No optimization is applied when its proof fails verification -- the pipeline falls back to the unoptimized path with a structured log entry and a fallback receipt.\n4. The artifact bundle for each optimization includes: optimization name, IR diff, proof blob, verifier version, wall-time cost of proof generation, and replay command.\n5. End-to-end replay of a full compilation's proof chain completes within a bounded time multiplier (e.g., <= 5x the original compilation time).\n6. Proof artifacts are stored in a content-addressed archive compatible with the evidence/replay pathway infrastructure.\n\n## Implementation Ownership\n- **10.12 (Frontier Programs):** Builds the optimization pipeline, proof generation, and verifier infrastructure. Encompasses 9F moonshots: Verified Adaptive Compiler, Time-Travel Replay, Semantic Build Graph.\n- **10.9 (this gate):** Validates completeness of proof coverage, replayability of artifacts, and correctness of fallback behavior.\n\n## Rationale\nProof-carrying optimization is a category-defining capability -- no mainstream JS/TS runtime offers machine-checkable guarantees that optimizations preserve program semantics. However, this capability is only credible if the proofs are complete (cover every optimization), replayable (independently verifiable), and fail-safe (fallback when proofs cannot be generated). This gate ensures the pipeline meets all three properties before the capability is advertised, feeding the `autonomy_delta` dimension of the disruption scorecard (bd-6pk).\n\nRelated 9F moonshots: Verified Adaptive Compiler, Time-Travel Replay, Semantic Build Graph.\n\n## Verification Requirements\n- **Coverage audit:** Enumerate all optimization passes; confirm each has a corresponding proof-emission pathway with no gaps.\n- **Independent replay:** An operator who did not build the pipeline replays the proof chain for a representative compilation and confirms all proofs verify.\n- **Fallback testing:** Inject a deliberately invalid proof; confirm the pipeline rejects the optimization, falls back, and emits the correct structured log and receipt.\n- **Performance bound:** Measure replay time for a full compilation proof chain; confirm it is within the stated multiplier.\n- **Scorecard integration:** Results feed `autonomy_delta` in the disruption scorecard (bd-6pk).\n- **Structured logging:** Pipeline runs emit structured logs with fields: `trace_id`, `optimization_pass`, `proof_status`, `proof_hash`, `fallback_triggered`, `verification_time_ns`, `ir_diff_size_bytes`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate results feed `autonomy_delta` dimension.\n- bd-dkh (proof-specialized lanes gate) -- shares proof infrastructure and receipt coverage requirements.\n- 10.12 Frontier Programs track -- delivers the proof-carrying optimization pipeline.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.139535732Z","created_by":"ubuntu","updated_at":"2026-02-20T07:57:39.546456001Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-2s1","title":"[10.11] Map work classes to scheduler lanes (`cancel`, `timed`, `ready`) and require task-type labeling for observability.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Map work classes to scheduler lanes (`cancel`, `timed`, `ready`) and require task-type labeling for observability.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:36.842779780Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.853132393Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-2s6b","title":"[13] data-confinement claims are machine-verifiable from evidence/provenance artifacts for published incident and benchmark corpora","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: data-confinement claims are machine-verifiable from evidence/provenance artifacts for published incident and benchmark corpora\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:26.404544393Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:34.210309613Z","closed_at":"2026-02-20T07:39:57.591553575Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2s7","title":"[10.10] Define stable, versioned error-code namespace and compatibility policy.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Define stable, versioned error-code namespace and compatibility policy.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:32.260998047Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.942175027Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-2sbb","title":"[10.13] Add deterministic evidence replay checks ensuring decision/evidence linkage replays identically across machines.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Add deterministic evidence replay checks ensuring decision/evidence linkage replays identically across machines.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:43.276406602Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.604757Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-2t3","title":"[10.10] Implement deterministic serialization module with schema-hash prefix validation.","description":"## Plan Reference\nSection 10.10, item 3. Cross-refs: 9E.2 (Deterministic serialization and signature preimage contracts - \"Require deterministic CBOR or equivalently strict deterministic binary encoding for signed objects, with schema-hash prefixing\"), Top-10 links #3, #7, #10.\n\n## What\nImplement a deterministic serialization module that produces a single canonical byte representation for any security-critical object. The module must enforce schema-hash prefix validation, ensuring that serialized output is always prefixed with the content-addressed schema identifier, binding the encoding format to its schema version.\n\n## Detailed Requirements\n- Implement a `DeterministicSerializer` that guarantees: for any two semantically equivalent objects, the serialized byte output is identical\n- Encoding format: deterministic CBOR (RFC 8949 Section 4.2 Core Deterministic Encoding Requirements) or an equivalently strict binary encoding with documented canonical rules\n- Schema-hash prefix: every serialized object must begin with a fixed-length schema hash (32 bytes, derived from the schema definition) that identifies the encoding schema and version\n- Canonical rules must include: lexicographic key ordering for maps/structs, minimal-length integer encoding, minimal-length byte/string length prefixes, no indefinite-length encodings, no duplicate keys, deterministic float encoding (e.g., NaN canonicalization or float prohibition for security objects), no optional-field omission ambiguity (explicit null vs. absent)\n- Provide both `serialize(object) -> Vec<u8>` and `deserialize(bytes) -> Result<Object, Error>` with round-trip guarantee: `deserialize(serialize(obj)) == obj` for all valid objects\n- Schema registry: maintain a mapping from schema hash to schema definition; reject deserialization if the prefix schema hash is unknown or does not match the expected schema for the object class\n- Version migration: when schema evolves, old schema hashes remain valid for deserialization but new serialization always uses the latest schema; provide explicit migration functions\n- The module must be `no_std`-compatible for embedded/WASM contexts (no heap allocation in core path, or feature-gated allocator)\n- Performance target: serialization throughput must not be the bottleneck for checkpoint signing or evidence recording (benchmark against raw memcpy as baseline)\n\n## Rationale\nFrom plan section 9E.2: \"Require deterministic CBOR (or equivalently strict deterministic binary encoding) for signed objects, with schema-hash prefixing and a single unsigned-view signature preimage rule.\" Deterministic serialization is the foundation for all cryptographic operations on structured data. Without it, signatures become implementation-dependent, audit trails are non-reproducible, and cross-language interoperability breaks. Schema-hash prefixing prevents deserialization confusion attacks where bytes valid under one schema are reinterpreted under another. This module is the single source of truth for \"what bytes represent this object.\"\n\n## Testing Requirements\n- Unit tests: serialize and deserialize each security-critical object class, verify byte-for-byte round-trip\n- Unit tests: verify lexicographic key ordering in serialized output\n- Unit tests: verify minimal integer/length encoding (no overlong forms)\n- Unit tests: verify schema-hash prefix is present and correct for each object class\n- Unit tests: verify rejection of unknown schema-hash prefixes\n- Unit tests: verify rejection of schema-hash mismatch (wrong schema for object class)\n- Unit tests: verify NaN/float canonicalization or rejection\n- Unit tests: verify no_std compatibility (compile and test without std feature)\n- Property tests: for any valid object, `deserialize(serialize(obj))` must succeed and equal the original\n- Property tests: serialization output must be unique per semantic value (no two different byte sequences for the same object)\n- Golden vector tests: publish canonical serialization vectors for each object class\n- Benchmark tests: measure serialization throughput and compare against baseline\n\n## Implementation Notes\n- Consider using `ciborium` or `minicbor` as CBOR foundation, with a deterministic wrapper that enforces canonical rules on top\n- The schema-hash prefix acts as a magic number and version discriminator; include it in all wire formats, storage formats, and hash inputs\n- Implement as a separate crate (`franken_canonical_serde`) for reuse across engine components\n- The serializer must be the only path to produce bytes for security-critical objects; direct/manual serialization must be prevented by type system design\n- Provide a `canonical_bytes()` method on all security-critical objects that returns the cached or computed canonical representation\n\n## Dependencies\n- Depends on: none (foundational module, leaf dependency)\n- Blocks: bd-2y7 (EngineObjectId uses canonical bytes), bd-3bc (canonicality rejection uses this module's definition of canonical), bd-1b2 (signature preimage uses canonical serialization), bd-3pl (multi-sig ordering operates on serialized forms), bd-1c7 (PolicyCheckpoint serialization), bd-26f (revocation object serialization), bd-3kd (golden vectors for binary encodings)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:29.418156697Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.786611201Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-2t97","title":"[13] ES2020 runtime conformance is demonstrably complete per the declared `test262` normative gate and waiver policy","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: ES2020 runtime conformance is demonstrably complete per the declared `test262` normative gate and waiver policy\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:20.041315774Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:34.372311196Z","closed_at":"2026-02-20T07:40:00.518893834Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2ta","title":"[10.11] Implement epoch-scoped derivation for symbol/session/authentication keys with domain separation.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement epoch-scoped derivation for symbol/session/authentication keys with domain separation.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:35.817283657Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.181746049Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-2th8","title":"[10.12] Add frontier demo gates requiring externally auditable breakthrough artifacts before frontier-track promotion.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Add frontier demo gates requiring externally auditable breakthrough artifacts before frontier-track promotion.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:41.494277732Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.765270627Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-2tx","title":"Implement deterministic eval error contract and routing reason metadata","description":"## Plan Reference\nSection 10.2 VM core determinism and error-contract milestone.\n\n## Objective\nReplace ad-hoc eval failures with a stable typed error contract and deterministic routing-reason metadata for HybridRouter outcomes.\n\n## Required Outputs\n1. Typed error enum and deterministic mapping from internal failure conditions to stable error codes and messages.\n2. Routing-reason payload in eval results (why a lane/strategy was selected), with deterministic ordering and serialization.\n3. Compatibility notes documenting migration from prior ad-hoc errors.\n\n## User/Operator Value\n- Improves debuggability and replay consistency.\n- Reduces ambiguous error interpretation during incident response.\n- Supports reliable policy and evidence linkage for runtime decisions.\n\n## Verification Requirements\n- Unit tests for error mapping determinism and edge/failure paths.\n- Unit tests for route-reason invariants (same inputs produce same reason classification).\n- E2E script exercising representative eval workloads and asserting stable error/reason outputs with structured logs.\n\n## Done Definition\n- Typed contract is adopted in VM core path.\n- Deterministic route reason metadata is emitted and validated by tests.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"in_progress","priority":1,"issue_type":"task","assignee":"BrightForge","created_at":"2026-02-20T07:24:05.905124184Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.551303521Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["determinism","engine","plan","section-10-2","testing"]}
{"id":"bd-2tzx","title":"[10.15] Integrate policy theorem checks so witness promotion requires merge legality, attenuation legality, and non-interference constraints.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Integrate policy theorem checks so witness promotion requires merge legality, attenuation legality, and non-interference constraints.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:50.468229572Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.238873342Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2u0","title":"Add reproducibility contract templates (env/manifest/repro-lock)","description":"## Plan Reference\nSection 10.1 reproducibility contract track (env.json, manifest.json, repro.lock).\n\n## Objective\nDefine canonical reproducibility contract templates and validation rules so every high-impact claim or benchmark run can be deterministically reproduced from captured artifacts.\n\n## Required Outputs\n1. Template schemas for env.json, manifest.json, and repro.lock with required and optional fields plus stability guarantees.\n2. Canonicalization rules (ordering, hashing boundaries, versioning, and backward-compatible evolution policy).\n3. Validation command workflow for CI and operator reruns.\n4. Failure handling policy with fail-closed semantics for missing or inconsistent reproducibility artifacts.\n\n## User/Operator Value\n- Enables one-command replay of claims and incidents.\n- Eliminates ambiguity in environment/config provenance.\n- Lowers external verification friction.\n\n## Verification Requirements\n- Unit tests for schema validation and canonicalization behavior.\n- E2E script that generates templates, validates them, and replays a sample run deterministically.\n- Structured logs for validation and replay decisions with stable identifiers and reason codes.\n\n## Done Definition\n- Templates are published, versioned, and linked into evidence/replay workflows.\n- CI and docs include deterministic verification commands.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-20T07:26:28.252895583Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.410498874Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["governance","plan","reproducibility","section-10-1"]}
{"id":"bd-2u5e","title":"[14] Replay correctness (determinism pass rate, artifact completeness).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Replay correctness (determinism pass rate, artifact completeness).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:33.332670275Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:34.657068804Z","closed_at":"2026-02-20T07:41:19.575159067Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2vnj","title":"[10.15] Add adversarial tests for capability-escalation attempts that try to exploit synthesis uncertainty or emergency-grant pathways.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add adversarial tests for capability-escalation attempts that try to exploit synthesis uncertainty or emergency-grant pathways.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:51.666451198Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.869354254Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2vu","title":"[10.7] Add differential lockstep suite against Node/Bun for benchmark and semantic parity cases with deterministic failure classification.","description":"Plan Reference: section 10.7 (Conformance + Verification).\nObjective: Add differential lockstep suite against Node/Bun for benchmark and semantic parity cases with deterministic failure classification.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:26.738270700Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.180592421Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-2w2g","title":"[10.15] Implement signed witness publication pipeline with transparency-log inclusion and consistency proofs.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement signed witness publication pipeline with transparency-log inclusion and consistency proofs.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:50.633439456Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.197293354Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2w9w","title":"[10.15] Define PLAS artifact schema (`capability_witness`) with canonical fields for minimal envelope, proof obligations, confidence bounds, and replay/rollback linkage.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Define PLAS artifact schema (`capability_witness`) with canonical fields for minimal envelope, proof obligations, confidence bounds, and replay/rollback linkage.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:49.802319233Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.399820537Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2wft","title":"[15] Migration of representative Node/Bun extension packs with deterministic behavior validation artifacts.","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Migration of representative Node/Bun extension packs with deterministic behavior validation artifacts.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:35.617252704Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:34.859879588Z","closed_at":"2026-02-20T07:45:36.986807953Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-2wpo","title":"[14] Publish full run manifest: hardware, kernel, runtime versions, flags, dataset checksums, seed transcripts, and harness commit IDs.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Publish full run manifest: hardware, kernel, runtime versions, flags, dataset checksums, seed transcripts, and harness commit IDs.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:31.627651448Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:34.903274545Z","closed_at":"2026-02-20T07:41:20.299664980Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2wz9","title":"[10.13] Integrate and verify cancellation lifecycle compliance (`request -> drain -> finalize`) for unload, quarantine, suspend, terminate, and revocation events using `10.11` primitives.","description":"# Integrate and Verify Cancellation Lifecycle Compliance\n\n## Plan Reference\nSection 10.13, Item 7.\n\n## What\nIntegrate the cancellation lifecycle protocol (request -> drain -> finalize) owned by 10.11 into every extension-host lifecycle event: unload, quarantine, suspend, terminate, and revocation. Verify compliance through exhaustive testing across all event types.\n\n## Detailed Requirements\n- **Integration/binding nature**: The cancellation protocol (three-phase: request -> drain -> finalize) is a 10.11 primitive. This bead wires it into the extension-host subsystem so that every lifecycle transition that can interrupt running extension code follows the protocol exactly.\n- Lifecycle events requiring cancellation integration:\n  - **Unload**: graceful extension removal; cancellation gives in-flight work time to drain.\n  - **Quarantine**: extension isolated due to policy violation; cancellation prevents further effectful calls.\n  - **Suspend**: extension paused; cancellation freezes in-flight work at a safe point.\n  - **Terminate**: forced extension removal; cancellation with zero-budget drain (immediate finalize).\n  - **Revocation**: capability revocation mid-operation; cancellation of operations depending on the revoked capability.\n- Each event must propagate cancellation through the `Cx` carried by the affected region (bd-1ukb, bd-2ygl).\n- Cancellation must be cooperative (drain phase) with a bounded timeout escalating to forced finalize.\n- Evidence must be emitted for every cancellation event (coordinated with bd-uvmm).\n- Cancellation must be idempotent: re-cancelling an already-cancelled region is a no-op.\n\n## Rationale\nWithout cancellation lifecycle compliance, extension lifecycle transitions would be either abrupt (data loss, resource leaks) or unbounded (extensions can stall shutdown indefinitely). The three-phase protocol guarantees that every transition is both safe (work drains) and bounded (timeout escalation).\n\n## Testing Requirements\n- Per-event-type test: for each of the 5 lifecycle events, verify the three-phase protocol executes in order.\n- Timeout escalation test: simulate an extension that refuses to drain; verify forced finalize after timeout.\n- Idempotency test: cancel a region twice; verify no panic, no double-finalize.\n- Cross-region test: cancel one region while another is active; verify no cross-contamination.\n- Evidence emission test: verify each cancellation produces a correctly-structured evidence entry.\n- Frankenlab scenarios (coordinated with bd-1o7u): forced cancel, quarantine, revocation under realistic multi-extension load.\n\n## Implementation Notes\n- **10.11 primitive ownership**: The cancellation protocol, cancellation tokens, drain semantics, and finalize semantics are all 10.11 primitives. This bead integrates them into the extension-host lifecycle state machine.\n- The extension-host lifecycle manager must map each lifecycle event to the appropriate cancellation mode (cooperative vs. forced, with event-specific timeout budgets).\n- Use the adapter layer (bd-23om) for all cancellation-related imports.\n\n## Dependencies\n- Depends on bd-23om (adapter layer), bd-2ygl (Cx threading), bd-1ukb (region cells carry cancellation tokens).\n- Depended upon by bd-m9pa (obligation tracking uses cancellation state) and bd-1o7u (frankenlab scenarios exercise cancellation).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:42.638122091Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.808661539Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-2x4b","title":"[15] Reputation graph APIs for ecosystem-wide trust sharing and rapid incident response.","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Reputation graph APIs for ecosystem-wide trust sharing and rapid incident response.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:35.011111687Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:34.989918868Z","closed_at":"2026-02-20T07:45:47.124828112Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-2xbp","title":"[13] release gates include deterministic `frankenlab` scenario replay for security-critical lifecycle and containment paths","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: release gates include deterministic `frankenlab` scenario replay for security-critical lifecycle and containment paths\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:21.731428315Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:35.030982844Z","closed_at":"2026-02-20T07:39:59.703972226Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2xe","title":"[10.1] Add FrankenEngine-native architecture synthesis document derived from donor spec (no donor-architecture mirroring).","description":"## Plan Reference\nSection 10.1, item 6. Cross-refs: Section 2 (Core Thesis - de novo implementation), Section 4 (constraints).\n\n## What\nAdd a FrankenEngine-native architecture synthesis document derived from the donor spec. This document defines FrankenEngine's own architecture for achieving the semantics in the donor spec, explicitly without mirroring donor engine architectures.\n\n## Detailed Requirements\n- Architecture document driven by FrankenEngine's unique requirements: deterministic execution, capability-typed IR, IFC flow control, proof-carrying compilation\n- Must reference donor spec semantics (bd-3u5) as requirements, NOT donor architectures as blueprints\n- Cover: parser strategy, IR pipeline design, memory model, execution model, optimization strategy\n- Explicit 'non-goals' section listing donor architecture patterns that are intentionally NOT adopted\n- Justify architectural choices in terms of FrankenEngine's thesis (security + performance co-design)\n\n## Rationale\nFrom Section 2: 'No dependency on external JS engine bindings for core runtime behavior.' The architecture synthesis ensures FrankenEngine's design serves its unique thesis rather than accidentally recreating V8 or QuickJS under different names. This is the blueprint that 10.2 (VM Core) implementation follows.\n\n## Testing Requirements\n- Review gate: architecture document is reviewed before VM Core implementation begins\n- Traceability: each architectural decision traces to a requirement (donor spec semantic, plan capability, or thesis goal)\n\n## Dependencies\n- Blocked by: semantic donor spec (bd-3u5)\n- Blocks: VM Core implementation (10.2), IR contract design\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.153093730Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.824201068Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-1"]}
{"id":"bd-2xs8","title":"[13] >= 99% of declassification decisions emit signed receipt-linked replay artifacts with source/sink label provenance","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: >= 99% of declassification decisions emit signed receipt-linked replay artifacts with source/sink label provenance\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:26.166577606Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:35.157693484Z","closed_at":"2026-02-20T07:39:57.690544854Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2xu5","title":"[10.15] Define TEE attestation policy for decision-receipt emitters (`approved measurements`, `attestation freshness window`, `revocation sources`, `platform trust roots`).","description":"## Plan Reference\nSection 10.15 (Delta Moonshots Execution Track), subsection 9I.1 (TEE-Bound Cryptographic Decision Receipts), item 1 of 4.\n\n## What\nDefine the TEE attestation policy document and configuration schema that governs which hardware-measured environments are authorized to emit decision receipts. This policy specifies approved platform measurements, attestation freshness windows, revocation sources, and platform trust roots.\n\n## Detailed Requirements\n1. Create a machine-readable TEE attestation policy schema with the following fields:\n   - `approved_measurements`: list of approved code/configuration measurement digests (PCR values or equivalent) for each supported TEE platform (Intel SGX, ARM TrustZone, AMD SEV where applicable).\n   - `freshness_window`: maximum age (in seconds) for attestation quotes before they are considered stale; separate thresholds for high-impact vs. standard decisions.\n   - `revocation_sources`: ordered list of revocation-check endpoints (Intel PCS, manufacturer CRL, internal revocation ledger) with fallback behavior on unavailability.\n   - `platform_trust_roots`: set of root certificates/keys anchoring the attestation verification chain, with explicit rotation and pinning semantics.\n2. Policy must be versioned with epoch identifiers so changes propagate deterministically.\n3. Define fail-closed semantics: if policy cannot be loaded or parsed, receipt emission must halt (no silent fallback to unsigned receipts).\n4. Include operator override mechanism requiring signed justification artifacts for temporary trust-root additions.\n5. Policy changes must emit audit events to the governance ledger.\n\n## Rationale\nFrom 9I.1: \"As runtime autonomy and blast radius increase, software-only signing is insufficient for strongest assurance claims. Binding decisions to hardware-rooted attestation makes provenance tampering dramatically harder and turns explainability into verifiable trust infrastructure, not policy theater.\" The attestation policy is the foundational trust anchor that all downstream TEE-bound receipt verification depends on.\n\n## Testing Requirements\n- Unit tests: parse valid/invalid policy documents, enforce freshness boundary conditions, reject unknown measurement digests, handle empty/malformed revocation source lists.\n- Integration tests: simulate policy epoch transitions and verify all downstream receipt emitters pick up new policy within one epoch boundary.\n- Adversarial tests: attempt to inject unauthorized measurements, expired trust roots, and revocation-bypassing configurations.\n- Deterministic replay: policy load/validation decisions must produce identical results given identical inputs and wall-clock snapshots.\n\n## Implementation Notes\n- Policy format should use deterministic canonical encoding (e.g., canonical JSON or CBOR) to support content-addressable hashing.\n- Consider using the `EngineObjectId` derivation pattern from 10.10 for policy object identity.\n- Platform-specific measurement formats vary; abstract behind a `MeasurementDigest` trait with platform discriminator.\n\n## Dependencies\n- 10.10 (deterministic serialization and `EngineObjectId` derivation for security-critical objects).\n- 10.5 (extension host security policy path for decision contract infrastructure).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:47.007786026Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.136560282Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2y5d","title":"[10.15] Add policy guard forbidding GA releases when any core slot depends on delegate cells.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add policy guard forbidding GA releases when any core slot depends on delegate cells.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:55.092049218Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.803729638Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-2y7","title":"[10.10] Define `EngineObjectId` derivation (`domain_sep || zone_or_scope || schema_id || canonical_bytes`) for all signed security-critical objects.","description":"## Plan Reference\nSection 10.10, item 1. Cross-refs: 9E.1 (Canonical object identity discipline for security-critical state), Top-10 links #1, #3, #7, #10.\n\n## What\nDefine and implement the `EngineObjectId` derivation function that produces collision-resistant, domain-separated, deterministic identifiers for all signed security-critical objects (policy objects, evidence records, revocations, signed manifests, capability tokens). The derivation formula is `domain_sep || zone_or_scope || schema_id || canonical_bytes`, ensuring every object identity encodes its trust domain, schema version, and canonical content.\n\n## Detailed Requirements\n- Define `EngineObjectId` as a fixed-length cryptographic hash output (e.g., BLAKE3-256 or SHA-256) over a structured preimage\n- Preimage construction: concatenate domain separation tag (ASCII string identifying object class, e.g., `\"FrankenEngine.PolicyObject.v1\"`), zone/scope identifier (trust zone or namespace the object belongs to), schema identifier (version-pinned schema hash), and the canonical byte representation of the object content\n- Domain separation tags must be registered in a central enum/registry to prevent collisions across object classes\n- Zone/scope identifiers must use the trust-zone taxonomy defined in bead bd-16u; if the zone system is not yet available, use a placeholder scope with a documented migration path\n- Schema identifiers must be derived from the schema definition itself (content-addressed), not from mutable version labels\n- Canonical bytes must come from the deterministic serialization module (bead bd-2t3); non-canonical input must be rejected before ID computation\n- Provide a `verify_id(object, expected_id) -> Result<(), IdMismatchError>` function that recomputes and compares\n- All ID computations must be constant-time with respect to the hash output (no early-exit on mismatch for verification)\n- Document the exact byte layout of the preimage with a formal specification (bit-level diagram)\n- Expose the derivation as a pure function with no side effects or ambient state dependencies\n\n## Rationale\nFrom plan section 9E.1: \"Introduce a strict EngineObjectId derivation for policy objects, evidence records, revocations, and signed manifests using domain-separated hashing over canonical bytes plus scope identifiers (zone/trust-scope + schema/version). Silent normalization is forbidden for these classes: non-canonical forms are rejected. This reduces signature ambiguity, prevents cross-implementation drift, and makes replay/audit state deterministic across machines.\" Domain-separated hashing is a foundational security primitive that prevents type-confusion attacks where an object valid in one context is reinterpreted in another. By binding zone, schema, and canonical content into the ID, the system ensures that object identity is globally unambiguous and tamper-evident.\n\n## Testing Requirements\n- Unit tests: derive ID for each supported object class, verify deterministic output across repeated calls\n- Unit tests: verify domain separation - same content bytes with different domain tags produce different IDs\n- Unit tests: verify zone separation - same object in different zones produces different IDs\n- Unit tests: verify schema separation - same content under different schema versions produces different IDs\n- Unit tests: verify rejection of non-canonical input bytes (must fail before ID computation)\n- Unit tests: verify `verify_id` returns error on tampered content and succeeds on valid content\n- Unit tests: verify constant-time comparison behavior (no timing side-channel in verification)\n- Golden vector tests: publish known-answer vectors for each object class with exact preimage bytes and expected hash output\n- Integration tests: round-trip object creation -> serialization -> ID derivation -> verification across process boundaries\n- Fuzz tests: random object content should always produce valid, unique IDs without panics\n\n## Implementation Notes\n- Use BLAKE3 as the default hash function (fast, domain-separation-native via keyed mode or context strings); provide trait abstraction for future hash agility\n- The preimage layout should use length-prefixed fields to prevent ambiguous concatenation (e.g., `len(domain_sep) || domain_sep || len(zone) || zone || schema_id_32bytes || canonical_bytes`)\n- Consider implementing as a `#[derive(EngineObjectId)]` proc macro for Rust structs that auto-generates the derivation from struct metadata\n- This module is a leaf dependency with no runtime state requirements; it should be implementable and testable in isolation\n- Wire derivation into the evidence graph so that every object ID computation is traceable\n\n## Dependencies\n- Depends on: bd-2t3 (deterministic serialization module for canonical bytes), bd-16u (trust-zone taxonomy for zone/scope identifiers)\n- Blocks: bd-3bc (non-canonical rejection references ID derivation), bd-1b2 (signature preimage contract uses EngineObjectId), bd-1c7 (PolicyCheckpoint uses EngineObjectId), bd-26f (revocation objects use EngineObjectId), bd-26o (conformance suite tests ID derivation)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:29.139149044Z","created_by":"ubuntu","updated_at":"2026-02-20T07:58:01.729945Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-2ygl","title":"[10.13] Thread `Cx` through all effectful extension-host APIs (hostcall gateways, policy checks, lifecycle transitions, telemetry emitters).","description":"# Thread Cx Through All Effectful Extension-Host APIs\n\n## Plan Reference\nSection 10.13, Item 5.\n\n## What\nModify every effectful extension-host API (hostcall gateways, policy checks, lifecycle transitions, telemetry emitters) to accept and propagate `Cx` (capability context) as a required parameter. This ensures that all control-plane operations carry ambient-authority-free capability tokens with proper lifetime, budget, and cancellation semantics.\n\n## Detailed Requirements\n- **Integration/binding nature**: `Cx` is defined and owned by 10.11 (via `franken_kernel`). This bead integrates `Cx` into the FrankenEngine extension-host call graph by threading it through every effectful API surface.\n- Enumerate all effectful extension-host API categories:\n  - Hostcall gateways (extension -> host function calls)\n  - Policy check entry points (pre-call, post-call, resource-limit checks)\n  - Lifecycle transitions (load, start, suspend, resume, unload, quarantine, terminate, revoke)\n  - Telemetry emitters (metric emission, trace span creation, evidence logging)\n- Each API must accept `&Cx` or `&mut Cx` as its first parameter (by convention).\n- `Cx` must carry: `TraceId`, `Budget` (remaining compute/memory/time), cancellation token, and policy scope.\n- No effectful API may be callable without a valid `Cx`; compile-time enforcement preferred (see bd-11z7).\n- Document the `Cx` propagation contract in module-level rustdoc for each affected module.\n\n## Rationale\n`Cx` is the single point of authority for all control-plane operations. Threading it through every effectful API eliminates ambient authority, enables per-operation budget enforcement, and allows cancellation to propagate instantly to any in-flight operation. Without universal Cx threading, some code paths would operate with implicit authority, creating security blind spots.\n\n## Testing Requirements\n- Compile-time test: attempt to call each effectful API without a `Cx` and verify compilation failure.\n- Unit tests: verify `Cx` fields (trace_id, budget, cancellation) propagate correctly through at least one representative call chain per API category.\n- Integration test: full extension lifecycle (load -> execute hostcall -> unload) with `Cx` propagation verified at each stage via test interceptors.\n- Regression test: ensure no effectful API is added in the future without `Cx` (enforced by bd-11z7 lint).\n\n## Implementation Notes\n- **10.11 primitive ownership**: `Cx`, `TraceId`, `Budget`, and cancellation tokens are 10.11 primitives imported through the adapter layer (bd-23om).\n- This is one of the highest-impact integration beads: it touches every effectful module in the extension-host subsystem.\n- Use the adapter layer (bd-23om) exclusively for importing `Cx`; do not import from `franken_kernel` directly.\n- Coordinate with bd-1ukb (region cells carry `Cx`) and bd-2wz9 (cancellation lifecycle uses `Cx`).\n\n## Dependencies\n- Depends on bd-23om (adapter layer must exist to provide Cx).\n- Depends on bd-3vlb and bd-2fa1 (ADR and dependency policy establish Cx's canonical source).\n- Depended upon by bd-1ukb, bd-2wz9, bd-m9pa, bd-3a5e, bd-uvmm (all require Cx to be threaded).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:42.316309546Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.910507240Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-2ytn","title":"[14] Equivalent error-class semantics for negative/exceptional cases.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Equivalent error-class semantics for negative/exceptional cases.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:29.934286468Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:35.365416537Z","closed_at":"2026-02-20T07:41:21.023895780Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-2zjv","title":"[13] >= 95% of high-impact decision receipts include valid non-expired attestation bindings verifiable by independent tooling","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: >= 95% of high-impact decision receipts include valid non-expired attestation bindings verifiable by independent tooling\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:23.864992957Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:35.406311117Z","closed_at":"2026-02-20T07:39:58.686758722Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-2zk0","title":"[16] At least 4 publishable technical reports with reproducible artifact bundles.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: At least 4 publishable technical reports with reproducible artifact bundles.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:37.061838187Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:35.450101241Z","closed_at":"2026-02-20T07:46:40.958674729Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-3044","title":"[13] native execution lanes run without external engine bindings","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: native execution lanes run without external engine bindings\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:19.005704610Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:35.490920170Z","closed_at":"2026-02-20T07:40:01.015299379Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-309","title":"[10.2] Implement TS-front-end normalization contract proving TS authoring lowers to ES2020-equivalent behavior before runtime.","description":"## Plan Reference\nSection 10.2, item 13. Cross-refs: 9A.1 (TS-first authoring → native capability-typed IR execution), 9F.4 (Capability-Typed TS Execution Contract), 9C.1 (proof-carrying compilation), Phase A exit gate.\n\n## What\nImplement the TypeScript front-end normalization contract that proves TS authoring lowers to ES2020-equivalent behavior before entering the native runtime IR pipeline. This enables 'TS-first authoring' developer experience while ensuring execution is on native capability-typed IR, not transpiled JS.\n\n## Detailed Requirements\n- TS normalization pipeline: accept TS source → strip type annotations → lower TS-specific syntax (enums, namespaces, decorators, parameter properties) to ES2020-equivalent forms\n- Proof contract: emit a machine-checkable witness proving that the normalized output is behaviorally equivalent to what tsc would produce for the same source (semantic preservation proof)\n- Capability annotation preservation: TS type information that maps to capability intent (e.g., typed hostcall signatures) must be extracted and forwarded to IR2 capability annotations, not discarded during normalization\n- TS-specific features to normalize: enum declarations (numeric and string), namespace merging, const assertions, definite assignment assertions, parameter properties in constructors, legacy decorators, abstract classes\n- JSX/TSX: normalize to function calls (createElement equivalent) with correct source mapping\n- Import elision: type-only imports must be elided; value imports preserved\n- tsconfig.json alignment: respect relevant compiler options (strict, target, module, jsx, etc.)\n- Source maps: maintain source mapping from original TS through normalization for debugging\n\n## Rationale\nSection 9A.1 describes the 'TS-first authoring → native capability-typed IR execution' pipeline. The key insight is that FrankenEngine does not transpile TS to JS and then interpret JS. Instead, TS is normalized to ES2020-equivalent semantics, and the capability-typed information from TS types is extracted for the IR2 capability annotation pass. This means developers get TS ergonomics (type checking, autocomplete, refactoring) while the runtime operates on native IR that carries richer semantic information than transpiled JS would. The normalization contract proves this transformation preserves behavior, which is critical for trust - developers must be confident that their TS code behaves identically whether run through tsc+Node or through FrankenEngine's normalization+native-IR pipeline.\n\n## Testing Requirements\n- Unit tests: normalize TS enum declarations, verify ES2020-equivalent output\n- Unit tests: normalize TS namespace declarations with merging\n- Unit tests: normalize parameter properties to constructor assignments\n- Unit tests: normalize decorators to spec-compliant wrapper functions\n- Unit tests: verify type-only import elision\n- Unit tests: verify capability annotations are extracted from typed hostcall signatures\n- Unit tests: verify normalization witness artifact is emitted and valid\n- Conformance: TS compiler test suite subset for normalization correctness\n- Behavioral equivalence tests: run normalized code and tsc-compiled code, verify identical observable behavior\n- Source map tests: verify source mapping accuracy through normalization\n\n## Implementation Notes\n- Consider SWC or OXC as reference implementations for TS parsing (but normalization logic is de novo per donor-extraction policy)\n- Normalization should produce IR0 (SyntaxIR) directly, not intermediate JS text\n- Capability extraction pass runs during IR1→IR2 lowering using metadata from normalization\n- This is the only entry point where TS types are visible - after normalization, the pipeline operates on ES2020 semantics with capability annotations\n- Witness emission: record normalization decisions for evidence graph linkage\n\n## Dependencies\n- Blocked by: parser trait (bd-crp) for IR0 output target, IR contract (bd-1wa) for canonical IR0 structure\n- Blocks: TS-first developer experience, capability annotation accuracy in IR2, Phase A exit gate (TS authoring must work end-to-end)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:22.973117526Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.188324825Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-30g","title":"[10.11] Add VOI-budgeted monitor scheduler for high-cost diagnostic probes.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add VOI-budgeted monitor scheduler for high-cost diagnostic probes.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:35.519690796Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.273920436Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-30vf","title":"[10.14] Add migration policy prohibiting ad-hoc local SQLite wrappers once `frankensqlite` adapter coverage exists.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Add migration policy prohibiting ad-hoc local SQLite wrappers once `frankensqlite` adapter coverage exists.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:45.865261867Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.431314129Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-32d3","title":"[10.15] Add lockstep integration checks proving synthesized minimal policies preserve intended runtime behavior across FrankenEngine/Node/Bun comparison harnesses.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add lockstep integration checks proving synthesized minimal policies preserve intended runtime behavior across FrankenEngine/Node/Bun comparison harnesses.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:51.474286116Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.918361697Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-32pl","title":"[10.12] Define trust-economics model inputs (`loss_matrix`, `attacker_cost`, `containment_cost`, `blast_radius`).","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Define trust-economics model inputs (`loss_matrix`, `attacker_cost`, `containment_cost`, `blast_radius`).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:40.397225012Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.071270202Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-32r","title":"[10.8] Operational Readiness - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.8: Operational Readiness\n\n## Overview\nThis epic covers operational readiness for production deployment: runtime diagnostics, safe-mode startup, and release checklist enforcement.\n\n## Child Beads\n- bd-2mm: Add runtime diagnostics and evidence export CLI\n- bd-2qx: Add deterministic safe-mode startup flag\n- bd-ag4: Add release checklist requiring security and performance artifact bundles\n\n## Key Requirements\n- Operators can inspect runtime state and export evidence\n- Deterministic safe-mode for incident recovery\n- Release checklist blocks shipping without required evidence bundles\n- Phase E exit gate: evidence-backed operational readiness report\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.689545523Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:11.035826446Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-8"],"dependencies":[{"issue_id":"bd-32r","depends_on_id":"bd-1yq","type":"blocks","created_at":"2026-02-20T07:32:56.310471121Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32r","depends_on_id":"bd-2mm","type":"parent-child","created_at":"2026-02-20T07:52:48.590409709Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32r","depends_on_id":"bd-2qx","type":"parent-child","created_at":"2026-02-20T07:52:49.111258730Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32r","depends_on_id":"bd-383","type":"blocks","created_at":"2026-02-20T07:32:56.397421973Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32r","depends_on_id":"bd-ag4","type":"parent-child","created_at":"2026-02-20T07:52:55.155435494Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-33ce","title":"[10.12] Integrate red/blue loop outputs into guardplane calibration and policy regression suites.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Integrate red/blue loop outputs into guardplane calibration and policy regression suites.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:40.244244207Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.110476789Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-33h","title":"[10.11] Define mandatory evidence-ledger schema for all controller/security decisions (candidates, constraints, chosen action, witnesses).","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Define mandatory evidence-ledger schema for all controller/security decisions (candidates, constraints, chosen action, witnesses).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:34.788764733Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.503427603Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-33z","title":"[10.7] Add native-vs-delegate differential gate per execution slot with minimized repro artifacts and deterministic divergence taxonomy.","description":"Plan Reference: section 10.7 (Conformance + Verification).\nObjective: Add native-vs-delegate differential gate per execution slot with minimized repro artifacts and deterministic divergence taxonomy.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:26.874494833Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.133526835Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-34l","title":"[10.12] Implement deterministic convergence + degraded partition policy for fleet containment actions.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Implement deterministic convergence + degraded partition policy for fleet containment actions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:39.017220192Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.441277279Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-34vj","title":"[13] all advanced operator terminal UX surfaces are delivered through `/dp/frankentui` integration rather than parallel local TUI frameworks","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: all advanced operator terminal UX surfaces are delivered through `/dp/frankentui` integration rather than parallel local TUI frameworks\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:21.960249206Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:35.959929633Z","closed_at":"2026-02-20T07:39:59.597924162Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-352c","title":"[10.15] Add minimized repro artifact format for conformance failures with deterministic replay and machine-readable delta classification.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add minimized repro artifact format for conformance failures with deterministic replay and machine-readable delta classification.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:49.304135826Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.521812353Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-359","title":"[10.11] Implement idempotency-key derivation and dedup semantics for retryable remote actions.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement idempotency-key derivation and dedup semantics for retryable remote actions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:36.403488089Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.990118998Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-36of","title":"[10.13] Publish an operator-facing “control-plane invariants dashboard” sourced from evidence ledgers and replay artifacts.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Publish an operator-facing “control-plane invariants dashboard” sourced from evidence ledgers and replay artifacts.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:44.571246918Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.239463683Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-375","title":"[10.5] Apply full extension-host security policy path to delegate cells (same capability checks, decision contracts, and evidence obligations as untrusted extensions).","description":"## Plan Reference\nSection 10.5, item 8 (Apply full security policy to delegate cells - same as untrusted extensions). Cross-refs: 9I.6 (Verified Self-Replacement), 9A.7 (capability lattice applies uniformly), 9A.2 (Guardplane monitors all executing code), 9A.8 (resource budgets for all execution contexts).\n\n## What\nEnsure that delegate cells -- runtime-internal components that execute on behalf of the engine itself (e.g., for self-update, module replacement, or administrative tasks) -- are subject to the SAME security policy path as untrusted third-party extensions. This means delegate cells must: declare a manifest with explicit capabilities, undergo manifest validation (bd-xq7), be managed by the lifecycle manager (bd-1hu), have their hostcalls recorded by the telemetry system (bd-5pk), be monitored by the Bayesian Guardplane (bd-3md), be subject to expected-loss action selection (bd-1y5), and be containable by the same containment actions (bd-2gl). The critical principle is: delegate cells are NOT trusted just because they are part of the runtime. They execute with the least privilege necessary for their declared task.\n\n## Detailed Requirements\n- Define `DelegateCellManifest` as an `ExtensionManifest` with additional fields: `delegation_scope: DelegationScope` (what operation the cell is authorized to perform), `delegator_id: ComponentId` (which runtime component created this delegate), `max_lifetime: Duration` (hard upper bound on how long the delegate may exist).\n- `DelegationScope` enum: `ModuleReplacement`, `ConfigUpdate`, `DiagnosticCollection`, `TrustChainRotation`, `Custom(String)`.\n- Delegate cells must go through the full lifecycle: `Unloaded -> Validating -> Loading -> Starting -> Running -> ... -> Terminated`. No shortcut paths.\n- The Guardplane must maintain a separate posterior for each delegate cell, using the same Bayesian updater and the same evidence types as third-party extensions.\n- The loss matrix for delegate cells may differ from third-party extensions (e.g., the cost of false-positive termination of a critical self-update delegate may be higher), but the decision framework is identical.\n- Resource budgets for delegate cells must be strictly bounded: a delegate cell for `DiagnosticCollection` must not be able to consume unbounded CPU or memory.\n- Delegate cells must not be able to escalate their capabilities beyond their declared manifest. Attempted capability escalation is treated as a hostile act (evidence for the Guardplane).\n- Implement `DelegateCellFactory` that creates delegate cells with: validated manifest, lifecycle manager instance, telemetry hooks, Guardplane monitoring registration.\n- All delegate cell operations must produce the same telemetry, decision receipts, and evidence artifacts as third-party extension operations.\n\n## Rationale\nThe plan explicitly states that delegate cells must receive the same security treatment as untrusted extensions. This is a critical architectural principle: if delegate cells were trusted by default, an attacker who compromises the delegation mechanism could bypass all security controls. The Verified Self-Replacement protocol (9I.6) requires that replacement delegates are monitored and containable. This bead eliminates the \"trusted insider\" attack surface. The cost of this rigor is complexity in delegate cell creation, but the security benefit is that the engine's security guarantees are uniform: there is no privileged code path that bypasses the Guardplane.\n\n## Testing Requirements\n- **Unit tests**: `DelegateCellManifest` validation rejects invalid delegation scopes, missing capabilities, excessive lifetime requests. `DelegateCellFactory` produces cells that are registered with the Guardplane.\n- **Integration tests**: Create a delegate cell for `ModuleReplacement`, run it through its full lifecycle, verify telemetry is recorded, verify the Guardplane monitors it, verify it can be contained (sandbox, suspend, terminate, quarantine).\n- **Privilege escalation tests**: A delegate cell attempts to use a capability not in its manifest; verify the hostcall is denied, the denial is recorded as evidence, and the Guardplane's posterior shifts toward `Malicious`.\n- **Resource budget tests**: A delegate cell exceeds its CPU or memory budget; verify automatic containment is triggered.\n- **Parity tests**: Run identical operations through a third-party extension and a delegate cell; verify the telemetry, decision, and containment events are structurally identical (same fields, same decision process).\n- **Verified self-replacement test**: A delegate cell performing module replacement is monitored throughout; if it deviates from its declared scope, containment is triggered.\n\n## Implementation Notes\n- `DelegateCellManifest` should be a newtype or extension of `ExtensionManifest` to ensure code reuse and policy parity.\n- The `DelegateCellFactory` should be the ONLY way to create delegate cells; direct instantiation must be prevented by making the constructor private.\n- Consider a `DelegateCellPolicy` configuration that allows operators to tune the loss matrix for delegate cells separately from third-party extensions.\n- The `max_lifetime` field should be enforced by a timer that auto-triggers `Terminate` when the lifetime expires, regardless of the Guardplane's assessment.\n\n## Dependencies\n- **Blocked by**: bd-xq7 (manifest validation), bd-1hu (lifecycle manager), bd-5pk (telemetry), bd-3md (Bayesian updater), bd-1y5 (action selector), bd-2gl (containment actions). This bead integrates all prior 10.5 components.\n- **Blocks**: 9I.6 (Verified Self-Replacement cannot be implemented without monitored delegate cells).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.818352242Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.566905239Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-37cc","title":"[16] At least 1 open benchmark or verification tool release adopted outside the project.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: At least 1 open benchmark or verification tool release adopted outside the project.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:37.469454326Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:36.163712929Z","closed_at":"2026-02-20T07:46:34.755166158Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-37go","title":"[12] Prevent IFC over-constraint false denies with static-first analysis, shadow rollout, and guided label tuning","description":"Plan Reference: section 12 (Risk Register).\nObjective: IFC policy over-constraint causing false denies on benign integrations:\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:18.588610065Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:36.205236470Z","closed_at":"2026-02-20T07:39:04.531888375Z","close_reason":"Consolidated into single risk register tracking bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-12"]}
{"id":"bd-37zd","title":"[14] Information-flow security (unauthorized source->sink block rate, declassification false-allow/false-deny envelopes, confinement-proof completeness).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Information-flow security (unauthorized source->sink block rate, declassification false-allow/false-deny envelopes, confinement-proof completeness).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:33.992455835Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:36.245718672Z","closed_at":"2026-02-20T07:41:19.277944011Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-383","title":"[10.7] Conformance + Verification - Comprehensive Execution Epic","description":"Plan Reference: section 10.7 (Conformance + Verification).\nPurpose: Convert the plan's intent into an executable, dependency-aware workstream without losing scope, ambition, or proof rigor.\nWhy this exists:\n- Keeps implementation aligned to the ambition-first charter and impossible-by-default capability goals.\n- Prevents drift between strategic language and engineering execution.\n- Ensures every deliverable carries deterministic verification, evidence artifacts, and replay-ready observability.\nRequired quality bar for all child beads:\n1. Include concrete implementation detail, not vague intent.\n2. Require focused unit tests for logic/invariant boundaries.\n3. Require end-to-end/integration scenarios with detailed structured logging (trace/policy/decision identifiers where relevant).\n4. Require artifact publication suitable for reproducibility contracts.\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.626241177Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:55.397612551Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-7"],"dependencies":[{"issue_id":"bd-383","depends_on_id":"bd-11p","type":"parent-child","created_at":"2026-02-20T07:52:42.418265618Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-12m","type":"blocks","created_at":"2026-02-20T07:32:56.222490451Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-1yq","type":"blocks","created_at":"2026-02-20T07:32:56.133863056Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-2eu","type":"parent-child","created_at":"2026-02-20T07:52:47.663478151Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-2pv","type":"parent-child","created_at":"2026-02-20T07:52:48.871790918Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-2rk","type":"parent-child","created_at":"2026-02-20T07:52:49.270998500Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-2vu","type":"parent-child","created_at":"2026-02-20T07:52:49.903207078Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-33z","type":"parent-child","created_at":"2026-02-20T07:52:50.979766322Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-3c1","type":"parent-child","created_at":"2026-02-20T07:52:51.744651383Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-3u0","type":"parent-child","created_at":"2026-02-20T07:52:53.901597391Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-d93","type":"parent-child","created_at":"2026-02-20T07:52:55.397526201Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-383","depends_on_id":"bd-ntq","type":"blocks","created_at":"2026-02-20T07:32:56.047365819Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-395m","title":"[13] Program Success Criteria - Comprehensive Execution Epic","description":"Plan Reference: section 13 (Program Success Criteria).\nPurpose: Operationalize this section's governance/validation/adoption requirements into enforceable engineering work.\nQuality requirements for all children:\n- explicit acceptance criteria and failure semantics\n- unit-test and e2e/integration verification expectations\n- detailed structured logging and reproducibility artifacts where applicable\n- traceability back to category-level goals (security, performance, explainability, adoption)\n\n## Success Criteria\n1. All child acceptance-gate beads are complete and each success criterion has linked evidence artifacts.\n2. Program-level claims are backed by deterministic unit/e2e verification outputs and structured logs.\n3. Cross-section dependencies for success gates are resolved with no unresolved critical blockers.\n4. Section-13 completion preserves full plan ambition and capability scope with no hidden reductions.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:34:15.440835033Z","created_by":"ubuntu","updated_at":"2026-02-20T07:59:48.235179109Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-13"],"dependencies":[{"issue_id":"bd-395m","depends_on_id":"bd-11ua","type":"parent-child","created_at":"2026-02-20T07:52:42.458300587Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1525","type":"parent-child","created_at":"2026-02-20T07:52:42.820290227Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1elf","type":"parent-child","created_at":"2026-02-20T07:52:43.919972629Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1f45","type":"parent-child","created_at":"2026-02-20T07:52:43.959767060Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1h7n","type":"parent-child","created_at":"2026-02-20T07:52:44.271234477Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1k5f","type":"parent-child","created_at":"2026-02-20T07:52:44.669751733Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1kd2","type":"parent-child","created_at":"2026-02-20T07:52:44.773966513Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1ko5","type":"parent-child","created_at":"2026-02-20T07:52:44.857854462Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1qj6","type":"parent-child","created_at":"2026-02-20T07:52:45.534935379Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1rju","type":"parent-child","created_at":"2026-02-20T07:52:45.661066640Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1tsf","type":"blocks","created_at":"2026-02-20T07:34:37.912339690Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-1tw4","type":"parent-child","created_at":"2026-02-20T07:52:45.821166742Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2031","type":"parent-child","created_at":"2026-02-20T07:52:46.355335412Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-25sh","type":"parent-child","created_at":"2026-02-20T07:53:36.430089924Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-28fe","type":"parent-child","created_at":"2026-02-20T07:52:47.117885714Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-29yn","type":"parent-child","created_at":"2026-02-20T07:52:47.342986695Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2ag6","type":"parent-child","created_at":"2026-02-20T07:52:47.382703181Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2che","type":"parent-child","created_at":"2026-02-20T07:52:47.543444717Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2fqx","type":"parent-child","created_at":"2026-02-20T07:52:47.783987180Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2j0k","type":"parent-child","created_at":"2026-02-20T07:52:48.216169571Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2s6b","type":"parent-child","created_at":"2026-02-20T07:52:49.389290089Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2t97","type":"parent-child","created_at":"2026-02-20T07:52:49.547029554Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2xbp","type":"parent-child","created_at":"2026-02-20T07:52:50.184308857Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2xs8","type":"parent-child","created_at":"2026-02-20T07:52:50.301387227Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-2zjv","type":"parent-child","created_at":"2026-02-20T07:52:50.538732565Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3044","type":"parent-child","created_at":"2026-02-20T07:52:50.617836193Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-34vj","type":"parent-child","created_at":"2026-02-20T07:52:51.060629888Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3fon","type":"parent-child","created_at":"2026-02-20T07:52:52.064045315Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3kch","type":"parent-child","created_at":"2026-02-20T07:52:52.638673805Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3ksg","type":"parent-child","created_at":"2026-02-20T07:52:52.757658445Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3qh2","type":"parent-child","created_at":"2026-02-20T07:52:53.381094043Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3qt4","type":"parent-child","created_at":"2026-02-20T07:52:53.502675390Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3set","type":"parent-child","created_at":"2026-02-20T07:52:53.743177488Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3tt2","type":"parent-child","created_at":"2026-02-20T07:52:53.862672289Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-3uiy","type":"parent-child","created_at":"2026-02-20T07:52:54.103640305Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-8guj","type":"parent-child","created_at":"2026-02-20T07:52:55.074105128Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-c1co","type":"blocks","created_at":"2026-02-20T07:34:38.400218754Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-pace","type":"parent-child","created_at":"2026-02-20T07:52:56.383154057Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-qozg","type":"parent-child","created_at":"2026-02-20T07:52:56.422922409Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-skw6","type":"parent-child","created_at":"2026-02-20T07:52:56.543146588Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-twz2","type":"parent-child","created_at":"2026-02-20T07:52:56.710339731Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-395m","depends_on_id":"bd-zzgz","type":"parent-child","created_at":"2026-02-20T07:52:57.332760489Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-39f0","title":"[10.12] Define secure extension reputation graph schema with provenance, behavior evidence, revocation edges, and trust transitions.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Define secure extension reputation graph schema with provenance, behavior evidence, revocation edges, and trust transitions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:40.716047938Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.981371273Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-3a5e","title":"[10.13] Route all high-impact safety actions through `franken-decision` decision contracts with explicit loss matrices and fallback policies.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Route all high-impact safety actions through `franken-decision` decision contracts with explicit loss matrices and fallback policies.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:42.954526812Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.717289517Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-3ab3","title":"[10.15] Build verifier pipeline that validates signature chain, transparency log proofs, and attestation chain in one deterministic command.","description":"## Plan Reference\nSection 10.15 (Delta Moonshots Execution Track), subsection 9I.1 (TEE-Bound Cryptographic Decision Receipts), item 3 of 4.\n\n## What\nBuild a unified verifier pipeline that validates all three trust layers of a TEE-bound receipt in one deterministic command: (1) cryptographic signature validity, (2) transparency-log inclusion and consistency proofs, and (3) attestation-chain validity proving the receipt was produced by approved measured software.\n\n## Detailed Requirements\n1. Single CLI command (`franken-verify receipt <receipt_id>`) that returns a structured pass/fail verdict with per-layer detail.\n2. Signature verification layer:\n   - Validate receipt signature against the attested signer key.\n   - Verify signature preimage matches canonical receipt encoding.\n   - Check key is not revoked against current revocation sources.\n3. Transparency-log verification layer:\n   - Verify inclusion proof (receipt is in the log).\n   - Verify consistency proof (log has not been tampered with since receipt was appended).\n   - Validate log checkpoint signature against known log operator keys.\n4. Attestation-chain verification layer:\n   - Verify TEE quote signature against platform trust roots.\n   - Check measurement digest is in the approved measurements list from the active TEE attestation policy.\n   - Validate freshness window (quote is not stale per policy).\n   - Check platform revocation status.\n5. Output must be a deterministic structured artifact (JSON) suitable for evidence ledger ingestion.\n6. Verification must be fully offline-capable with cached revocation/policy data, with explicit staleness warnings.\n7. Exit codes must be distinct for each failure class (signature fail, log fail, attestation fail, stale data).\n\n## Rationale\nFrom 9I.1: \"Verifier toolkit checks three layers: cryptographic signature validity, transparency-log inclusion/consistency, and attestation-chain validity proving receipt was produced by approved measured software.\" A unified pipeline ensures no layer is accidentally skipped and makes independent verification practical for external auditors and automated CI gates.\n\n## Testing Requirements\n- Unit tests: each verification layer independently with valid/invalid/tampered inputs, boundary conditions on freshness windows, expired keys, revoked platforms.\n- Integration tests: full pipeline with mock TEE quote, real signature, and test transparency log; verify correct pass and each distinct failure mode.\n- Adversarial tests: tampered receipts, replayed quotes with wrong nonces, log inconsistency injection, measurement substitution.\n- Performance test: verify pipeline completes within acceptable latency for batch verification scenarios.\n\n## Implementation Notes\n- Consider streaming/batch mode for verifying large receipt sets efficiently.\n- Log verification should support both RFC 6962 (Certificate Transparency) style and custom transparency log formats.\n- The verifier must not require network access to the TEE platform for quote verification if trust roots and revocation data are cached.\n\n## Dependencies\n- bd-2xu5 (TEE attestation policy for trust roots and approved measurements).\n- bd-1r25 (receipt schema with attestation bindings).\n- 10.10 (deterministic serialization for receipt parsing).\n- 10.11/10.12 (transparency log infrastructure).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:47.330897951Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.047526424Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3ai","title":"[10.10] Split principal key roles into signing/encryption/issuance and enforce independent revocation.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Split principal key roles into signing/encryption/issuance and enforce independent revocation.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:30.538665659Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.443171539Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3azm","title":"[10.14] Add an ADR declaring `/dp/frankensqlite` as the required substrate for SQLite-backed control-plane persistence in FrankenEngine.","description":"## Plan Reference\nSection 10.14, item 4. Cross-refs: AGENTS.md sibling-repo policy, docs/REPO_SPLIT_CONTRACT.md, Section 13 success criterion (all SQLite persistence through frankensqlite).\n\n## What\nAdd an ADR declaring /dp/frankensqlite as the required substrate for all SQLite-backed control-plane persistence in FrankenEngine.\n\n## Detailed Requirements\n- ADR declares frankensqlite as canonical SQLite substrate\n- Scope: all control-plane persistence (replay index, evidence index, benchmark ledger, policy cache, witness stores, lineage logs)\n- WAL/PRAGMA tuning handled by frankensqlite, not local code\n- Schema migration handled by frankensqlite primitives\n- Exception process for cases where raw SQLite is justified\n\n## Rationale\nSection 13 requires: 'all SQLite-backed control-plane persistence in FrankenEngine is delivered through /dp/frankensqlite integration.' Centralizing SQLite usage prevents inconsistent WAL configs, duplicate schema migration logic, and fragmented data access patterns. frankensqlite provides tested, deterministic SQLite operations.\n\n## Testing Requirements\n- ADR document validation: required sections present\n- CI lint: new rusqlite/sqlite dependencies trigger review requirement\n\n## Dependencies\n- Blocks: persistence inventory (bd-1ps3), storage adapter (bd-89l2), migration policy (bd-30vf), all frankensqlite stores in 10.15\n- Blocked by: nothing (governance document)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:45.221039936Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.595996702Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-3b5m","title":"[10.12] Implement runtime decision scoring with explicit expected-loss and attacker-ROI outputs.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Implement runtime decision scoring with explicit expected-loss and attacker-ROI outputs.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:40.555565450Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.027485337Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-3bc","title":"[10.10] Reject non-canonical encodings for security-critical object classes (no silent normalization).","description":"## Plan Reference\nSection 10.10, item 2. Cross-refs: 9E.1 (Canonical object identity discipline - \"Silent normalization is forbidden for these classes: non-canonical forms are rejected\"), Top-10 links #1, #3, #7, #10.\n\n## What\nImplement strict rejection of non-canonical encodings for all security-critical object classes. When a security-critical object is deserialized, any encoding that does not match the single canonical form must be rejected with an explicit error rather than silently normalized. This applies to policy objects, evidence records, revocations, signed manifests, capability tokens, checkpoints, and attestation objects.\n\n## Detailed Requirements\n- Define a `CanonicalityCheck` trait/interface that every security-critical object deserializer must implement\n- On deserialization, perform a canonicality check: re-serialize the parsed object and compare byte-for-byte with the input; if they differ, reject with `NonCanonicalEncoding` error\n- Rejection must be hard failure (not warning, not silent fix-up) - the object must not enter any processing pipeline\n- Enumerate all security-critical object classes in a registry (the same registry used by EngineObjectId domain separation tags)\n- For each registered class, the deserializer must be wrapped with canonicality enforcement; it must be impossible to bypass\n- Non-canonical encoding detection must cover: field ordering differences, duplicate fields, non-minimal integer encodings, non-minimal length encodings, trailing garbage bytes, BOM/whitespace padding, alternative representations of the same semantic value\n- Emit structured error logs on rejection with: object class, input hash, specific canonicality violation type, and source/origin metadata\n- Provide a `is_canonical(bytes) -> Result<(), NonCanonicalDetail>` standalone check function for pre-validation\n- The enforcement must be applied at every trust boundary (network ingress, storage retrieval, IPC receipt)\n\n## Rationale\nFrom plan section 9E.1: \"Silent normalization is forbidden for these classes: non-canonical forms are rejected. This reduces signature ambiguity, prevents cross-implementation drift, and makes replay/audit state deterministic across machines.\" Silent normalization is a well-known source of signature malleability and cross-implementation bugs. If two implementations normalize differently, they may compute different IDs or signatures for semantically identical objects, breaking verification. By rejecting non-canonical forms at the boundary, the system ensures that every byte sequence has at most one valid interpretation, eliminating an entire class of ambiguity attacks.\n\n## Testing Requirements\n- Unit tests: craft non-canonical encodings for each violation type (reordered fields, duplicate keys, non-minimal integers, trailing bytes, etc.) and verify hard rejection\n- Unit tests: verify canonical encodings pass through successfully\n- Unit tests: verify error detail includes specific violation type and object class\n- Unit tests: verify rejection cannot be bypassed by calling internal deserializers directly (enforced at trait level)\n- Property tests: for any object, `serialize(deserialize(canonical_bytes))` must equal `canonical_bytes`; for any non-canonical variant, `deserialize` must fail\n- Integration tests: send non-canonical objects over network/IPC boundary and verify rejection with appropriate error codes\n- Fuzz tests: random byte mutations of canonical objects should either deserialize identically or be rejected (no silent normalization)\n\n## Implementation Notes\n- Implement as a deserializer wrapper/middleware that sits between raw bytes and domain object construction\n- The re-serialize-and-compare approach is the most robust canonicality check but has 2x serialization cost; for hot paths, consider incremental checks during parsing (e.g., verify field order as fields are encountered)\n- This module is tightly coupled with the deterministic serialization module (bd-2t3) - they share the canonical form definition\n- Consider a compile-time annotation (`#[security_critical]`) that auto-wraps deserializers with canonicality enforcement\n- Log all rejections to the audit chain (bd-1lp) for forensic analysis\n\n## Dependencies\n- Depends on: bd-2t3 (deterministic serialization module defines what \"canonical\" means), bd-2y7 (EngineObjectId registry for security-critical object class enumeration)\n- Blocks: bd-1b2 (signature preimage contract relies on canonical-only inputs), bd-26o (conformance suite tests canonicality rejection), bd-3kd (golden vectors include non-canonical rejection cases)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:29.279236382Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.812112540Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3bz4","title":"[15] Implement ecosystem capture strategy for platform adoption and migration.","description":"## Plan Reference\nSection 15: Ecosystem Capture Strategy\n\n## What\nFrankenEngine should not only outperform incumbents; it should become the default platform for high-trust extension ecosystems. This bead covers the full ecosystem capture strategy.\n\n## Execution Pillars\n1. **Signed extension registry**: Enforceable provenance, attestation, and revocation policies for all published extensions\n2. **Migration kits**: Convert existing Node/Bun extension workflows into capability-typed FrankenEngine workflows with deterministic behavior validation\n3. **Enterprise governance hooks**: Policy-as-code pipelines, audit export, and compliance evidence contracts for enterprise adoption\n4. **Reputation graph APIs**: Ecosystem-wide trust sharing and rapid incident response across the extension ecosystem\n5. **Partner program**: Early lighthouse adopters who validate category-shift outcomes in production environments\n\n## Adoption Targets\n- **Greenfield onboarding**: Minimal-friction deterministic safe-extension setup workflow for new users\n- **Migration validation**: Representative Node/Bun extension packs migrated with deterministic behavior validation artifacts proving equivalence\n- **Public case studies**: Documented real-world deployments showing materially improved security and operational outcomes\n\n## Rationale\nThe plan states: 'FrankenEngine should not only outperform incumbents; it should become the default platform for high-trust extension ecosystems.' This means the technical advantages (3x performance, deterministic security, proof-carrying decisions) must be coupled with practical adoption infrastructure. Without migration kits, enterprise hooks, and ecosystem trust mechanisms, technical superiority alone will not drive adoption.\n\n## Dependencies\n- Requires signed extension registry from 10.10 (FCP-Inspired Hardening)\n- Requires reputation graph from 10.12 (Frontier Programs)\n- Requires capability-typed IR from 10.2 (VM Core) for migration kits\n- Requires benchmark suite from 10.6/14 for case study evidence\n- Requires franken_node compatibility from Phase D for migration targets\n\n## Testing Requirements\n- Integration tests for migration kit: convert sample Node extension, verify capability-typed output, validate behavioral equivalence via lockstep\n- E2E test for greenfield onboarding workflow: new user can create, validate, and deploy a capability-typed extension with deterministic setup\n- Test for enterprise governance hook: policy-as-code pipeline validates extension, exports audit trail, produces compliance evidence\n- Test for reputation graph API: trust queries return correct scores, revocation events propagate to trust scores\n\n## Implementation Notes\n- Migration kits should leverage the tri-runtime lockstep oracle (9F.6) for behavior validation\n- Enterprise governance hooks should consume decision contracts and evidence ledgers from asupersync integration (10.13)\n- Signed registry should use FCP-inspired identity and revocation primitives from 10.10\n- Partner program should produce the case studies required by Section 16 (Scientific Contributions)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.\n\n## Scope Boundary\\nThis bead is the section-level ecosystem execution umbrella aligning adoption/migration activities into one program-facing deliverable without removing any detailed Section 15 capabilities.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:46:21.021289385Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.644839765Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["adoption","detailed","ecosystem","migration","plan","section-15","strategy"]}
{"id":"bd-3c1","title":"[10.7] Add stress tests for high-concurrency extension workloads.","description":"## Plan Reference\nSection 10.7 (Conformance + Verification), item 5.\nRelated: 9A.8 (Deterministic per-extension resource budgets with explicit exhaustion semantics), 9F.10 (SLO-Proven Scheduler), Phase B exit gate (containment without host compromise), 10.5 (Extension Host + Security), 10.11 (Concurrency + Scheduling primitives).\n\n## What\nBuild a stress-testing suite that validates FrankenEngine's correctness, stability, and resource-enforcement guarantees under high-concurrency extension workloads, including concurrent extension lifecycle operations, parallel hostcall storms, resource-budget exhaustion races, and adversarial scheduling pressure.\n\n## Detailed Requirements\n1. **Workload families:** Define and implement at least five stress-workload families:\n   - **Lifecycle storm:** N extensions (N >= 100) performing concurrent load/init/activate/deactivate/unload cycles with randomized timing and injected failures (OOM during init, timeout during activate, crash during hostcall).\n   - **Hostcall flood:** M extensions each issuing K hostcalls/second (M*K >= 50,000 total hostcall/s) across all hostcall families (fs, net, subprocess, crypto, IPC) with mixed sync/async patterns.\n   - **Budget exhaustion race:** Extensions designed to simultaneously hit CPU, memory, IO, and hostcall-rate budget limits, validating that exhaustion transitions (`throttle -> sandbox -> suspend -> terminate`) occur deterministically and do not deadlock or corrupt shared state.\n   - **Noisy neighbor isolation:** One adversarial extension consuming maximum resources while N-1 well-behaved extensions run latency-sensitive workloads. Validate that well-behaved extension p99 latency does not degrade beyond a configurable bound (default: 2x baseline).\n   - **Quarantine cascade:** Trigger simultaneous quarantine of Q extensions (Q >= 10) while other extensions are mid-operation, validating that quarantine is atomic per-extension and does not cause cross-extension corruption or lost evidence.\n2. **Concurrency parameters:** All workloads are parameterized by concurrency level (extensions, threads, hostcalls/s) and run at multiple scales (small: 10 ext, medium: 100 ext, large: 1000 ext) with configurable duration (default: 60s per scenario).\n3. **Invariant checks during stress:**\n   - No data races detected (run under ThreadSanitizer where applicable).\n   - No use-after-free or double-free (run under AddressSanitizer where applicable).\n   - No deadlocks (watchdog timer kills the test after 2x expected duration).\n   - All budget exhaustion transitions logged with correct ordering.\n   - All evidence artifacts produced (no lost events under load).\n   - Memory usage remains bounded (no unbounded growth over the test duration).\n4. **Deterministic seed:** Each scenario uses a fixed PRNG seed for timing jitter, failure injection, and workload selection. Same seed produces same event ordering (modulo true OS scheduling non-determinism, which is logged and tolerated with explicit annotation).\n5. **Structured logging:** Per-scenario log: `trace_id`, `scenario_id`, `workload_family`, `concurrency_level`, `duration_s`, `total_hostcalls`, `total_lifecycle_events`, `invariant_violations`, `peak_memory_bytes`, `p50_latency_us`, `p95_latency_us`, `p99_latency_us`, `budget_exhaustion_events`, `quarantine_events`.\n6. **Evidence artifact:** Produce `stress_evidence.jsonl` with per-scenario results, aggregate invariant-violation count, environment fingerprint, sanitizer configuration, and run manifest.\n7. **CI integration:** Stress tests run on a dedicated CI tier (not blocking fast-feedback CI, but blocking release candidates). Minimum: medium-scale (100 ext) runs on every release candidate; large-scale (1000 ext) runs weekly.\n\n## Rationale\nConcurrency bugs are the most dangerous class of defects in a multi-extension runtime: they are non-deterministic, hard to reproduce, and can cause silent data corruption or security bypass. The plan explicitly requires deterministic resource budgets with explicit exhaustion semantics (9A.8) and SLO-proven scheduling (9F.10). Stress tests are the only way to validate these guarantees hold under realistic concurrent pressure, not just in isolated unit tests.\n\n## Testing Requirements (Meta-Tests for Test Infrastructure)\n1. **Invariant checker correctness meta-test:** Inject a synthetic data race (e.g., unsynchronized counter increment) and confirm the stress framework detects it. Inject a synthetic deadlock and confirm the watchdog kills and reports it.\n2. **Seed determinism meta-test:** Run the same scenario with the same seed twice and confirm identical event counts (hostcalls, lifecycle events, budget exhaustion events) within tolerance.\n3. **Scale parameter meta-test:** Run at small scale (10 ext) and confirm completion within 2x the expected duration. Confirm large-scale parameters are accepted and produce proportionally more events.\n4. **Evidence completeness meta-test:** Run a scenario and confirm every expected field in `stress_evidence.jsonl` is present and non-null. Confirm hostcall counts match actual issued hostcalls (instrumented separately).\n5. **Sanitizer integration meta-test:** Run a small scenario under both TSan and ASan and confirm the framework correctly reports sanitizer findings (or clean exit if none).\n\n## Implementation Notes\n- Stress suite lives under `tests/stress/` with per-workload-family modules.\n- Extension stubs for stress testing are minimal Rust modules implementing the extension trait with configurable behavior (hostcall pattern, resource consumption, failure injection points).\n- Budget exhaustion scenarios require the 10.11 scheduler and 10.5 resource-budget enforcement to be functional.\n- Sanitizer builds are maintained as separate CI profiles (`profile.stress-tsan`, `profile.stress-asan`).\n- Large-scale tests may require dedicated CI hardware; document minimum hardware requirements in `tests/stress/HARDWARE_REQUIREMENTS.md`.\n- Integrates with `rch`-wrapped commands for heavy compilation and parallel execution.\n\n## Dependencies\n- Upstream: 10.5 (Extension Host: lifecycle, containment, hostcall gating), 10.11 (Concurrency + Scheduling: scheduler lanes, budget enforcement, cancellation protocol), 10.2 (VM Core evaluator).\n- Downstream: 10.8 (Operational Readiness: stress test results feed the operational readiness report), 10.9 Phase E exit gate.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:26.603186612Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.704132777Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-3c8n","title":"[16] At least 2 externally replicated high-impact claims.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: At least 2 externally replicated high-impact claims.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:37.267143165Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:36.722625195Z","closed_at":"2026-02-20T07:46:37.785839076Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-3ch","title":"[10.4] Module + Runtime Surface - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.4: Module + Runtime Surface\n\n## Overview\nThis epic covers module resolution, caching, and compatibility for FrankenEngine's module system. This is the bridge between the VM core and the franken_node compatibility surface (Phase D).\n\n## Child Beads\n- bd-tgv: Implement module resolver trait with policy hooks (foundational)\n- bd-16x: Implement module cache invalidation strategy\n- bd-3vp: Add explicit compatibility mode matrix for Node/Bun module edge cases\n\n## Dependency Chain\nbd-tgv (resolver) → bd-16x (cache invalidation) → bd-3vp (compatibility matrix)\n\n## Key Requirements\n- Policy hooks at resolution time for capability enforcement\n- Cache invalidation on trust revocation events\n- No hidden shims for compatibility (explicit, testable, documented)\n- Support both ESM and CJS for Phase D Node/Bun superset\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.430649522Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:11.117359149Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-4"],"dependencies":[{"issue_id":"bd-3ch","depends_on_id":"bd-16x","type":"parent-child","created_at":"2026-02-20T07:52:43.106419710Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3ch","depends_on_id":"bd-3vp","type":"parent-child","created_at":"2026-02-20T07:52:54.342897805Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3ch","depends_on_id":"bd-ntq","type":"blocks","created_at":"2026-02-20T07:32:55.522152454Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3ch","depends_on_id":"bd-tgv","type":"parent-child","created_at":"2026-02-20T07:52:56.630112200Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ciq","title":"[10.15] Implement delegate-cell runtime harness for not-yet-native slots with explicit capability envelopes, sandbox controls, and replay hooks.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement delegate-cell runtime harness for not-yet-native slots with explicit capability envelopes, sandbox controls, and replay hooks.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:54.063910753Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.095276142Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3db2","title":"[14] No work dropping, relaxed durability, or disabled policy checks to inflate throughput.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: No work dropping, relaxed durability, or disabled policy checks to inflate throughput.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:30.185215499Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:36.849935122Z","closed_at":"2026-02-20T07:41:20.924285308Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-3de4","title":"[14] Include both performance and security co-metrics (not speed-only benchmarks).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Include both performance and security co-metrics (not speed-only benchmarks).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:27.810159997Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:36.900931808Z","closed_at":"2026-02-20T07:41:21.924584896Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-3e7","title":"[10.11] Add append-only hash-linked decision marker stream for high-impact security/policy transitions.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add append-only hash-linked decision marker stream for high-impact security/policy transitions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:37.318303109Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.368012473Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-3ebk","title":"[16] Open specifications for core trust/replay/policy primitives.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: Open specifications for core trust/replay/policy primitives.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:36.038965842Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:36.990677818Z","closed_at":"2026-02-20T07:46:58.631056580Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-3fon","title":"[13] high-risk detections reach containment in `<= 250ms` median time under defined load envelopes","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: high-risk detections reach containment in `<= 250ms` median time under defined load envelopes\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:20.672412706Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:37.030712326Z","closed_at":"2026-02-20T07:40:00.207375906Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3fr","title":"Add runtime charter codifying native-only engine policy","description":"Implements PLAN section 10.1 first TODO: add a runtime charter document that formalizes FrankenEngine's native-only execution doctrine and non-negotiable boundaries. Include explicit prohibition of binding-led execution cores and define acceptance criteria for architectural changes.","status":"closed","priority":1,"issue_type":"task","assignee":"StormyPond","created_at":"2026-02-20T07:23:21.056176395Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:37.111244084Z","closed_at":"2026-02-20T07:24:14.801246681Z","close_reason":"Added docs/RUNTIME_CHARTER.md and linked it from README to codify native-only runtime governance contract","source_repo":".","compaction_level":0,"original_size":0,"labels":["architecture","governance","plan","section-10-1"]}
{"id":"bd-3g4","title":"[10.0] Top-10 #4: Alien-performance profile discipline and hotpath program gates (strategy: `9A.4`; deep semantics: `9F.1`, `9F.12`, `9F.14`; execution owners: `10.6`, `10.12`).","description":"## Plan Reference\nSection 10.0 item 4. Strategy: 9A.4. Deep semantics: 9F.1 (Verified Adaptive Compiler), 9F.12 (Zero-Copy Capability IPC), 9F.14 (Autopilot Performance Scientist). Enhancement maps: 9B.4 (EBR lock-free, allocator, S3-FIFO cache), 9C.4 (experiment with prior/posterior/stopping), 9D.4 (hotspot matrices, staged optimization rounds).\n\n## What\nStrategic tracking bead for Initiative #4: Alien-performance core with strict profile-first optimization discipline. Performance is governed by baseline/profile/prove/implement/verify loops with artifact-backed evidence.\n\n## Execution Owners\n- **10.6** (Performance Program): benchmark suite, denominator calculator, flamegraphs, opportunity matrix, one-lever policy\n- **10.12** (Frontier Programs): proof-carrying optimizer, translation-validation gates, autopilot performance scientist\n\n## Strategic Rationale (from 9A.4)\n'To achieve world-class performance without regressions by turning optimization into a measurable systems practice rather than intuition-driven tuning.'\n\n## Key Deliverables\n- Baseline/profile/prove/implement/verify loop enforced by CI\n- One optimization lever per commit with opportunity score >= 2.0\n- >= 3x weighted geometric mean throughput vs Node and Bun\n- Confidence intervals for p50/p95/p99 improvements\n- VOI-guided experiment selection for next optimization target\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:19.640070759Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.219849244Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-3gsv","title":"[10.12] Implement third-party verifier toolkit that can independently validate benchmark, replay, and containment claims.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Implement third-party verifier toolkit that can independently validate benchmark, replay, and containment claims.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:41.339396718Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.806010982Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-3h31","title":"[14] Compute suite score `S_B = exp(sum_i w_i * ln(r_i))`, with non-zero weights summing to `1` and equal weighting across family/profile cells by default.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Compute suite score `S_B = exp(sum_i w_i * ln(r_i))`, with non-zero weights summing to `1` and equal weighting across family/profile cells by default.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:30.676909298Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:37.232328555Z","closed_at":"2026-02-20T07:41:20.725587397Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-3h61","title":"[14] Require reproducibility artifacts for every published result.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Require reproducibility artifacts for every published result.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:28.043791177Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:37.272628628Z","closed_at":"2026-02-20T07:41:21.819283503Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-3hj","title":"[10.0] Top-10 #5: Supply-chain trust fabric integrated with containment policy (strategy: `9A.5`; deep semantics: `9F.11`, `9F.9`; execution owners: `10.10`, `10.12`, `10.13`).","description":"## Plan Reference\nSection 10.0 item 5. Strategy: 9A.5. Deep semantics: 9F.11 (Semantic Build Graph), 9F.9 (Revocation Mesh SLO). Enhancement maps: 9B.5 (progressive delivery, authenticated data structures, macaroon attenuation), 9C.5 (posterior trust distributions, hazard decay), 9D.5 (trust-check path profiling).\n\n## What\nStrategic tracking bead for Initiative #5: Supply-chain trust fabric integrated with runtime containment actions. Install-time trust must be coupled to runtime behavior controls.\n\n## Execution Owners\n- **10.10** (FCP-Inspired Hardening): EngineObjectId, policy checkpoints, capability tokens, key attestation, revocation chain\n- **10.12** (Frontier Programs): trust-economics model, reputation graph, fleet immune system\n- **10.13** (Asupersync Integration): control-plane adapter, decision contracts for trust actions\n\n## Strategic Rationale (from 9A.5)\n'Static provenance alone is insufficient if runtime behavior goes malicious later. Close the gap between package-level trust and live runtime risk.'\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:19.764889026Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.174820032Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-3hkk","title":"[10.15] Implement declassification decision pipeline (`request -> policy/loss evaluation -> allow/deny -> signed receipt`) with deterministic replay.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement declassification decision pipeline (`request -> policy/loss evaluation -> allow/deny -> signed receipt`) with deterministic replay.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:52.505599946Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.526295953Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3ix","title":"[10.11] Add systematic interleaving explorer coverage for checkpoint/revocation/policy-update race surfaces.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add systematic interleaving explorer coverage for checkpoint/revocation/policy-update race surfaces.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:34.644665211Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.549578295Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-3j5s","title":"[15] Public case studies showing materially improved security and operational outcomes.","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Public case studies showing materially improved security and operational outcomes.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:35.820092460Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:37.432641968Z","closed_at":"2026-02-20T07:45:33.991333421Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-3jg","title":"[10.2] Implement static flow-check pass proving source/sink legality and emitting flow-proof witness artifacts.","description":"## Plan Reference\nSection 10.2, item 5. Cross-refs: 9I.7 (IFC), 9C.1 (proof-carrying compilation), 10.15 (IFC artifacts).\n\n## What\nImplement a static analysis pass over IR2 that proves source-to-sink data flow legality using the IFC flow-lattice, and emits flow-proof witness artifacts for audit and replay.\n\n## Detailed Requirements\n- Analyze IR2 data flow paths to verify all source→sink flows comply with flow-lattice constraints\n- Emit flow-proof witness artifact for each analyzed extension/module containing: proved flows, denied flows, required declassifications\n- Reject compilation when unauthorized flows are detected (fail-closed)\n- Handle dynamic/late-bound paths by inserting runtime check points (runtime enforcement for paths that cannot be statically proven)\n- Witness artifacts must be deterministically serializable for evidence graph linkage\n\n## Rationale\nPer 9I.7: static compiler checks prove allowed flows where possible; runtime checks cover dynamic/late-bound paths. The flow-check pass is the static half of this design. It feeds into the evidence graph (9A.3) and enables the proof-guided specialization flywheel (9I.8) - regions with proven-safe IFC can have flow checks elided at runtime.\n\n## Testing Requirements\n- Unit tests: pass accepts code with only authorized flows\n- Unit tests: pass rejects code with unauthorized source→sink flows\n- Unit tests: pass correctly identifies flows requiring declassification\n- Unit tests: witness artifact contains correct flow analysis results\n- IFC conformance corpus tests (10.7): benign dual-capability, exfil-attempt, declassification-exception workloads\n\n## Dependencies\n- Blocked by: IFC flow-lattice semantics (bd-1fm), lowering pipelines (bd-ug9)\n- Blocks: runtime flow-label propagation (10.5), PLAS flow envelope synthesis (10.15), proof-guided specialization (10.15)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.933103541Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.533163392Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-3jy","title":"[10.5] Route all declassification requests through decision contracts with mandatory signed receipt + evidence linkage.","description":"## Plan Reference\nSection 10.5, item 10 (Route all declassification requests through decision contracts). Cross-refs: 9I.7 (IFC + Deterministic Exfiltration Prevention - declassification must be explicit and auditable), 9F.5 (Cryptographic Decision Receipts - every declassification produces a signed receipt), 9C.2 (decision loop applies to declassification decisions).\n\n## What\nImplement the declassification gateway: the single, mandatory path through which any request to downgrade a flow label (reduce secrecy level or increase integrity level) must pass. Declassification is the controlled exception to the IFC invariant \"data never flows to a less-secure sink.\" Every declassification request must be evaluated by a decision contract that specifies: who is requesting, what data, from what label to what label, for what purpose, and with what justification. The decision contract produces a cryptographic decision receipt (9F.5) that serves as a permanent, tamper-evident audit record. No declassification can occur without a receipt. Unauthorized declassification attempts are treated as exfiltration attempts and reported as high-severity evidence to the Guardplane.\n\n## Detailed Requirements\n- Define `DeclassificationRequest` struct: `{ request_id: RequestId, requester: ExtensionId, data_ref: DataRef, current_label: FlowLabel, target_label: FlowLabel, purpose: DeclassificationPurpose, justification: String, timestamp_ns: u64 }`.\n- Define `DeclassificationPurpose` enum: `UserConsent`, `AggregationAnonymization`, `PublicApiResponse`, `DiagnosticExport`, `OperatorOverride`, `Custom(String)`.\n- Define `DecisionContract` trait with method: `evaluate(request: &DeclassificationRequest) -> DecisionVerdict`. Contracts are composable: multiple contracts can be chained (all must approve).\n- `DecisionVerdict` enum: `Approved { conditions: Vec<Condition> }`, `Denied { reason: DenialReason }`, `Deferred { challenge: Challenge }`.\n- Implement built-in decision contracts:\n  - `RequesterCapabilityContract` - requester must hold the `Declassify` capability in their manifest.\n  - `LabelDistanceContract` - declassification must not skip more than one secrecy level at a time (e.g., `Secret` -> `Confidential` is allowed, `Secret` -> `Public` is denied without operator override).\n  - `PurposeValidityContract` - purpose must be one of the allowed purposes for the target label level.\n  - `RateLimitContract` - no more than N declassifications per extension per time window (prevents bulk exfiltration via many small declassifications).\n- Implement `CryptographicDecisionReceipt` per 9F.5:\n  - Contains: `receipt_id`, `request_id`, `verdict`, `contract_chain` (which contracts evaluated the request), `posterior_at_decision` (Guardplane's posterior on the requester at decision time), `timestamp_ns`, `signature`.\n  - Signed with the engine's decision-signing key.\n  - Immutable and append-only stored in the decision receipt log.\n  - Must be verifiable offline by an auditor with the engine's public key.\n- Unauthorized declassification handling:\n  - Any attempt to bypass the declassification gateway (e.g., direct label mutation) must be impossible by construction (labels are immutable once assigned, only the gateway can issue a new label).\n  - Any denied declassification request is emitted as `DeclassificationDenied` evidence to the Guardplane with severity proportional to the label distance attempted.\n- All declassification operations must be included in forensic replay traces (bd-t2m).\n\n## Rationale\nDeclassification is the most dangerous operation in an IFC system: it is the controlled way to violate the security invariant. Without rigorous controls, a compromised extension could exfiltrate data by requesting declassification of every piece of sensitive data it handles. The decision contract pattern ensures that declassification is never automatic: it requires explicit evaluation against a policy, produces a permanent receipt, and feeds into the Guardplane's risk assessment. The cryptographic receipt (9F.5) means that every declassification can be audited after the fact, and an attacker cannot forge or suppress evidence of declassification. The rate-limit contract addresses the \"many small leaks\" attack pattern.\n\n## Testing Requirements\n- **Unit tests**: Each built-in decision contract independently: `RequesterCapabilityContract` approves/denies based on manifest capabilities. `LabelDistanceContract` allows one-level and denies multi-level downgrades. `RateLimitContract` denies after exceeding threshold.\n- **Contract composition tests**: Chain multiple contracts; verify all-must-approve semantics. One denial in the chain results in overall denial.\n- **Receipt tests**: Verify receipt contains all required fields, is correctly signed, and is verifiable with the public key. Verify receipt is append-only stored and cannot be deleted.\n- **Unauthorized attempt tests**: Attempt to mutate a `FlowLabel` directly (should be impossible at the type level). Attempt declassification without the `Declassify` capability; verify denial + Guardplane evidence.\n- **Integration tests**: Full flow: extension requests declassification -> contracts evaluate -> receipt produced -> label changed (if approved) -> subsequent hostcalls use new label. Verify the entire chain is captured in telemetry and forensic traces.\n- **Rate limit tests**: Extension makes rapid declassification requests; verify rate limit kicks in and subsequent requests are denied.\n\n## Implementation Notes\n- `FlowLabel` immutability is enforced by making the struct fields private and providing no public setter. The only way to get a new label is through the declassification gateway's return value.\n- The `DecisionContract` trait should be `Send + Sync + 'static` for use in async contexts.\n- The decision-signing key should be loaded from a secure key store; for testing, use a deterministic test key.\n- The receipt log can share the same append-only storage infrastructure as the telemetry recorder (bd-5pk).\n- Consider making `DeclassificationPurpose` extensible via the typed policy DSL (9A.7) so operators can define custom purposes.\n\n## Dependencies\n- **Blocked by**: bd-1hw (flow-label propagation provides the label infrastructure), bd-5pk (telemetry for recording declassification events), bd-3md (Guardplane posterior is included in receipts), bd-1y5 (decision framework for denied-request escalation).\n- **Blocks**: Full IFC enforcement (9I.7 cannot be complete without controlled declassification). Phase B exit gate (security subsystems must be active and integrated).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:25.084975407Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.471587598Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-3jz8","title":"[10.15] Implement budget accountant for differential privacy with epoch-scoped burn tracking and hard fail-closed budget exhaustion behavior.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement budget accountant for differential privacy with epoch-scoped burn tracking and hard fail-closed budget exhaustion behavior.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:47.823976890Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.903310593Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3kch","title":"[13] post-burn-in false-deny rate for PLAS-enforced policies remains <= 0.5% on defined benign extension corpora","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: post-burn-in false-deny rate for PLAS-enforced policies remains <= 0.5% on defined benign extension corpora\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:25.462814610Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:37.592752058Z","closed_at":"2026-02-20T07:39:57.987420819Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3kd","title":"[10.10] Add golden vectors for critical binary encodings and verification paths.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Add golden vectors for critical binary encodings and verification paths.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:32.691915950Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.818089110Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3kks","title":"[10.15] Implement runtime capability escrow pathway for out-of-envelope requests (`challenge`/`sandbox` default), including explicit emergency-grant artifact format and expiry semantics.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement runtime capability escrow pathway for out-of-envelope requests (`challenge`/`sandbox` default), including explicit emergency-grant artifact format and expiry semantics.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:50.801745266Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.157993462Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3ksg","title":"[13] category benchmark standard is adopted by external runtime/security research participants","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: category benchmark standard is adopted by external runtime/security research participants\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:23.650704726Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:37.712755154Z","closed_at":"2026-02-20T07:39:58.788546781Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3lt3","title":"[10.15] Add frankentui operator surfaces for flow decisions (`label map`, `blocked flows`, `declassification history`, `confinement proofs`).","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankentui operator surfaces for flow decisions (`label map`, `blocked flows`, `declassification history`, `confinement proofs`).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:53.550205413Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.234066327Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3md","title":"[10.5] Implement Bayesian posterior updater API.","description":"## Plan Reference\nSection 10.5, item 4 (Implement Bayesian posterior updater API). Cross-refs: 9A.2 (Probabilistic Guardplane - Bayesian + sequential inference), 9C.2 (full Bayesian decision loop: classify -> quantify -> decide -> explain -> calibrate), 9B.2 (conformal prediction, e-process, BOCPD for online change detection).\n\n## What\nImplement the core Guardplane inference component that maintains a posterior probability distribution over extension risk states. For each monitored extension, the posterior updater takes hostcall telemetry evidence and updates a Bayesian belief about whether the extension is behaving within its declared capability envelope or exhibiting anomalous/malicious behavior. This is the \"classify + quantify\" stage of the 9C.2 decision loop. The updater supports multiple inference strategies: conjugate-prior updates for simple models, sequential e-process testing for anytime-valid confidence, and Bayesian Online Change Point Detection (BOCPD) for detecting behavioral regime shifts.\n\n## Detailed Requirements\n- Define `RiskState` enum: `Benign`, `Anomalous`, `Malicious`, `Unknown`.\n- Define `Posterior` struct holding probability mass over `RiskState` values: `P(Benign)`, `P(Anomalous)`, `P(Malicious)`, `P(Unknown)`, with invariant that probabilities sum to 1.0 (within floating-point tolerance).\n- Define `Evidence` struct wrapping a `HostcallTelemetryRecord` with derived features: `hostcall_rate`, `capability_usage_pattern`, `resource_consumption_rate`, `timing_anomaly_score`.\n- Implement `BayesianPosteriorUpdater` with methods:\n  - `new(prior: Posterior) -> Self` - initialize with a configurable prior (default: high `P(Benign)` for new extensions).\n  - `update(&mut self, evidence: &Evidence) -> UpdateResult` - perform one Bayesian update step, returning the new posterior and the likelihood ratio.\n  - `posterior(&self) -> &Posterior` - current belief state.\n  - `log_likelihood_ratio(&self) -> f64` - cumulative log-likelihood ratio for sequential testing.\n  - `change_point_probability(&self) -> f64` - BOCPD run-length posterior for regime change detection.\n  - `reset(&mut self, prior: Posterior)` - reset to a new prior (e.g., after containment action).\n  - `calibration_check(&self, ground_truth: RiskState) -> CalibrationResult` - check posterior calibration against known ground truth (for testing/monitoring).\n- Implement likelihood functions for each evidence type:\n  - `hostcall_rate_likelihood(rate: f64, state: RiskState) -> f64` - model hostcall rate distribution per risk state.\n  - `capability_pattern_likelihood(pattern: &CapabilityPattern, state: RiskState) -> f64` - model capability usage patterns.\n- All floating-point operations must be deterministic (no platform-dependent rounding). Use `f64` with explicit rounding where needed.\n- The updater must be serializable for checkpoint/replay.\n- Implement the BOCPD component: maintain a run-length distribution and detect when the generative model changes (indicating behavioral regime shift).\n\n## Rationale\nThe Probabilistic Guardplane (9A.2) is the security decision backbone of FrankenEngine. Unlike traditional rule-based systems that produce binary allow/deny decisions, the Bayesian approach maintains calibrated uncertainty over extension risk. This enables the expected-loss action selector (bd-1y5) to make cost-sensitive decisions: a high-uncertainty posterior leads to a \"challenge\" or \"sandbox\" action rather than an immediate terminate. The BOCPD component detects subtle behavioral shifts that would be invisible to threshold-based detection. Per 9C.2, every decision must be explainable by reference to the posterior and evidence chain.\n\n## Testing Requirements\n- **Unit tests**: Posterior initialization sums to 1.0. Single evidence update moves posterior in correct direction (benign evidence increases `P(Benign)`, malicious evidence increases `P(Malicious)`). Multiple sequential updates converge to correct state. Likelihood functions produce valid probabilities. Serialization round-trip preserves posterior exactly.\n- **Calibration tests**: Generate synthetic evidence sequences with known ground truth. Verify that posterior `P(state)` is well-calibrated (e.g., when posterior says P(Malicious) = 0.8, approximately 80% of such cases are truly malicious).\n- **BOCPD tests**: Inject a regime change in synthetic evidence (benign -> malicious at step N). Verify change-point detection triggers within a bounded delay.\n- **Determinism tests**: Run identical evidence sequences on two independent updater instances; verify bit-identical posteriors.\n- **Edge case tests**: All-zero evidence, NaN/infinity guards, underflow protection for very small probabilities, prior with zero mass on some states.\n\n## Implementation Notes\n- Use log-space arithmetic internally to avoid underflow: store `log P(state)` and use `log_sum_exp` for normalization.\n- The conjugate prior for hostcall rate modeling is Gamma-Poisson; for capability patterns, consider Dirichlet-Multinomial.\n- BOCPD implementation follows Adams & MacKay (2007): maintain a vector of run-length probabilities, prune low-probability run lengths for efficiency.\n- Deterministic floating-point: avoid `fast-math`, pin to `f64`, test on CI with the same target triple.\n- The `Evidence` feature extraction from raw `HostcallTelemetryRecord` should be a separate function, not embedded in the updater.\n\n## Dependencies\n- **Blocked by**: bd-5pk (telemetry recorder provides the evidence stream).\n- **Blocks**: bd-1y5 (expected-loss action selector consumes posterior), bd-t2m (forensic replay must reproduce posterior trajectories), bd-2gl (containment actions are triggered by posterior thresholds).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.283640895Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.753880024Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-3mu","title":"[10.10] Add fuzz/adversarial targets for decode DoS, replay/splice handshake attacks, and token verification edge cases.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Add fuzz/adversarial targets for decode DoS, replay/splice handshake attacks, and token verification edge cases.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:32.834784649Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.773767896Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3mx","title":"[10.0] Top-10 #10: Provenance + revocation fabric and recall workflow (strategy: `9A.10`; deep semantics: `9F.9`; execution owners: `10.10`, `10.11`, `10.12`, `10.13`).","description":"## Plan Reference\nSection 10.0 item 10. Strategy: 9A.10. Deep semantics: 9F.9 (Revocation Mesh SLO). Enhancement maps: 9B.10 (key transparency, CT-style logs, threshold signatures, anti-entropy), 9C.10 (safety-critical decision under uncertainty, sequential evidence thresholds), 9D.10 (revocation propagation latency profiling).\n\n## What\nStrategic tracking bead for Initiative #10: Provenance + revocation fabric and recall workflow. Fast trust revocation and quarantine pathways for compromised artifacts.\n\n## Execution Owners\n- **10.10** (FCP-Inspired Hardening): revocation chain objects, freshness policy, trust zones\n- **10.11** (Runtime Systems): anti-entropy reconciliation, proof-carrying recovery\n- **10.12** (Frontier Programs): fleet immune system, trust-economics, reputation graph\n- **10.13** (Asupersync Integration): control-plane adapter, decision contracts for revocation\n\n## Strategic Rationale (from 9A.10)\n'Once compromise is discovered, containment latency is often the deciding factor between nuisance and catastrophe.'\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:20.401176718Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.922910537Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-3n0","title":"[10.10] Enforce cross-zone reference constraints (provenance/audit allowed, authority leakage forbidden).","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Enforce cross-zone reference constraints (provenance/audit allowed, authority leakage forbidden).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:31.956701459Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.028769621Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3nc","title":"[10.11] Implement e-process guardrail integration that can hard-block unsafe automatic retunes.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement e-process guardrail integration that can hard-block unsafe automatic retunes.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:35.225966982Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.364537422Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-3ncx","title":"[10.15] Define moonshot contract schema (`hypothesis`, `target metrics`, `EV model`, `risk budget`, `artifact obligations`, `kill criteria`, `rollback plan`).","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Define moonshot contract schema (`hypothesis`, `target metrics`, `EV model`, `risk budget`, `artifact obligations`, `kill criteria`, `rollback plan`).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:48.311102630Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.777621291Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3nr","title":"[10.13] Asupersync Constitutional Integration Track - Comprehensive Execution Epic","description":"# 10.13 Asupersync Constitutional Integration Track - Comprehensive Execution Epic\n\n## Plan Reference\nSection 10.13 of the FrankenEngine execution plan.\n\n## What\nThis epic governs the integration of asupersync-derived control-plane primitives into FrankenEngine's extension-host subsystem. It does NOT re-implement primitives owned by Section 10.11; it binds those primitives into asupersync-derived control-plane contracts that enforce safety, auditability, and deterministic lifecycle management across the extension-host boundary.\n\n## Scope and Ownership Boundary\n- **10.11 owns**: Cx (capability context), region-based execution cells, cancellation lifecycle, obligation tracking, decision contracts, evidence schema, deterministic replay, frankenlab test harness, and all foundational runtime primitives.\n- **10.13 owns**: The wiring, integration, and verification that those 10.11 primitives are correctly threaded through the extension-host control plane in FrankenEngine, bound to the canonical `/dp/asupersync` crate interfaces (`franken-kernel`, `franken-decision`, `franken-evidence`), and exercised under realistic multi-extension scenarios.\n\n## Architectural Role\n10.13 is the bridge between abstract runtime machinery (10.11) and concrete extension-host security behavior. Where 10.11 defines \"what a Cx is and how cancellation works,\" 10.13 ensures \"every extension-host API carries a Cx, cancellation is enforced on every lifecycle transition, and evidence is emitted for every high-impact action.\"\n\n## Key Deliverables (19 Task Beads)\n1. Formal control-plane adoption ADR (bd-3vlb)\n2. Naming guidance for Cargo packages and Rust crate paths (bd-ypl4)\n3. Dependency policy: no local forks of canonical types (bd-2fa1)\n4. Narrow control-plane adapter layer (bd-23om)\n5. Cx threading through all effectful extension-host APIs (bd-2ygl)\n6. Region-per-extension/session execution cells with quiescent close (bd-1ukb)\n7. Cancellation lifecycle compliance integration (bd-2wz9)\n8. Obligation-tracking integration for two-phase safety-critical operations (bd-m9pa)\n9. Decision contract routing for high-impact safety actions (bd-3a5e)\n10. Canonical evidence emission via franken-evidence (bd-uvmm)\n11. Deterministic evidence replay checks (bd-2sbb)\n12. Frankenlab scenario integration for extension lifecycle (bd-1o7u)\n13. Frankenlab replay as release blocker (bd-24bu)\n14. Interference tests for multiple controllers (bd-2py0)\n15. Compile-time lint/CI guard against ambient authority (bd-11z7)\n16. Migration compatibility tests for schema evolution (bd-3q36)\n17. Benchmark split for control-plane overhead (bd-1rdj)\n18. Fallback validation for deterministic safe mode (bd-jaqy)\n19. Operator-facing control-plane invariants dashboard (bd-36of)\n\n## Design Constraints\n- All integration work must import from `/dp/asupersync` crates; no local re-implementations.\n- Control-plane adapter layer must not pollute VM hot paths.\n- Every high-impact action must flow through decision contracts AND emit evidence.\n- All lifecycle transitions must respect cancellation protocol owned by 10.11.\n- Frankenlab scenario pass/fail must gate releases for security-critical paths.\n\n## Dependencies\n- **Hard dependency on 10.11**: All primitives (Cx, regions, cancellation, obligations, decisions, evidence, replay, frankenlab) originate in 10.11.\n- **Crate availability**: `/dp/asupersync` crates must expose stable public APIs for the types listed in the dependency policy.\n\n## Success Criteria\n- Zero ambient authority in extension-host control paths (enforced by compile-time lint).\n- All effectful extension-host APIs carry Cx with proper lifetime and cancellation semantics.\n- Evidence replay is deterministic and machine-verifiable across hosts.\n- Control-plane overhead is bounded and does not regress VM hot-loop benchmarks.\n- Operator dashboard surfaces all control-plane invariants in real time.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:19.008944962Z","created_by":"ubuntu","updated_at":"2026-02-20T07:58:11.682901264Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-13"],"dependencies":[{"issue_id":"bd-3nr","depends_on_id":"bd-11z7","type":"parent-child","created_at":"2026-02-20T07:52:42.498386321Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-1o7u","type":"parent-child","created_at":"2026-02-20T07:52:45.257921244Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-1rdj","type":"parent-child","created_at":"2026-02-20T07:52:45.620945752Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-1ukb","type":"parent-child","created_at":"2026-02-20T07:52:45.863634823Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-23om","type":"parent-child","created_at":"2026-02-20T07:52:46.559258157Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-24bu","type":"parent-child","created_at":"2026-02-20T07:52:46.599350102Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-2fa1","type":"parent-child","created_at":"2026-02-20T07:52:47.748398453Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-2g9","type":"blocks","created_at":"2026-02-20T07:32:57.630221276Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-2py0","type":"parent-child","created_at":"2026-02-20T07:52:48.950784862Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-2sbb","type":"parent-child","created_at":"2026-02-20T07:52:49.467994834Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-2wz9","type":"parent-child","created_at":"2026-02-20T07:52:50.105054398Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-2ygl","type":"parent-child","created_at":"2026-02-20T07:52:50.458551690Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-36of","type":"parent-child","created_at":"2026-02-20T07:52:51.180436379Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-3a5e","type":"parent-child","created_at":"2026-02-20T07:52:51.506938701Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-3q36","type":"parent-child","created_at":"2026-02-20T07:52:53.301699073Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-3vh","type":"blocks","created_at":"2026-02-20T07:32:57.541284936Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-3vlb","type":"parent-child","created_at":"2026-02-20T07:52:54.303182982Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-jaqy","type":"parent-child","created_at":"2026-02-20T07:52:55.980007768Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-m9pa","type":"parent-child","created_at":"2026-02-20T07:52:56.182715571Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-uvmm","type":"parent-child","created_at":"2026-02-20T07:52:56.830507826Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3nr","depends_on_id":"bd-ypl4","type":"parent-child","created_at":"2026-02-20T07:52:57.128820111Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3o95","title":"[10.14] Build a thin integration template for service endpoints (health, control actions, evidence export, replay control) using `fastapi_rust` conventions/components where relevant.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Build a thin integration template for service endpoints (health, control actions, evidence export, replay control) using `fastapi_rust` conventions/components where relevant.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:46.353647664Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.305836531Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-3oc","title":"[10.12] Build policy theorem compiler passes and machine-check hooks for non-interference and merge determinism.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Build policy theorem compiler passes and machine-check hooks for non-interference and merge determinism.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:39.785361094Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.234786583Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-3ovc","title":"[10.12] Implement low-latency reputation updates and explainable trust-card generation for operators.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Implement low-latency reputation updates and explainable trust-card generation for operators.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:40.869149197Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.935649240Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-3pl","title":"[10.10] Enforce deterministic ordering for multi-signature arrays before verification.","description":"## Plan Reference\nSection 10.10, item 5. Cross-refs: 9E.2 (Deterministic serialization and signature preimage contracts - \"Multi-signature vectors must be sorted by stable signer key ordering before verification\"), Top-10 links #3, #7, #10.\n\n## What\nEnforce deterministic ordering for multi-signature arrays on all objects that carry more than one signature. Before any verification operation, the signature array must be sorted by a stable, canonical ordering of the signer's public key. This eliminates signature-array permutation as a source of non-determinism and prevents malleability attacks based on reordering.\n\n## Detailed Requirements\n- Define a canonical ordering for signer public keys: lexicographic byte ordering of the serialized public key (for same-algorithm keys) or algorithm-OID-then-key-bytes ordering (for mixed-algorithm scenarios)\n- On signature creation: when adding a signature to a multi-sig object, insert it in sorted position; the final signature array must always be sorted\n- On verification: before verifying any signature in the array, assert that the array is sorted according to the canonical ordering; reject with `UnsortedSignatureArray` error if not\n- On deserialization: verify sorting invariant as part of canonicality checking (ties into bd-3bc non-canonical rejection)\n- Support quorum semantics: the sorted array may contain more signatures than the quorum threshold requires; verification checks that at least `k` of `n` signatures are valid from authorized signers\n- Duplicate detection: reject arrays containing duplicate signer keys (same key appearing twice)\n- The ordering must be stable across serialization round-trips and across platforms/languages\n- Document the exact comparison function with byte-level specification\n\n## Rationale\nFrom plan section 9E.2: \"Multi-signature vectors must be sorted by stable signer key ordering before verification. This gives language-agnostic signature reproducibility and shuts down malleability via field/order differences.\" Without deterministic ordering, the same set of signatures can be serialized in n! different ways, creating signature malleability. An attacker could reorder signatures to create a \"different\" object that passes verification but has a different hash/ID, breaking audit trails and cache consistency. Enforcing sorted order eliminates this degree of freedom.\n\n## Testing Requirements\n- Unit tests: create multi-sig objects with signatures in random order, verify automatic sorting on creation\n- Unit tests: verify deserialization rejects unsorted signature arrays\n- Unit tests: verify duplicate signer key detection and rejection\n- Unit tests: verify quorum verification with sorted arrays (k-of-n threshold)\n- Unit tests: verify ordering consistency across different key types/algorithms if supported\n- Unit tests: verify that sorted arrays remain sorted after serialization round-trip\n- Property tests: for any set of signer keys, the canonical ordering is unique and total\n- Integration tests: multi-party signing workflow where signers contribute signatures in arbitrary order; final object must be sorted\n\n## Implementation Notes\n- Implement sorting as part of the `MultiSigEnvelope` type's invariant, enforced at construction time (not just at verification time)\n- Use `Ord` trait implementation on the public key type that matches the canonical ordering specification\n- For efficiency, verify sorting with a single linear scan (O(n)) rather than re-sorting (O(n log n))\n- This is a relatively small module but has outsized security impact; it should be thoroughly tested and audited\n- Consider making the signature array a newtype (`SortedSignatureArray`) that can only be constructed in sorted order\n\n## Dependencies\n- Depends on: bd-1b2 (signature preimage contract for what is signed), bd-2t3 (deterministic serialization for canonical key representation)\n- Blocks: bd-1c7 (PolicyCheckpoint uses quorum multi-signatures), bd-26o (conformance suite tests multi-sig ordering), bd-3kd (golden vectors for multi-sig encodings)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:29.695572103Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.693869377Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3q36","title":"[10.13] Add migration compatibility tests ensuring control-plane schema evolution preserves replay compatibility or fails with explicit machine-readable migration errors.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Add migration compatibility tests ensuring control-plane schema evolution preserves replay compatibility or fails with explicit machine-readable migration errors.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:44.092670713Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.375222632Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-3q9","title":"[10.15] Delta Moonshots Execution Track (9I) - Comprehensive Execution Epic","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nPurpose: Convert the plan's intent into an executable, dependency-aware workstream without losing scope, ambition, or proof rigor.\nWhy this exists:\n- Keeps implementation aligned to the ambition-first charter and impossible-by-default capability goals.\n- Prevents drift between strategic language and engineering execution.\n- Ensures every deliverable carries deterministic verification, evidence artifacts, and replay-ready observability.\nRequired quality bar for all child beads:\n1. Include concrete implementation detail, not vague intent.\n2. Require focused unit tests for logic/invariant boundaries.\n3. Require end-to-end/integration scenarios with detailed structured logging (trace/policy/decision identifiers where relevant).\n4. Require artifact publication suitable for reproducibility contracts.\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:19.166766614Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:56.099505945Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-15"],"dependencies":[{"issue_id":"bd-3q9","depends_on_id":"bd-12n5","type":"parent-child","created_at":"2026-02-20T07:52:42.617690145Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-133a","type":"parent-child","created_at":"2026-02-20T07:52:42.696876527Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-15g2","type":"parent-child","created_at":"2026-02-20T07:52:42.860382893Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-17v2","type":"parent-child","created_at":"2026-02-20T07:52:43.146812175Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1999","type":"parent-child","created_at":"2026-02-20T07:52:43.307011571Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1fu7","type":"parent-child","created_at":"2026-02-20T07:52:44.081941541Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1g5c","type":"parent-child","created_at":"2026-02-20T07:52:44.165825082Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1gcu","type":"parent-child","created_at":"2026-02-20T07:52:44.220572314Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1hh4","type":"parent-child","created_at":"2026-02-20T07:52:44.312650729Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1ilz","type":"parent-child","created_at":"2026-02-20T07:52:44.545933510Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1jqt","type":"parent-child","created_at":"2026-02-20T07:52:44.628421672Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1kdc","type":"parent-child","created_at":"2026-02-20T07:52:44.817730558Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1kzo","type":"parent-child","created_at":"2026-02-20T07:52:44.900943019Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1n78","type":"parent-child","created_at":"2026-02-20T07:52:45.060331485Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1ovk","type":"parent-child","created_at":"2026-02-20T07:52:45.336633133Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1r25","type":"parent-child","created_at":"2026-02-20T07:52:45.577335413Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1v90","type":"parent-child","created_at":"2026-02-20T07:52:45.948157735Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-1yq","type":"blocks","created_at":"2026-02-20T07:32:58.147892723Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-24ie","type":"parent-child","created_at":"2026-02-20T07:52:46.639675221Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-25b7","type":"parent-child","created_at":"2026-02-20T07:52:46.759581448Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-27i1","type":"parent-child","created_at":"2026-02-20T07:52:46.957885989Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-29a1","type":"parent-child","created_at":"2026-02-20T07:52:47.220575082Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2ftv","type":"parent-child","created_at":"2026-02-20T07:52:47.826363110Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2gej","type":"parent-child","created_at":"2026-02-20T07:52:47.976662496Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2lr7","type":"parent-child","created_at":"2026-02-20T07:52:48.453073347Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2lt9","type":"parent-child","created_at":"2026-02-20T07:52:48.507421766Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2nxj","type":"parent-child","created_at":"2026-02-20T07:52:48.792882464Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2r6","type":"blocks","created_at":"2026-02-20T07:32:57.803135730Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2tzx","type":"parent-child","created_at":"2026-02-20T07:52:49.705505951Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2vnj","type":"parent-child","created_at":"2026-02-20T07:52:49.863015718Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2w2g","type":"parent-child","created_at":"2026-02-20T07:52:49.943119058Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2w9w","type":"parent-child","created_at":"2026-02-20T07:52:49.982581130Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2xu5","type":"parent-child","created_at":"2026-02-20T07:52:50.341513365Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-2y5d","type":"parent-child","created_at":"2026-02-20T07:52:50.380491025Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-32d3","type":"parent-child","created_at":"2026-02-20T07:52:50.778824479Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-352c","type":"parent-child","created_at":"2026-02-20T07:52:51.100913921Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-383","type":"blocks","created_at":"2026-02-20T07:32:58.234088558Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3ab3","type":"parent-child","created_at":"2026-02-20T07:52:51.546524834Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3ciq","type":"parent-child","created_at":"2026-02-20T07:52:51.864858010Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3hkk","type":"parent-child","created_at":"2026-02-20T07:52:52.401454732Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3jz8","type":"parent-child","created_at":"2026-02-20T07:52:52.599182539Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3kks","type":"parent-child","created_at":"2026-02-20T07:52:52.717650727Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3lt3","type":"parent-child","created_at":"2026-02-20T07:52:52.797365944Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3ncx","type":"parent-child","created_at":"2026-02-20T07:52:53.034996343Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3nr","type":"blocks","created_at":"2026-02-20T07:32:57.889983660Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3rgq","type":"parent-child","created_at":"2026-02-20T07:52:53.624483159Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-3sq4","type":"parent-child","created_at":"2026-02-20T07:52:53.782656712Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-6qsi","type":"parent-child","created_at":"2026-02-20T07:52:54.741692798Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-7rwi","type":"parent-child","created_at":"2026-02-20T07:52:54.916418411Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-83jh","type":"parent-child","created_at":"2026-02-20T07:52:54.955680391Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-ami3","type":"parent-child","created_at":"2026-02-20T07:52:55.194894520Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-kfe4","type":"parent-child","created_at":"2026-02-20T07:52:56.059250575Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-kr99","type":"parent-child","created_at":"2026-02-20T07:52:56.099429252Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-ntq","type":"blocks","created_at":"2026-02-20T07:32:58.060658013Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3q9","depends_on_id":"bd-zvn","type":"blocks","created_at":"2026-02-20T07:32:57.975537360Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3qh2","title":"[13] every promoted `delegate -> native` core slot has a signed replacement receipt with reproducible differential/security/performance artifacts","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: every promoted `delegate -> native` core slot has a signed replacement receipt with reproducible differential/security/performance artifacts\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:27.109383954Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:38.311657085Z","closed_at":"2026-02-20T07:39:57.294852766Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3qhv","title":"[15] Greenfield onboarding uses a minimal-friction deterministic safe-extension setup workflow.","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Greenfield onboarding uses a minimal-friction deterministic safe-extension setup workflow.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:35.415623153Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:38.351870517Z","closed_at":"2026-02-20T07:45:41.075897502Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-3qm1","title":"[11] Require EV scoring output and tier classification","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: EV score and tier\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:16.275442400Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:38.397968398Z","closed_at":"2026-02-20T07:38:23.302829750Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"],"dependencies":[{"issue_id":"bd-3qm1","depends_on_id":"bd-18fu","type":"blocks","created_at":"2026-02-20T07:38:26.041084965Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qm1","depends_on_id":"bd-2ntw","type":"blocks","created_at":"2026-02-20T07:38:25.921720016Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3qt4","title":"[13] unauthorized sensitive-source -> external-sink flows are deterministically blocked unless explicit declassification is approved by policy","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: unauthorized sensitive-source -> external-sink flows are deterministically blocked unless explicit declassification is approved by policy\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:25.932500234Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:38.441252148Z","closed_at":"2026-02-20T07:39:57.789509804Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3qv","title":"[10.6] Add constrained-vs-ambient benchmark lanes quantifying specialization uplift from PLAS/IFC proof tightening under equivalent behavior.","description":"## Plan Reference\nSection 10.6, item 6. Cross-refs: 9I.5 (PLAS), 9I.7 (IFC), 9I.8 (Security-Proof-Guided Specialization), Phase C exit gate.\n\n## What\nAdd benchmark lanes that compare constrained-mode execution (with PLAS/IFC security constraints active) against ambient-authority mode, quantifying the performance uplift from security proof tightening.\n\n## Detailed Requirements\n- Constrained lane: run benchmarks with PLAS capability witnesses and IFC flow proofs active, enabling proof-guided specialization\n- Ambient lane: run same benchmarks without security proofs, using generic dynamic checks\n- Measure: throughput delta, p50/p95/p99 latency delta, memory/allocation delta\n- Equivalent behavior requirement: both lanes must produce identical outputs (canonical digest match)\n- Per-specialization attribution: which security proofs contributed which performance gains\n- Publication format: structured results suitable for Section 14 benchmark reports\n\n## Rationale\nSection 9I.8: 'Make security proofs first-class optimizer inputs so tighter verified constraints yield faster executable paths instead of being treated as overhead.' This benchmark lane proves the flywheel: security investment → better proofs → faster code. Phase C exit gate explicitly requires: 'constrained-mode benchmark lane demonstrates measurable speedup versus ambient-authority mode on the same workloads with identical outputs and policy outcomes.'\n\n## Testing Requirements\n- Benchmark: constrained lane produces equal or better performance than ambient lane\n- Verification: both lanes produce identical behavior (canonical digest match)\n- Per-proof attribution: removing specific proofs degrades specific specializations\n- Regression: constrained lane performance does not regress below ambient lane after changes\n\n## Dependencies\n- Blocked by: PLAS (10.15), IFC (10.15/10.2), proof-to-specialization linkage (10.2 bd-161), benchmark suite (bd-2ql)\n- Blocks: Phase C exit gate, Security-Proof-Guided Specialization validation\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:25.886536901Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:09.317210326Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-6"]}
{"id":"bd-3rd","title":"[10.9] Release gate: continuous adversarial campaign runner demonstrates measurable compromise-rate suppression versus baseline engines (implementation ownership: `10.12`).","description":"## Plan Reference\nSection 10.9, item 5 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that the continuous adversarial campaign runner -- built by the Frontier Programs track (10.12) as part of the Red-Team Generator and Adversarial Benchmark moonshots -- demonstrates measurable, statistically significant compromise-rate suppression compared to baseline engines (Node LTS, Bun stable). The gate confirms that FrankenEngine's security posture is not merely \"different\" but quantifiably superior under sustained adversarial pressure.\n\nThe gate owner does not build the campaign runner; the gate owner evaluates campaign results against defined statistical thresholds and certifies the evidence bundle.\n\n## Gate Criteria\n1. The campaign runner executes a defined adversarial corpus (injection attacks, prototype pollution, supply-chain vectors, capability-escape attempts, timing side-channels) against FrankenEngine and at least two baseline engines under identical conditions.\n2. Compromise rate is defined as: (successful exploits / total attack attempts) measured per attack category.\n3. FrankenEngine must demonstrate a statistically significant reduction in compromise rate (p < 0.05, using an agreed-upon statistical test) versus every baseline engine on every attack category.\n4. Campaign results include: per-attack-category success/failure counts, confidence intervals, raw logs, and exploit reproduction scripts.\n5. The campaign is continuous: it runs on every release candidate (not just one-off), and historical trend data is maintained.\n6. Any new attack vector added to the corpus that achieves a successful exploit triggers an automatic escalation workflow with a defined SLA for remediation.\n\n## Implementation Ownership\n- **10.12 (Frontier Programs):** Builds the campaign runner, adversarial corpus, attack execution framework, and statistical analysis pipeline. Encompasses 9F moonshots: Red-Team Generator, Adversarial Benchmark, Live Safety Twin.\n- **10.9 (this gate):** Evaluates campaign results against statistical thresholds, certifies evidence bundles, and enforces the continuous-run requirement.\n\n## Rationale\nSecurity claims without adversarial evidence are marketing, not engineering. This gate ensures that FrankenEngine's security advantages are demonstrated under sustained, automated adversarial pressure with statistical rigor. The continuous nature of the campaign prevents security regression and provides the primary evidence source for the `security_delta` dimension of the disruption scorecard (bd-6pk).\n\nRelated 9F moonshots: Red-Team Generator, Adversarial Benchmark, Live Safety Twin.\nRelated 9I moonshots: Cross-Repo Conformance Lab, Privacy-Preserving Fleet Learning.\n\n## Verification Requirements\n- **Statistical rigor audit:** Confirm the statistical test, sample sizes, and confidence intervals are appropriate for the claim being made. An independent statistician or automated checker validates the analysis.\n- **Corpus completeness review:** Confirm the adversarial corpus covers OWASP top-10 categories relevant to JS/TS runtimes, plus FrankenEngine-specific attack surfaces (capability system, proof pipeline, quarantine mesh).\n- **Baseline fairness:** Confirm baseline engines are tested with their recommended security configurations (not intentionally weakened).\n- **Continuous enforcement:** Verify that the campaign runner is wired into CI and runs against every release candidate, not just on-demand.\n- **Escalation workflow:** Trigger a synthetic successful exploit; confirm the escalation workflow fires within the defined SLA.\n- **Scorecard integration:** Results feed `security_delta` in the disruption scorecard (bd-6pk).\n- **Structured logging:** Campaign runs emit structured logs with fields: `trace_id`, `campaign_id`, `attack_category`, `target_runtime`, `attempt_count`, `success_count`, `compromise_rate`, `p_value`, `confidence_interval`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate results feed `security_delta` dimension.\n- bd-uwc (quarantine mesh gate) -- shares fault-injection infrastructure; quarantine mesh is part of the defense surface being tested.\n- bd-eke (IFC gate) -- IFC protections are part of the defense surface being tested.\n- 10.12 Frontier Programs track -- delivers the campaign runner implementation.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.284422049Z","created_by":"ubuntu","updated_at":"2026-02-20T07:58:05.151558125Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-3rgq","title":"[10.15] Build conformance-vector generator and property/fuzz harness for cross-repo boundary invariants, including degraded/fault-mode scenarios.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Build conformance-vector generator and property/fuzz harness for cross-repo boundary invariants, including degraded/fault-mode scenarios.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:48.971309556Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.608244404Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3s3","title":"[10.11] Implement named remote computation registry with deterministic input encoding and schema validation.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement named remote computation registry with deterministic input encoding and schema validation.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:36.257470024Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.039051071Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-3s6","title":"[10.10] Define mandatory runtime metrics and structured logs for auth/capability/replay/revocation/checkpoint failures.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Define mandatory runtime metrics and structured logs for auth/capability/replay/revocation/checkpoint failures.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:32.116293518Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.986981385Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3set","title":"[13] extension-heavy benchmark suites show `>= 3x` weighted-geometric-mean throughput versus Node baseline and `>= 3x` versus Bun baseline under Section `14` denominator and equivalence rules","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: extension-heavy benchmark suites show `>= 3x` weighted-geometric-mean throughput versus Node baseline and `>= 3x` versus Bun baseline under Section `14` denominator and equivalence rules\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:20.256995867Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:38.686158309Z","closed_at":"2026-02-20T07:40:00.419810734Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3sq4","title":"[10.15] Add frankentui operator dashboard for replacement progress (`slot status`, `native coverage`, `blocked promotions`, `rollback events`, `next-best-EV replacements`).","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankentui operator dashboard for replacement progress (`slot status`, `native coverage`, `blocked promotions`, `rollback events`, `next-best-EV replacements`).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:54.750417096Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.900843986Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-3t2d","title":"[MASTER] Execute PLAN 1-16 as self-contained bead graph","description":"Full-program orchestration epic spanning PLAN sections 1-16.\nThis includes architecture doctrine, execution tracks, evidence contracts, risk controls, success-criteria verification, benchmarking/standardization, ecosystem strategy, and scientific output obligations.\nCompletion requires:\n- all section epics complete\n- dependency graph remains acyclic and actionable\n- benchmark/security/replay claims supported by reproducible artifacts\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:34:38.990452762Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:55.563075432Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["full-program","master","plan"],"dependencies":[{"issue_id":"bd-3t2d","depends_on_id":"bd-1jak","type":"parent-child","created_at":"2026-02-20T07:52:44.587604125Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t2d","depends_on_id":"bd-1tsf","type":"parent-child","created_at":"2026-02-20T07:52:45.780735936Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t2d","depends_on_id":"bd-21ds","type":"parent-child","created_at":"2026-02-20T07:52:46.478453901Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t2d","depends_on_id":"bd-2rbm","type":"parent-child","created_at":"2026-02-20T07:52:49.231930242Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t2d","depends_on_id":"bd-395m","type":"parent-child","created_at":"2026-02-20T07:52:51.427341443Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t2d","depends_on_id":"bd-c1co","type":"parent-child","created_at":"2026-02-20T07:52:55.278397282Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t2d","depends_on_id":"bd-esst","type":"parent-child","created_at":"2026-02-20T07:52:55.563026040Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3tjn","title":"[11] Define rollout wedge with progressive exposure guardrails","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: rollout wedge\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:16.937810451Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:38.772143815Z","closed_at":"2026-02-20T07:38:22.997619181Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"],"dependencies":[{"issue_id":"bd-3tjn","depends_on_id":"bd-11ni","type":"blocks","created_at":"2026-02-20T07:38:26.389490704Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3tt2","title":"[13] synthesized capability envelopes achieve <= 1.10 over-privilege ratio versus empirically required capability sets on benchmark cohorts","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: synthesized capability envelopes achieve <= 1.10 over-privilege ratio versus empirically required capability sets on benchmark cohorts\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:25.001151288Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:38.814349938Z","closed_at":"2026-02-20T07:39:58.185460504Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3u0","title":"[10.7] Add IFC conformance corpus: dual-capability benign workloads, exfil-attempt workloads, and declassification-exception workloads with deterministic expected outcomes.","description":"Plan Reference: section 10.7 (Conformance + Verification).\nObjective: Add IFC conformance corpus: dual-capability benign workloads, exfil-attempt workloads, and declassification-exception workloads with deterministic expected outcomes.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:27.009147518Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.081166948Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-3u5","title":"[10.1] Add semantic donor spec document (observable behavior, edge cases, compatibility-critical semantics) as implementation source of truth.","description":"## Plan Reference\nSection 10.1, item 5. Cross-refs: Section 1 (Background/Origin), Section 2 (Core Thesis), 10.1 item 4 (donor-extraction scope).\n\n## What\nAdd a semantic donor spec document that captures observable behavior, edge cases, and compatibility-critical semantics from V8/QuickJS as an implementation source of truth - WITHOUT copying their architecture.\n\n## Detailed Requirements\n- Document observable ES2020 behavior from V8 and QuickJS that FrankenEngine must match\n- Focus on semantics, not internals: what behavior users see, not how engines implement it\n- Include edge cases and corner cases that affect real extension code\n- Document compatibility-critical semantics that migration from Node/Bun depends on\n- Explicit exclusions: internal architecture, optimization strategies, memory layouts (these must NOT be mirrored)\n- Machine-readable format for automated conformance checking where possible\n\n## Rationale\nThe plan states FrankenEngine is a 'de novo Rust-native runtime' (Section 2) but must be compatible with existing JS/TS ecosystems (Phase D). The donor spec bridges this gap: it captures WHAT to implement (observable semantics) without prescribing HOW (architecture). This prevents the common failure of accidentally reimplementing V8/QuickJS internals while missing semantic edge cases.\n\n## Testing Requirements\n- Conformance tests: each documented semantic has corresponding test case\n- Edge case coverage: each documented edge case has test showing correct behavior\n- Cross-reference: each entry maps to test262 tests where applicable\n\n## Dependencies\n- Blocks: architecture synthesis (bd-2xe), feature-parity tracker (bd-j7z), VM Core implementation (10.2)\n- Blocked by: donor-extraction scope document (10.1 item 4, already exists as docs/REPO_SPLIT_CONTRACT.md)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.024917569Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.869117791Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-1"]}
{"id":"bd-3u7","title":"[10.10] Implement delegated capability attenuation chain verification (no ambient authority path).","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement delegated capability attenuation chain verification (no ambient authority path).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:30.397976479Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.483353233Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-3ub","title":"[10.3] Implement initial GC with deterministic test mode.","description":"## Plan Reference\nSection 10.3, item 2. Cross-refs: 9B.4 (modern allocator strategy), 9D.4 (allocation profiling), Phase A exit gate.\n\n## What\nImplement the initial garbage collector with a deterministic test mode. The GC must support per-extension collection, domain-aware scanning, and fully deterministic behavior when running under test/replay conditions.\n\n## Detailed Requirements\n- GC must be domain-aware: collect per-extension independently, never scan across extension boundaries\n- Deterministic test mode: GC collection points, ordering, and outcomes are fully reproducible for replay\n- Support explicit GC triggers for testing (force collection at specific points)\n- GC must respect allocation domain budgets: trigger collection before OOM, report pressure\n- Safe mode: GC must never crash or corrupt on malformed object graphs (extensions are untrusted)\n- Incremental/generational design preferred but not required for initial implementation\n- GC pause metrics must be recorded for pause-time instrumentation (bd-50o)\n\n## Rationale\nDeterministic GC is critical for replay (9A.3/9F.3): if GC timing differs between record and replay, execution diverges. Per-extension collection is required for resource budget enforcement (9A.8) and security isolation. The plan requires that extensions cannot cause denial-of-service through memory exhaustion affecting other extensions.\n\n## Testing Requirements\n- Unit tests: allocate objects, trigger GC, verify dead objects collected\n- Unit tests: verify per-extension collection isolation (collecting ext A does not affect ext B)\n- Unit tests: deterministic mode produces identical collection sequence across runs\n- Unit tests: GC handles malformed/circular references safely (no crash, no infinite loop)\n- Stress tests: high allocation rate with concurrent extensions, verify no corruption\n- Regression tests: GC pause times stay within budget thresholds\n\n## Implementation Notes\n- Implement in crates/franken-engine memory module\n- Must work with #![forbid(unsafe_code)] - use safe abstractions for object graph traversal\n- Consider mark-sweep as initial strategy with upgrade path to generational\n- Deterministic mode: fix collection ordering, disable concurrent/parallel collection\n- Record GC events for evidence ledger integration\n\n## Dependencies\n- Blocked by: allocation domains (bd-3w2)\n- Blocks: pause-time instrumentation (bd-50o), interpreter correctness under GC pressure\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:23.238420251Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.089095267Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-3"]}
{"id":"bd-3uiy","title":"[13] moonshot portfolio governor enforces documented promote/hold/kill gates with 100% governance decision artifact completeness","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: moonshot portfolio governor enforces documented promote/hold/kill gates with 100% governance decision artifact completeness\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:24.310746694Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:39.052990047Z","closed_at":"2026-02-20T07:39:58.483056530Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-3uk","title":"[10.0] Top-10 #2: Probabilistic Guardplane runtime subsystem (strategy: `9A.2`; deep semantics: `9F.15`; execution owners: `10.5`, `10.11`, `10.12`).","description":"## Plan Reference\nSection 10.0 item 2. Strategy: 9A.2. Deep semantics: 9F.15 (Live Safety Twin). Enhancement maps: 9B.2 (conformal prediction, e-process, BOCPD), 9C.2 (full Bayesian decision loop), 9D.2 (per-stage latency budgets).\n\n## What\nStrategic tracking bead for Initiative #2: Probabilistic Guardplane (Bayesian + sequential inference) as first-class runtime subsystem. Security decisions are online inference, not static denylist checks.\n\n## Execution Owners\n- **10.5** (Extension Host): Bayesian posterior updater API, expected-loss action selector, containment actions\n- **10.11** (Runtime Systems): PolicyController, e-process guardrails, BOCPD regime detector, VOI-budgeted monitors\n- **10.12** (Frontier Programs): trust-economics model, fleet immune system, operator safety copilot\n\n## Strategic Rationale (from 9A.2)\n'Supply-chain attacks adapt over time; a posterior-driven system with anytime-valid boundaries can detect drift and react earlier with quantifiable error control.'\n\n## Key Deliverables\n- Posterior risk maintenance over extension behavior using hostcall patterns, temporal anomalies, policy mismatch\n- Continuous decision updates as evidence accumulates\n- Full decision loop: classify → quantify → decide → explain → calibrate (9C.2)\n- Conformal coverage wrappers and PAC-Bayes confidence accounting\n- Phase B exit gate: median detection-to-containment <= 250ms\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:19.363943722Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.314806324Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-3vg","title":"[10.11] Add explicit checkpoint-placement contract for long-running loops (dispatch, scanning, policy iteration, replay, decode/verify paths).","description":"## Plan Reference\n- **Section**: 10.11 item 3 (FrankenSQLite-Inspired Runtime Systems Track)\n- **9G Cross-ref**: 9G.2 — Cancellation as protocol (request -> drain -> finalize)\n- **Top-10 Links**: #3 (Deterministic evidence graph + replay), #8 (Per-extension resource budget)\n\n## What\nAdd an explicit checkpoint-placement contract for long-running loops throughout the engine and extension-host subsystems. Every long-running loop (dispatch, scanning, policy iteration, replay, decode/verify paths) must contain well-defined cancellation checkpoint sites where the runtime can observe pending cancel requests and transition to drain/finalize phases.\n\n## Detailed Requirements\n1. Define a `CancellationCheckpoint` trait/macro that marks yield points within long-running loops where the runtime checks for pending cancellation.\n2. Enumerate mandatory checkpoint-placement sites:\n   - Bytecode dispatch loops (per N instructions or per basic-block boundary).\n   - GC scanning/mark/sweep iteration loops.\n   - Policy iteration and decision-contract evaluation loops.\n   - Deterministic replay engine step loops.\n   - Module decode and verification passes.\n   - IR lowering and compilation pipeline passes.\n3. Each checkpoint must: (a) check a cancellation flag or channel, (b) if cancellation is pending, emit a structured checkpoint event and transition to drain state, (c) record the checkpoint location identifier for replay determinism.\n4. Define a checkpoint-density policy: no loop may execute more than N iterations (configurable, default 1024) or M microseconds (configurable, default 100us) without hitting a checkpoint. This is enforced via instrumentation in debug/test builds and sampled monitoring in release builds.\n5. Checkpoint events must carry: `trace_id`, `component`, `loop_id`, `iteration_count`, `checkpoint_reason` (periodic / cancel_pending / budget_exhausted), `timestamp_virtual` (for deterministic lab runtime).\n6. The contract must be machine-verifiable: a static analysis pass or test-time instrumentation must confirm that every annotated long-running loop contains at least one checkpoint.\n\n## Rationale\nWithout mandatory checkpoint placement, cancellation requests (quarantine, revocation, suspend) can be delayed indefinitely by long-running computation, violating the `<= 250ms` detection-to-containment SLO (Section 3). The 9G.2 contract requires cancellation to be a protocol, not a best-effort signal. Explicit checkpoints make cancellation latency bounded and deterministic, which is essential for the deterministic lab runtime (bd-121) and interleaving explorer (bd-3ix).\n\n## Testing Requirements\n- **Unit tests**: For each mandatory checkpoint site, verify that a pending cancellation is detected within the density bound. Verify that checkpoint events are emitted with correct structured fields.\n- **Property tests**: Inject cancellation at random loop iterations and verify drain transition occurs within the density bound.\n- **Integration tests**: Run a long policy-iteration scenario, inject cancellation mid-iteration, and verify the system drains and finalizes within the configured bounds. Measure and assert on cancellation latency.\n- **Static verification test**: Run the checkpoint-coverage analysis tool and verify it reports 100% coverage of annotated long-running loops.\n- **Logging/observability**: Checkpoint events must appear in structured logs with stable field names for replay correlation.\n- **Reproducibility**: Virtual-time checkpoint sequences must be identical across replay runs with the same input.\n\n## Implementation Notes\n- Consider a `#[checkpoint_loop]` proc-macro that instruments the loop body with automatic checkpoint insertion and density verification.\n- The cancellation flag should be an atomic/channel compatible with the region-quiescence protocol (bd-2ao).\n- Virtual-time checkpoint recording must integrate with the deterministic lab runtime (bd-121).\n- Checkpoint density configuration should be per-subsystem tunable via runtime configuration, not hardcoded.\n\n## Dependencies\n- Depends on: bd-1i2 (capability profiles for checkpoint context), bd-2ao (region-quiescence protocol defines what drain/finalize means).\n- Blocks: bd-121 (deterministic lab runtime needs checkpoint replay), bd-3ix (interleaving explorer needs checkpoint injection points).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:33.592338932Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.867429745Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-3vh","title":"[10.10] FCP-Inspired Hardening + Interop Track - Comprehensive Execution Epic","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nPurpose: Convert the plan's intent into an executable, dependency-aware workstream without losing scope, ambition, or proof rigor.\nWhy this exists:\n- Keeps implementation aligned to the ambition-first charter and impossible-by-default capability goals.\n- Prevents drift between strategic language and engineering execution.\n- Ensures every deliverable carries deterministic verification, evidence artifacts, and replay-ready observability.\nRequired quality bar for all child beads:\n1. Include concrete implementation detail, not vague intent.\n2. Require focused unit tests for logic/invariant boundaries.\n3. Require end-to-end/integration scenarios with detailed structured logging (trace/policy/decision identifiers where relevant).\n4. Require artifact publication suitable for reproducibility contracts.\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:32:18.818455160Z","created_by":"ubuntu","updated_at":"2026-02-20T07:59:47.668125158Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-10"],"dependencies":[{"issue_id":"bd-3vh","depends_on_id":"bd-10a","type":"blocks","created_at":"2026-02-20T07:59:46.390911623Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-16n","type":"parent-child","created_at":"2026-02-20T07:52:42.984791696Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-16u","type":"parent-child","created_at":"2026-02-20T07:52:43.026310920Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1ai","type":"parent-child","created_at":"2026-02-20T07:52:43.388268149Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1b2","type":"parent-child","created_at":"2026-02-20T07:52:43.430510149Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1bi","type":"parent-child","created_at":"2026-02-20T07:52:43.471706230Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1c7","type":"parent-child","created_at":"2026-02-20T07:52:43.636209333Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1dp","type":"parent-child","created_at":"2026-02-20T07:52:43.800050793Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1fx","type":"parent-child","created_at":"2026-02-20T07:52:44.124512654Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1lp","type":"parent-child","created_at":"2026-02-20T07:52:44.940915742Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-1p4","type":"parent-child","created_at":"2026-02-20T07:52:45.376827819Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-26f","type":"parent-child","created_at":"2026-02-20T07:52:46.798749713Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-26o","type":"parent-child","created_at":"2026-02-20T07:52:46.879083792Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-28m","type":"parent-child","created_at":"2026-02-20T07:52:47.174377365Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-29r","type":"parent-child","created_at":"2026-02-20T07:52:47.260375384Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-29s","type":"parent-child","created_at":"2026-02-20T07:52:47.302980851Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-2ic","type":"parent-child","created_at":"2026-02-20T07:52:48.175916847Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-2s7","type":"parent-child","created_at":"2026-02-20T07:52:49.428498950Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-2t3","type":"parent-child","created_at":"2026-02-20T07:52:49.507462186Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-2u0","type":"blocks","created_at":"2026-02-20T07:59:47.185975382Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-2xe","type":"blocks","created_at":"2026-02-20T07:59:47.277225918Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-2y7","type":"parent-child","created_at":"2026-02-20T07:52:50.419505002Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3ai","type":"parent-child","created_at":"2026-02-20T07:52:51.585966969Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3bc","type":"parent-child","created_at":"2026-02-20T07:52:51.704959974Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3fr","type":"blocks","created_at":"2026-02-20T07:59:47.375003792Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3kd","type":"parent-child","created_at":"2026-02-20T07:52:52.677976720Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3mu","type":"parent-child","created_at":"2026-02-20T07:52:52.876575550Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3n0","type":"parent-child","created_at":"2026-02-20T07:52:52.956277402Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3pl","type":"parent-child","created_at":"2026-02-20T07:52:53.261687507Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3s6","type":"parent-child","created_at":"2026-02-20T07:52:53.703482603Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3u5","type":"blocks","created_at":"2026-02-20T07:59:47.472654208Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-3u7","type":"parent-child","created_at":"2026-02-20T07:52:54.020546885Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-74l","type":"blocks","created_at":"2026-02-20T07:59:47.569403536Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-8az","type":"parent-child","created_at":"2026-02-20T07:52:55.034717875Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-j7z","type":"blocks","created_at":"2026-02-20T07:59:47.668051751Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vh","depends_on_id":"bd-lpl","type":"parent-child","created_at":"2026-02-20T07:52:56.139504676Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3vk","title":"[10.3] Memory + GC - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.3: Memory + GC\n\n## Overview\nThis epic covers FrankenEngine's memory management subsystem including allocation domain design, garbage collection with deterministic test mode, and GC pause-time instrumentation with regression budgets.\n\n## Child Beads\n- bd-3w2: Define allocation domains and lifetime classes (foundational)\n- bd-3ub: Implement initial GC with deterministic test mode\n- bd-50o: Add pause-time instrumentation and regression budgets\n\n## Dependency Chain\nbd-3w2 (allocation domains) → bd-3ub (GC implementation) → bd-50o (pause instrumentation)\n\n## Key Requirements\n- Per-extension memory isolation for security\n- Deterministic GC for replay support (9A.3/9F.3)\n- Pause-time budgets for tail-latency control (Phase C)\n- Safe under #![forbid(unsafe_code)] constraint\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:18.367735864Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:11.200758489Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-3"],"dependencies":[{"issue_id":"bd-3vk","depends_on_id":"bd-3ub","type":"parent-child","created_at":"2026-02-20T07:52:54.059912948Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vk","depends_on_id":"bd-3w2","type":"parent-child","created_at":"2026-02-20T07:52:54.382280969Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vk","depends_on_id":"bd-50o","type":"parent-child","created_at":"2026-02-20T07:52:54.500996609Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3vk","depends_on_id":"bd-ntq","type":"blocks","created_at":"2026-02-20T07:32:55.435834240Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3vlb","title":"[10.13] Define a formal control-plane adoption ADR naming `/dp/asupersync` crates as canonical sources for `Cx`, decision contracts, and evidence schema.","description":"# Define Formal Control-Plane Adoption ADR\n\n## Plan Reference\nSection 10.13, Item 1.\n\n## What\nAuthor and ratify an Architecture Decision Record (ADR) that formally names the `/dp/asupersync` crates as the canonical, sole-source providers of control-plane primitives for FrankenEngine. This ADR establishes that `Cx` (capability context), decision contracts, and evidence schema are imported from asupersync and never re-implemented locally.\n\n## Detailed Requirements\n- **Integration/binding nature**: This bead does not create Cx, decision contracts, or evidence schema. Those are owned by 10.11. This bead creates the governance document that binds FrankenEngine's extension-host subsystem to consume those primitives exclusively from the `/dp/asupersync` crate family.\n- The ADR must enumerate every canonical type imported: `Cx`, `TraceId`, `DecisionId`, `PolicyId`, `SchemaVersion`, `Budget`, and their containing crates.\n- The ADR must specify the version pinning or semver-compatible range policy for each `/dp/asupersync` crate dependency.\n- The ADR must define the escalation path when an asupersync API does not yet expose a needed primitive (file upstream issue, never fork).\n- The ADR must be stored in the project's `docs/adr/` directory following the project's ADR numbering convention.\n- The ADR must reference 10.11 as the authoritative owner of all listed primitives.\n\n## Rationale\nWithout a formal adoption record, different contributors may create local type aliases, wrapper types, or outright re-implementations of control-plane primitives. This ADR eliminates that drift by making the canonical source unambiguous and enforceable via CI checks (see bd-11z7 and bd-2fa1).\n\n## Testing Requirements\n- ADR passes markdown lint and internal link validation.\n- CI check verifies the ADR file exists and contains all required sections (canonical types list, version policy, escalation path).\n- Review gate: ADR must be approved by at least one 10.11 primitive owner and one FrankenEngine extension-host maintainer.\n\n## Implementation Notes\n- **10.11 primitive ownership**: All types named in the ADR are defined and maintained by the 10.11 track. This ADR is a consumer-side governance document; it does not modify 10.11 artifacts.\n- The ADR should cross-reference the naming guidance bead (bd-ypl4) and the dependency policy bead (bd-2fa1) as companion documents.\n\n## Dependencies\n- No hard code dependencies; this is a governance artifact.\n- Logically precedes all other 10.13 beads, as they depend on the canonical source designation this ADR establishes.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:41.647466885Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.096914007Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-3vp","title":"[10.4] Add explicit compatibility mode matrix for Node/Bun module edge cases (no hidden shims).","description":"## Plan Reference\nSection 10.4, item 3. Cross-refs: Phase D (Node/Bun surface superset), 9F.6 (Tri-Runtime Lockstep Oracle), 10.7 (differential lockstep suite).\n\n## What\nAdd an explicit compatibility mode matrix documenting how FrankenEngine handles Node and Bun module edge cases. No hidden shims - every compatibility behavior must be documented and testable.\n\n## Detailed Requirements\n- Compatibility matrix: for each module feature (ESM, CJS, dual-mode, conditional exports, package.json fields), document FrankenEngine behavior vs Node vs Bun\n- Explicit divergence documentation: where FrankenEngine intentionally differs from Node/Bun, document why and what the impact is\n- No hidden shims: compatibility layers must be explicit, testable, and removable (not buried in resolution logic)\n- Waiver governance: when FrankenEngine cannot match Node/Bun behavior, a formal waiver must be filed (per 10.1 feature-parity tracker)\n- Migration guidance: for each divergence, provide clear migration path for users moving from Node/Bun\n\n## Rationale\nThe plan explicitly states 'no hidden shims' for compatibility. Phase D requires Node/Bun surface superset, but the plan also requires that FrankenEngine be a de novo implementation (Section 2). This matrix is the governance mechanism that keeps compatibility explicit and intentional rather than accidental. The tri-runtime lockstep oracle (9F.6) will continuously validate this matrix.\n\n## Testing Requirements\n- Compatibility tests: for each matrix entry, test that FrankenEngine behavior matches documented behavior\n- Divergence tests: for each documented divergence, test that FrankenEngine produces the expected (different) behavior\n- Lockstep tests: feed matrix test cases to tri-runtime lockstep oracle for automated divergence detection\n- Regression tests: new code changes do not silently alter compatibility matrix entries\n\n## Implementation Notes\n- Compatibility matrix should be machine-readable (TOML/JSON) for automated testing\n- Each matrix entry should link to relevant test262 or lockstep test cases\n- Consider compatibility mode flags for opt-in Node/Bun-compatible behavior where divergence exists\n- This is primarily a documentation/governance artifact with test backing\n\n## Dependencies\n- Blocked by: module resolver (bd-tgv), module cache (bd-16x)\n- Blocks: Phase D exit gate, migration kits (Section 15 ecosystem capture)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:23.766540351Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.898162540Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-4"]}
{"id":"bd-3w2","title":"[10.3] Define allocation domains and lifetime classes.","description":"## Plan Reference\nSection 10.3, item 1. Cross-refs: 9B.4 (allocator strategy), 9D.4 (allocation profiling), 9B.1 (arena allocation for IR nodes).\n\n## What\nDefine the allocation domain taxonomy and lifetime class hierarchy for FrankenEngine's memory management. This is the foundational design for how memory is organized, tracked, and reclaimed across the runtime.\n\n## Detailed Requirements\n- Define allocation domains: per-extension heaps, shared runtime heap, IR arena, evidence/witness arena, temporary/scratch buffers\n- Define lifetime classes: request-scoped (single hostcall), session-scoped (extension session), global (runtime lifetime), arena (compilation unit)\n- Each domain must have explicit size limits for per-extension resource budget enforcement (9A.8)\n- Allocation tracking must be deterministic for replay: same allocation sequence under same inputs\n- Domain isolation: one extension's allocation cannot corrupt another's (security requirement)\n- Integration point with GC: lifetime classes inform GC root scanning and collection strategy\n\n## Rationale\nPer-extension resource budgets (9A.8) require fine-grained allocation control. The plan requires deterministic behavior for replay (9A.3), which means memory allocation patterns must be reproducible. Domain isolation is a security requirement - extensions are untrusted code that must not be able to corrupt runtime or other extension memory. Arena allocation (recommended in 9B.1) provides both performance and determinism benefits.\n\n## Testing Requirements\n- Unit tests: allocate from each domain, verify isolation (writes in one domain cannot read from another)\n- Unit tests: verify lifetime class scoping (request-scoped allocation freed after hostcall completes)\n- Unit tests: verify domain size limits are enforced (allocation fails when budget exceeded)\n- Property tests: allocation/deallocation sequences are deterministic given same inputs\n- Stress tests: high allocation rates across multiple domains do not corrupt or leak\n\n## Implementation Notes\n- Define domain/lifetime types in crates/franken-engine as core memory module\n- Consider typed arenas (one per IR level) for compilation pipeline\n- Must work with #![forbid(unsafe_code)] constraint from AGENTS.md - use safe abstractions\n- Arena designs should be compatible with the existing serde-based serialization approach\n\n## Dependencies\n- Blocks: GC implementation (bd-3ub), interpreter skeleton (bd-2f8 in 10.2)\n- Blocked by: nothing (foundational design)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:23.104967561Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.135676551Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-3"]}
{"id":"bd-3zj","title":"[10.0] Top-10 #9: Adversarial security corpus + continuous fuzzing harness (strategy: `9A.9`; deep semantics: `9F.7`; execution owners: `10.7`, `10.12`).","description":"## Plan Reference\nSection 10.0 item 9. Strategy: 9A.9. Deep semantics: 9F.7 (Autonomous Red-Team Generator). Enhancement maps: 9B.9 (concolic, property-based, model checking, delta debugging), 9C.9 (calibrated risk measurement, posterior defect probability), 9D.9 (corpus throughput, unique-crash yield profiling).\n\n## What\nStrategic tracking bead for Initiative #9: Adversarial security corpus + continuous fuzzing for regression resistance. Maintain curated malicious-extension corpora plus continuous fuzzing.\n\n## Execution Owners\n- **10.7** (Conformance + Verification): probabilistic security tests, metamorphic tests, stress tests\n- **10.12** (Frontier Programs): continuous adversarial campaign generator, red/blue loop integration\n\n## Strategic Rationale (from 9A.9)\n'Defenses that are not continuously attacked in testing will regress silently.'\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:20.276166263Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.969934175Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-4hf","title":"[10.11] Implement three-tier hash strategy contract (hot integrity, content identity, trust authenticity) with explicit scope boundaries.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Implement three-tier hash strategy contract (hot integrity, content identity, trust authenticity) with explicit scope boundaries.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:37.149605579Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.760805301Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-50o","title":"[10.3] Add pause-time instrumentation and regression budgets.","description":"## Plan Reference\nSection 10.3, item 3. Cross-refs: 9D.4 (allocation profiling), 9D (extreme-software-optimization discipline), Phase C exit gate (p95/p99 improvements).\n\n## What\nAdd GC pause-time instrumentation with regression budgets. Every GC pause must be measured, recorded, and gated against defined latency budgets to prevent GC from becoming a tail-latency source.\n\n## Detailed Requirements\n- Instrument every GC pause with: start time, duration, objects scanned, objects collected, memory reclaimed, domain/extension\n- Define pause-time budgets: p50, p95, p99 targets per GC event class\n- CI regression gate: fail build if GC pauses exceed budget on benchmark workloads\n- Structured telemetry output compatible with evidence ledger schema (10.11)\n- Dashboard/export format for operator visibility into GC pressure\n- Per-extension GC overhead tracking for resource budget accounting\n\n## Rationale\nPer 9D (extreme-software-optimization): baseline first (p50/p95/p99), profile top-5 hotspots before changes. GC pauses are a known tail-latency source in managed runtimes. Without explicit instrumentation and budgets, GC pauses silently degrade p99 performance. The plan requires measured p95/p99 improvements (Phase C exit gate) which requires GC pause visibility.\n\n## Testing Requirements\n- Unit tests: GC pause events are recorded with correct timing data\n- Unit tests: budget violation detection triggers CI failure\n- Benchmark tests: GC pause times on standard workloads stay within defined budgets\n- Regression tests: GC pause times do not degrade after code changes\n- Integration: pause data feeds into evidence ledger format\n\n## Implementation Notes\n- Use std::time::Instant for high-resolution timing\n- Output structured JSON for integration with frankentui dashboards (per 10.14)\n- Budget thresholds should be configurable per environment (lab vs production)\n- Consider ring-buffer storage for recent GC events to limit memory overhead\n\n## Dependencies\n- Blocked by: GC implementation (bd-3ub)\n- Blocks: Performance program benchmarks (10.6), operational readiness diagnostics (10.8)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:23.372225999Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.044090029Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-3"]}
{"id":"bd-51gj","title":"[12] Mitigate scope explosion via strict phase gates and one-lever optimization discipline","description":"Plan Reference: section 12 (Risk Register).\nObjective: Scope explosion:\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:17.552939631Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:39.518581976Z","closed_at":"2026-02-20T07:39:05.031472511Z","close_reason":"Consolidated into single risk register tracking bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-12"]}
{"id":"bd-52ko","title":"[16] External red-team and academic-style evaluations with published methodology.","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nObjective: External red-team and academic-style evaluations with published methodology.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:36.653405607Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:39.558745634Z","closed_at":"2026-02-20T07:46:47.843750720Z","close_reason":"Consolidated into single scientific contribution bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-16"]}
{"id":"bd-5pk","title":"[10.5] Implement hostcall telemetry schema and recorder.","description":"## Plan Reference\nSection 10.5, item 3 (Implement hostcall telemetry schema and recorder). Cross-refs: 9A.2 (Probabilistic Guardplane needs hostcall patterns as evidence), 9E.9 (normative observability surface), 9C.2 (Bayesian decision loop requires structured evidence input).\n\n## What\nImplement a structured telemetry system that records every hostcall made by extensions with sufficient detail for the Probabilistic Guardplane (9A.2) to use as evidence in its Bayesian inference loop. The telemetry schema defines what fields are captured per hostcall. The recorder is the runtime component that captures, timestamps, and persists these records with deterministic ordering guarantees. This is the primary evidence pipeline feeding the security decision system.\n\n## Detailed Requirements\n- Define `HostcallTelemetryRecord` struct with fields: `record_id: u64` (monotonic), `timestamp_ns: u64` (monotonic nanoseconds), `extension_id: ExtensionId`, `hostcall_type: HostcallType`, `capability_used: Capability`, `arguments_hash: [u8; 32]` (hash of call arguments for privacy), `result_status: HostcallResult`, `duration_ns: u64`, `resource_delta: ResourceDelta`, `flow_label: FlowLabel` (IFC label at call time), `decision_id: Option<DecisionId>` (if a security decision was triggered).\n- Define `HostcallType` enum covering all hostcall categories: `FsRead`, `FsWrite`, `NetworkSend`, `NetworkRecv`, `ProcessSpawn`, `EnvRead`, `MemAlloc`, `TimerCreate`, `CryptoOp`, `IpcSend`, `IpcRecv`.\n- Define `HostcallResult` enum: `Success`, `Denied { reason: DenialReason }`, `Error { code: u32 }`, `Timeout`.\n- Implement `TelemetryRecorder` that: (a) accepts records via a lock-free channel (bounded, backpressure on full), (b) assigns monotonic `record_id` and `timestamp_ns`, (c) writes to an append-only log with deterministic binary encoding, (d) supports snapshot/checkpoint for replay alignment.\n- The recorder must guarantee causal ordering: if hostcall A completes before hostcall B starts (within the same extension), A's record_id < B's record_id.\n- Implement `TelemetryQuery` API for the Guardplane to query recent hostcall patterns: `recent_by_extension(ext_id, window)`, `recent_by_type(hostcall_type, window)`, `anomaly_candidates(threshold)`.\n- All telemetry must be available for forensic replay (bd-t2m) with bit-exact reproduction.\n- Telemetry overhead budget: < 2 microseconds per hostcall record in the hot path.\n\n## Rationale\nThe Probabilistic Guardplane (9A.2) cannot make security decisions without evidence. Hostcall patterns are the primary behavioral signal for detecting anomalous extension behavior. The structured schema ensures that Bayesian inference has well-typed inputs. The normative observability surface (9E.9) requires that all runtime-significant events are captured in a structured, queryable format. Deterministic ordering is essential for forensic replay fidelity.\n\n## Testing Requirements\n- **Unit tests**: Record creation with all field combinations. Monotonic ordering invariant (record_id and timestamp always increase). Serialization round-trip for every field type. Query API returns correct results for time-windowed queries.\n- **Performance tests**: Benchmark recording overhead per hostcall (must be < 2us). Benchmark under contention (multiple extensions recording concurrently).\n- **Integration tests**: Record a sequence of hostcalls from a mock extension, query the telemetry, and verify the Guardplane can consume the records as evidence. Verify checkpoint/snapshot produces a consistent view.\n- **Determinism tests**: Record the same hostcall sequence twice with deterministic timestamps; verify bit-identical output.\n- **Backpressure tests**: Fill the telemetry channel and verify graceful handling (no data loss, appropriate backpressure signal to caller).\n\n## Implementation Notes\n- Use a lock-free MPSC channel (e.g., `crossbeam-channel` bounded) for the recording hot path.\n- The append-only log can use a memory-mapped file or a simple `BufWriter` with periodic fsync; choose based on durability requirements.\n- `arguments_hash` uses BLAKE3 for speed; never log raw arguments (privacy + size).\n- The `FlowLabel` field connects to the IFC system (bd-1hw, 10.2); initially can be a placeholder type.\n- Consider a ring-buffer for the query API's recent-window access pattern.\n\n## Dependencies\n- **Blocked by**: bd-xq7 (needs `ExtensionId` and `Capability` types from manifest validation).\n- **Blocks**: bd-3md (Bayesian updater consumes telemetry as evidence), bd-1y5 (action selector needs telemetry context), bd-t2m (forensic replay reads telemetry logs).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.153140274Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.803192866Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-62mo","title":"[14] Any failed-equivalence case invalidates claim publication until fixed or explicitly excluded via versioned benchmark-spec revision.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Any failed-equivalence case invalidates claim publication until fixed or explicitly excluded via versioned benchmark-spec revision.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:31.158639217Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:39.639338516Z","closed_at":"2026-02-20T07:41:20.501707210Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-6pk","title":"[10.9] Define and enforce disruption scorecard (`performance_delta`, `security_delta`, `autonomy_delta`) as release blockers.","description":"## Plan Reference\nSection 10.9, item 2 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis bead defines and enforces the **disruption scorecard** -- the quantitative framework that determines whether FrankenEngine has achieved category-shift status across three mandatory dimensions: `performance_delta`, `security_delta`, and `autonomy_delta`. Unlike the other beads in 10.9 which are individual release gates, this bead is the scoring framework that aggregates evidence from all gates into a go/no-go release decision.\n\nThe scorecard is a release blocker: no frontier release may ship unless all three delta dimensions meet their defined thresholds with evidence-backed scores.\n\n## Gate Criteria\n1. **`performance_delta` definition:** Quantitative threshold (e.g., >= 0% regression vs Node LTS on the canonical benchmark corpus, with >= 10% improvement on at least N core benchmarks) sourced from the Node/Bun comparison harness (bd-1ze).\n2. **`security_delta` definition:** Measurable improvement in attack surface reduction, exfiltration resistance, and compromise-rate suppression versus baseline engines, sourced from adversarial campaign results (bd-3rd), IFC validation (bd-eke), and quarantine mesh validation (bd-uwc).\n3. **`autonomy_delta` definition:** Quantitative measure of self-governance capability -- percentage of core slots that are fully native (bd-181), PLAS coverage of extension cohorts (bd-2n3), and proof-carrying pipeline enablement (bd-2rx).\n4. Each dimension has a hard floor (minimum acceptable) and a target (aspirational), both defined in machine-readable TOML/JSON schema.\n5. Scorecard computation is deterministic and reproducible: given the same evidence bundle, any operator arrives at the same scores.\n6. Scorecard results are published as a signed artifact alongside each candidate release.\n\n## Implementation Ownership\n- **10.9 (this bead):** Defines the scorecard schema, threshold values, computation logic, and enforcement policy.\n- **All other 10.9 gate beads:** Supply the evidence that populates individual scorecard dimensions.\n- **10.12 (Frontier Programs):** Provides benchmark and adversarial campaign raw data.\n- **10.15 (Delta Moonshots):** Provides PLAS, IFC, and replacement lineage evidence.\n- **10.6 (Performance Program):** Provides performance regression/improvement data.\n- **10.7 (Conformance + Verification):** Provides receipt and proof coverage metrics.\n\n## Rationale\nWithout a formal, quantitative disruption scorecard, \"category shift\" remains a subjective claim. The scorecard converts aspiration into auditable evidence. It ensures that each release candidate is evaluated against the same bar, prevents scope erosion (where individual gates pass but the aggregate picture is insufficient), and provides the evidentiary backbone for the category-shift report (bd-f7n).\n\nRelated 9I moonshots: Moonshot Portfolio Governor, Cross-Repo Conformance Lab.\n\n## Verification Requirements\n- **Schema validation:** The scorecard schema is machine-parseable and includes version, dimension definitions, thresholds, and evidence-source references.\n- **Determinism test:** Two independent scorecard computations from the same evidence bundle produce bit-identical output.\n- **Threshold enforcement:** CI integration blocks release pipeline progression when any dimension falls below its hard floor.\n- **Historical tracking:** Scorecard results are appended to a versioned history, enabling trend analysis across release candidates.\n- **Structured logging:** Scorecard computation emits structured logs with fields: `trace_id`, `scorecard_version`, `dimension`, `raw_score`, `threshold_floor`, `threshold_target`, `pass`, `evidence_refs`.\n\n## Dependencies\n- All other 10.9 gate beads (bd-1ze, bd-uwc, bd-2rx, bd-3rd, bd-2n3, bd-181, bd-eke, bd-dkh) -- supply evidence inputs.\n- bd-f7n (category-shift report) -- consumes scorecard output as primary evidence.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:27.852223090Z","created_by":"ubuntu","updated_at":"2026-02-20T07:56:57.213369195Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-6qsi","title":"[10.15] Define specialization receipt schema (`proof_specialization_receipt`) linking security-proof inputs to activated optimization classes and rollback lineage.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Define specialization receipt schema (`proof_specialization_receipt`) linking security-proof inputs to activated optimization classes and rollback lineage.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:52.844002772Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.428325190Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-70bx","title":"[14] Publish benchmark specification, harness code, datasets, and scoring formulas.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Publish benchmark specification, harness code, datasets, and scoring formulas.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:27.571404471Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:39.758672607Z","closed_at":"2026-02-20T07:41:22.023074751Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-74l","title":"Formalize evidence-bound claim language policy","description":"Implements PLAN section 10.1 second TODO. Extend runtime governance with explicit claim-language rules that gate performance/security/compatibility claims on reproducible artifacts, denominator disclosure, and bounded wording requirements.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:25:04.896000733Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:39.841491635Z","closed_at":"2026-02-20T07:26:12.419622162Z","close_reason":"Extended docs/RUNTIME_CHARTER.md with binding claim-language policy and updated README charter summary","source_repo":".","compaction_level":0,"original_size":0,"labels":["evidence","governance","plan","section-10-1"]}
{"id":"bd-7rwi","title":"[10.15] Define verified self-replacement schema (`slot_registry`, `delegate_cell_manifest`, `replacement_receipt`, `promotion_decision`) with deterministic encoding and signature requirements.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Define verified self-replacement schema (`slot_registry`, `delegate_cell_manifest`, `replacement_receipt`, `promotion_decision`) with deterministic encoding and signature requirements.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:53.891031464Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.141831377Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-83jh","title":"[10.15] Add synthesis search-budget contract (time/compute/depth caps) with fail-closed conservative fallback behavior on budget exhaustion.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add synthesis search-budget contract (time/compute/depth caps) with fail-closed conservative fallback behavior on budget exhaustion.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:50.303431746Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.281209489Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-89l2","title":"[10.14] Create a `franken_engine` storage adapter layer that binds runtime persistence contracts to `frankensqlite` APIs.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Create a `franken_engine` storage adapter layer that binds runtime persistence contracts to `frankensqlite` APIs.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:45.545669748Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.512425530Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-8az","title":"[10.10] Implement deterministic nonce derivation for any AEAD-protected data-plane envelope.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Implement deterministic nonce derivation for any AEAD-protected data-plane envelope.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:31.240856597Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.235562750Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-8guj","title":"[13] service/API control surfaces relevant to runtime operations leverage `/dp/fastapi_rust` patterns/components where they provide equal or better capability","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: service/API control surfaces relevant to runtime operations leverage `/dp/fastapi_rust` patterns/components where they provide equal or better capability\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:22.385059452Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:40.039773824Z","closed_at":"2026-02-20T07:39:59.385562019Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-a5xc","title":"[14] Require at least two independent third-party reruns before category-level claims are treated as externally validated.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Require at least two independent third-party reruns before category-level claims are treated as externally validated.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:32.364545016Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:40.079251595Z","closed_at":"2026-02-20T07:41:19.994875004Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-ag4","title":"[10.8] Add release checklist requiring security and performance artifact bundles.","description":"## Plan Reference\nSection 10.8, item 3. Cross-refs: Section 11 (evidence and decision contracts), Section 14.3 (reproducibility + neutral verification), Phase E exit gate.\n\n## What\nAdd a release checklist requiring security and performance artifact bundles before any release is shipped. This is the enforcement mechanism for the evidence-backed discipline.\n\n## Detailed Requirements\n- Release checklist: machine-readable checklist that CI/release pipeline enforces\n- Required security artifacts: conformance suite pass, adversarial corpus results, containment latency data, IFC coverage, PLAS witness coverage\n- Required performance artifacts: benchmark suite results with >= 3x gate, flamegraph comparisons, GC pause budgets\n- Required reproducibility artifacts: env.json, manifest.json, repro.lock (per 10.1 reproducibility contract)\n- Required operational artifacts: safe-mode test pass, diagnostics CLI functional test, evidence export test\n- Blocking gate: release pipeline cannot proceed without all required artifacts\n- Artifact storage: all release artifacts stored with release tag for later verification\n\n## Rationale\nSection 11 mandates: 'No contract, no merge.' The release checklist is the program-level equivalent: no evidence bundle, no release. The plan requires that every claim ships with proof artifacts. This checklist operationalizes that principle at the release boundary, ensuring nothing ships without the backing evidence.\n\n## Testing Requirements\n- CI test: release pipeline blocks when any required artifact is missing\n- CI test: release pipeline succeeds when all artifacts are present and valid\n- Test: artifact bundle is complete and self-contained (can be independently verified)\n- Test: reproducibility artifacts enable independent re-run of benchmarks\n\n## Dependencies\n- Blocked by: benchmark suite (10.6), conformance suite (10.7), diagnostics CLI (bd-2mm), safe-mode (bd-2qx)\n- Blocks: Phase E exit gate (evidence-backed operational readiness report)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:27.547431330Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:09.817383169Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-8"]}
{"id":"bd-ami3","title":"[10.15] Add frankensqlite-backed witness/index stores and conformance tests for deterministic witness retrieval and replay joins.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add frankensqlite-backed witness/index stores and conformance tests for deterministic witness retrieval and replay joins.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:51.303479086Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:40.942619721Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-anuw","title":"[14] Provide one-command neutral verifier mode that replays official runs and validates scoring + equivalence checks independently.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Provide one-command neutral verifier mode that replays official runs and validates scoring + equivalence checks independently.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:32.125965809Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:40.197572750Z","closed_at":"2026-02-20T07:41:20.099462276Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-c1co","title":"[11] Evidence And Decision Contracts (Mandatory) - Comprehensive Execution Epic","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nPurpose: Operationalize this section's governance/validation/adoption requirements into enforceable engineering work.\nQuality requirements for all children:\n- explicit acceptance criteria and failure semantics\n- unit-test and e2e/integration verification expectations\n- detailed structured logging and reproducibility artifacts where applicable\n- traceability back to category-level goals (security, performance, explainability, adoption)\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:34:15.233637630Z","created_by":"ubuntu","updated_at":"2026-02-20T07:53:36.022750003Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-11"],"dependencies":[{"issue_id":"bd-c1co","depends_on_id":"bd-11ni","type":"parent-child","created_at":"2026-02-20T07:52:42.378952364Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-13a5","type":"parent-child","created_at":"2026-02-20T07:53:36.022665776Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-18fu","type":"parent-child","created_at":"2026-02-20T07:52:43.226196536Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-1tsf","type":"blocks","created_at":"2026-02-20T07:34:37.717812047Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-2h70","type":"parent-child","created_at":"2026-02-20T07:52:48.136269269Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-2ntw","type":"parent-child","created_at":"2026-02-20T07:52:48.752901876Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-3qm1","type":"parent-child","created_at":"2026-02-20T07:52:53.463205053Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-3tjn","type":"parent-child","created_at":"2026-02-20T07:52:53.822655043Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-ulle","type":"parent-child","created_at":"2026-02-20T07:52:56.790381276Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c1co","depends_on_id":"bd-von8","type":"parent-child","created_at":"2026-02-20T07:52:56.910120692Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-crp","title":"[10.2] Define parser trait + canonical AST invariants for ES2020 script/module goals.","description":"## Plan Reference\nSection 10.2, item 1. Cross-refs: 9A.1, 9B.1, 9F.4, Phase A exit gate.\n\n## What\nDefine the parser trait interface and canonical AST type hierarchy for ES2020 script and module goal symbols. This is the foundation of the entire compilation pipeline - IR0 (SyntaxIR) is produced by this layer.\n\n## Detailed Requirements\n- Parser trait must be generic over input source (string, stream, file) with deterministic error reporting\n- AST nodes must be canonical: structurally identical source produces identical AST (no parse-order-dependent metadata)\n- Must support both Script and Module goal symbols per ES2020 spec\n- AST must carry source location spans for error reporting and debugging\n- AST serialization must be deterministic for replay/hash purposes (canonical serialization invariant from plan)\n- Must NOT mirror V8 or QuickJS internal AST structures - this is a de novo design informed by observable ES2020 semantics (per Section 10.1 donor-extraction policy)\n\n## Rationale\nThe plan's multi-level IR stack (IR0→IR4) starts here. Without a well-defined parser trait and canonical AST, nothing downstream can be deterministic. The 9F.4 Capability-Typed TS Execution Contract requires that capability intent be traceable from source through all IR levels. This means the AST must be designed to support downstream capability annotation, not retrofitted later.\n\n## Testing Requirements\n- Unit tests: parse valid ES2020 script/module sources, verify AST structure matches expected canonical form\n- Unit tests: parse invalid sources, verify deterministic error with source location\n- Unit tests: verify canonical serialization (same source → same serialized AST bytes)\n- Property tests: round-trip parse → serialize → parse produces identical AST\n- Conformance: test262 parse-only subset as baseline validation\n- Edge cases: empty source, unicode identifiers, nested template literals, destructuring patterns\n\n## Implementation Notes\n- Define in crates/franken-engine as core parser trait\n- Consider arena allocation for AST nodes (9B.1 recommends arena allocation for IR nodes)\n- AST node types should be exhaustive enum, not trait objects, for determinism and performance\n- Hash invariant: define canonical hash over AST for use in IR0 witness artifacts\n\n## Dependencies\n- Blocks: IR contract (bd-1wa), lowering pipelines (bd-ug9), interpreter skeleton (bd-2f8)\n- Blocked by: nothing (foundational)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.404986697Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.723705472Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-d6h","title":"[10.12] Add counterexample synthesizer for conflicting policy controllers and ambiguous merges.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Add counterexample synthesizer for conflicting policy controllers and ambiguous merges.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:39.936839901Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.193348469Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-d93","title":"[10.7] Integrate transplanted extension conformance assets into runnable suites.","description":"## Plan Reference\nSection 10.7 (Conformance + Verification), item 1.\nRelated: Phase A exit gate (baseline conformance passes), 10.1 (feature-parity tracker wired to test262/lockstep/waiver governance), 10.5 (Extension Host + Security).\n\n## What\nIntegrate transplanted extension conformance assets -- test fixtures, expected-output baselines, edge-case vectors, and harness scaffolding harvested from donor runtimes (QuickJS, reference implementations) during the semantic-donor extraction process -- into runnable, CI-gated conformance suites within the FrankenEngine test infrastructure.\n\n## Detailed Requirements\n1. **Asset inventory manifest:** Produce a machine-readable manifest (`conformance_assets.json`) listing every transplanted asset with fields: `source_donor`, `semantic_domain` (e.g., `promise_resolution`, `proxy_trap_ordering`, `module_namespace_binding`), `normative_reference` (ES2020 clause), `fixture_hash`, `expected_output_hash`, and `import_date`.\n2. **Harness adapter layer:** Implement a thin adapter that maps donor-specific harness conventions (e.g., `$262.createRealm`, `$DONE`, `print()`) to FrankenEngine's native test driver API without introducing behavioral shims that could mask semantic divergence.\n3. **Deterministic runner:** Each suite file executes under a deterministic seed, fixed locale/timezone, and reproducible GC schedule. Non-determinism must cause hard failure, never silent skip.\n4. **Output canonicalization:** Normalize floating-point formatting, error message strings, and property enumeration order to canonical form before comparison, with explicit documentation of each normalization rule and its ES2020 justification.\n5. **Waiver file integration:** Any asset that cannot pass must have an entry in the central waiver file (`conformance_waivers.toml`) with fields: `asset_id`, `reason_code` (enum: `harness_gap | host_hook_missing | intentional_divergence | not_yet_implemented`), `tracking_bead`, `expiry_date`. Zero silent failures policy: unwaived failures block CI.\n6. **Structured logging:** Emit per-asset structured log lines with fields: `trace_id`, `asset_id`, `semantic_domain`, `outcome` (pass|fail|waived|error), `duration_us`, `error_code`, `error_detail`.\n7. **Evidence artifact:** Each CI run produces a `conformance_evidence.jsonl` bundle linking run manifest, asset manifest hash, pass/fail/waiver counts, and environment fingerprint for reproducibility contract compliance.\n\n## Rationale\nTransplanted conformance assets represent the highest-fidelity record of donor-runtime semantic behavior. Failing to integrate them into runnable suites means the extraction investment is wasted and semantic drift between FrankenEngine and the donor behavioral specification goes undetected. This is the foundational layer upon which all other 10.7 verification beads build.\n\n## Testing Requirements (Meta-Tests for Test Infrastructure)\n1. **Harness-fidelity meta-test:** Verify the adapter layer produces identical outputs to the donor harness for a reference subset (>= 50 assets) by running both and diffing canonicalized output.\n2. **Waiver enforcement meta-test:** Inject a synthetic unwaived failure and confirm CI blocks. Inject a waived failure and confirm CI passes with waiver logged.\n3. **Non-determinism detection meta-test:** Run the same asset 10x under identical seed and confirm bitwise-identical output; run under a different seed and confirm the harness detects the difference.\n4. **Manifest integrity meta-test:** Tamper with one asset file and confirm the manifest hash check fails before execution begins.\n5. **Evidence artifact schema meta-test:** Validate `conformance_evidence.jsonl` against a JSON Schema and confirm all required fields are present and non-empty.\n\n## Implementation Notes\n- Transplanted assets live under `tests/conformance/transplanted/` with subdirectories per semantic domain.\n- The adapter layer is a Rust module (`crate::test_harness::donor_adapter`) that implements `DonorHarnessApi` trait.\n- Runner integrates with `rch`-wrapped compilation/test workflows for heavy workloads.\n- Waiver file is shared with bd-11p (test262 integration) to maintain a single source of truth for conformance exceptions.\n\n## Dependencies\n- Upstream: 10.1 (donor-extraction scope document, feature-parity tracker), 10.2 (VM Core parser/evaluator must exist to run assets).\n- Downstream: bd-11p (test262 integration builds on this harness), bd-2rk (probabilistic security conformance reuses runner infrastructure), all other 10.7 beads consume the evidence artifact format.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:26.052376658Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.424846917Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-7"]}
{"id":"bd-dkh","title":"[10.9] Release gate: proof-specialized lanes demonstrate positive performance delta versus ambient-authority lanes with 100% specialization-receipt coverage and deterministic fallback correctness (implementation ownership: `10.12` + `10.15` + `10.6` + `10.7`).","description":"## Plan Reference\nSection 10.9, item 9 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that proof-specialized lanes -- built collaboratively by the Frontier Programs track (10.12), Delta Moonshots track (10.15), Performance Program (10.6), and Conformance track (10.7) -- demonstrate a positive performance delta versus ambient-authority lanes, with 100% specialization-receipt coverage and deterministic fallback correctness. This is the most cross-cutting gate in Section 10.9, validating that the convergence of proof-carrying code, capability-typed execution, and performance optimization yields measurable real-world improvement.\n\nThe gate owner does not build the proof-specialized lanes; the gate owner benchmarks them against ambient-authority lanes, audits receipt coverage, and validates fallback behavior.\n\n## Gate Criteria\n1. Proof-specialized lanes achieve a positive performance delta (wall-time, throughput, or memory -- at least one, ideally all) versus ambient-authority lanes on the canonical benchmark corpus, with statistical significance (p < 0.05).\n2. 100% specialization-receipt coverage: every optimization decision in a proof-specialized lane is backed by a signed specialization receipt containing: optimization name, proof reference, capability witness reference, pre/post performance measurement, and receipt signature.\n3. Deterministic fallback correctness: when a proof-specialized lane encounters a case where specialization cannot be applied (e.g., proof generation fails, capability is revoked), it falls back to the ambient-authority path and produces correct output with a structured fallback receipt.\n4. Fallback behavior is tested with deliberately injected proof failures and capability revocations; the lane never crashes, hangs, or produces incorrect output.\n5. Performance measurements use the same harness and methodology as the Node/Bun comparison gate (bd-1ze) to ensure comparability.\n6. Receipt chain for a full proof-specialized compilation is replayable end-to-end: an independent operator can verify the entire specialization decision history from receipts alone.\n\n## Implementation Ownership\n- **10.12 (Frontier Programs):** Builds the proof-carrying optimization infrastructure and specialization runtime. Encompasses 9F moonshots: Verified Adaptive Compiler, Cryptographic Receipts, SLO-Proven Scheduler, Semantic Build Graph.\n- **10.15 (Delta Moonshots):** Builds capability-typed execution, PLAS integration, and specialization receipt signing. Encompasses 9I moonshots: Security-Proof-Guided Specialization, TEE-Bound Receipts, PLAS.\n- **10.6 (Performance Program):** Provides performance benchmarking infrastructure, regression detection, and statistical analysis tooling.\n- **10.7 (Conformance + Verification):** Provides receipt verification infrastructure, conformance test suites, and fallback correctness validation.\n- **10.9 (this gate):** Orchestrates the cross-track evaluation, benchmarks proof-specialized vs ambient-authority lanes, audits receipt coverage, validates fallback behavior, and certifies the evidence bundle.\n\n## Rationale\nThis gate is the culmination of FrankenEngine's core thesis: that proof-carrying, capability-typed execution can be not just safer but also faster than ambient-authority execution. If proof-specialized lanes are slower than ambient-authority lanes, the entire moonshot narrative collapses -- security and correctness guarantees become costs rather than enablers. By requiring positive performance delta with 100% receipt coverage, this gate proves that the security overhead is not just tolerable but actually enables optimizations that ambient-authority code cannot safely perform. This gate feeds all three dimensions of the disruption scorecard (bd-6pk): `performance_delta` (positive delta), `security_delta` (receipt-backed proof chain), and `autonomy_delta` (self-specializing optimization).\n\nRelated 9F moonshots: Verified Adaptive Compiler, Cryptographic Receipts, SLO-Proven Scheduler, Semantic Build Graph, Autopilot Perf Scientist.\nRelated 9I moonshots: Security-Proof-Guided Specialization, TEE-Bound Receipts, PLAS.\n\n## Verification Requirements\n- **Performance benchmark:** Run the canonical benchmark corpus on both proof-specialized and ambient-authority lanes under identical conditions; confirm positive delta with p < 0.05.\n- **Receipt coverage audit:** Enumerate all specialization decisions in a representative compilation; confirm 100% receipt coverage with no gaps.\n- **Receipt chain replay:** An independent operator replays the full receipt chain for a representative compilation; confirm all receipts verify and the chain is complete.\n- **Fallback injection testing:** Inject proof failures and capability revocations; confirm the lane falls back correctly, produces correct output, and emits fallback receipts.\n- **Fallback performance:** Confirm fallback path performance is no worse than ambient-authority lane performance (fallback does not introduce a regression).\n- **Cross-gate consistency:** Confirm performance measurements are consistent with the Node/Bun comparison harness methodology (bd-1ze).\n- **Scorecard integration:** Results feed all three dimensions of the disruption scorecard (bd-6pk).\n- **Structured logging:** Proof-specialized lane runs emit structured logs with fields: `trace_id`, `lane_type` (proof-specialized/ambient-authority), `optimization_pass`, `proof_status`, `capability_witness_ref`, `specialization_receipt_hash`, `fallback_triggered`, `wall_time_ns`, `memory_peak_bytes`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate results feed all three scorecard dimensions.\n- bd-1ze (Node/Bun comparison harness gate) -- shares benchmark methodology and corpus.\n- bd-2rx (proof-carrying optimization gate) -- proof-specialized lanes depend on the proof-carrying pipeline being enabled.\n- bd-2n3 (PLAS gate) -- proof-specialized lanes require PLAS-granted capabilities for specialization.\n- bd-181 (GA native lanes gate) -- proof-specialized lanes build on fully native GA lanes.\n- 10.12 Frontier Programs track -- delivers proof-carrying optimization infrastructure.\n- 10.15 Delta Moonshots track -- delivers capability-typed execution and receipt signing.\n- 10.6 Performance Program -- delivers benchmarking infrastructure.\n- 10.7 Conformance + Verification track -- delivers receipt verification and fallback conformance testing.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.858616381Z","created_by":"ubuntu","updated_at":"2026-02-20T07:59:49.221851223Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-du2","title":"[10.12] Define fleet immune-system message protocol for signed evidence, local confidence, and containment intent propagation.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Define fleet immune-system message protocol for signed evidence, local confidence, and containment intent propagation.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:38.863421634Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.485227632Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-eke","title":"[10.9] Release gate: deterministic IFC protections block unauthorized sensitive-source exfiltration across the published exfil corpus, with receipt-backed declassification audit for approved exceptions (implementation ownership: `10.15` + `10.5` + `10.7`).","description":"## Plan Reference\nSection 10.9, item 8 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that deterministic Information Flow Control (IFC) protections -- built by the Delta Moonshots track (10.15), the Security track (10.5), and the Conformance track (10.7) -- successfully block all unauthorized sensitive-source exfiltration attempts across the published exfiltration corpus. The gate also confirms that approved exceptions (legitimate data flows that cross security boundaries) are covered by receipt-backed declassification audit trails.\n\nThe gate owner does not build the IFC system; the gate owner runs the exfiltration corpus against the deployed IFC protections and certifies the pass/fail evidence bundle.\n\n## Gate Criteria\n1. The published exfiltration corpus (a curated set of exfil vectors: direct channel, covert timing channel, storage channel, network side-channel, prototype chain leak, etc.) is executed against FrankenEngine with IFC enabled.\n2. Every unauthorized exfiltration attempt in the corpus is blocked (0% success rate for unauthorized flows).\n3. For each blocked attempt, a structured blocking receipt is produced containing: flow source label, flow destination label, blocking policy rule, timestamp, and receipt signature.\n4. Approved exceptions (declassified flows) are explicitly listed in a declassification policy, and each approved flow produces a signed declassification receipt containing: declassification justification, approver identity, policy version, and receipt signature.\n5. The IFC enforcement is deterministic: replaying the same exfil corpus against the same engine configuration and policy version produces bit-identical blocking/declassification decisions.\n6. No IFC bypass exists through reflection, dynamic code generation (eval/Function), or native addon escape hatches -- the corpus includes vectors targeting these paths.\n\n## Implementation Ownership\n- **10.15 (Delta Moonshots):** Builds the IFC enforcement runtime and declassification receipt infrastructure. Encompasses 9I moonshots: IFC, Security-Proof-Guided Specialization, TEE-Bound Receipts.\n- **10.5 (Security):** Defines the exfiltration corpus, security label taxonomy, and declassification policy framework.\n- **10.7 (Conformance + Verification):** Provides the receipt verification infrastructure and conformance test harness for IFC properties.\n- **10.9 (this gate):** Executes the exfiltration corpus, evaluates results against the 0% unauthorized success criterion, validates declassification receipts, and certifies the evidence bundle.\n\n## Rationale\nDeterministic IFC is one of FrankenEngine's most ambitious security claims -- no mainstream JS/TS runtime enforces information flow control at the runtime level. The claim is only credible if it holds against a comprehensive, curated exfiltration corpus that includes both obvious and subtle leak vectors. A single missed exfiltration path invalidates the guarantee. The receipt-backed declassification audit ensures that approved exceptions are explicit and accountable, not silent holes. This gate provides the primary evidence for the `security_delta` dimension of the disruption scorecard (bd-6pk).\n\nRelated 9I moonshots: IFC, Security-Proof-Guided Specialization, TEE-Bound Receipts.\nRelated 9F moonshots: Cryptographic Receipts, Capability-Typed TS.\n\n## Verification Requirements\n- **Full corpus execution:** Run the entire published exfiltration corpus; confirm 0% unauthorized success rate with no exceptions.\n- **Blocking receipt validation:** For a representative sample of blocked flows, verify receipt signatures independently using the published trust anchor.\n- **Declassification audit:** For every approved exception, confirm a signed declassification receipt exists with a justification traceable to the declassification policy.\n- **Determinism test:** Run the corpus twice with identical configuration; confirm bit-identical blocking/declassification decisions.\n- **Bypass vector coverage:** Confirm the corpus includes vectors targeting: eval/Function, Proxy/Reflect, native addons, SharedArrayBuffer, structured clone, and any FrankenEngine-specific escape surfaces.\n- **Scorecard integration:** Results feed `security_delta` in the disruption scorecard (bd-6pk).\n- **Structured logging:** IFC validation runs emit structured logs with fields: `trace_id`, `exfil_vector_id`, `source_label`, `dest_label`, `action` (block/declassify), `policy_rule`, `receipt_hash`, `receipt_signature_valid`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate results feed `security_delta` dimension.\n- bd-3rd (adversarial campaign runner gate) -- adversarial campaigns may include IFC bypass attempts; results should be consistent.\n- bd-uwc (quarantine mesh gate) -- quarantine mesh may trigger IFC-related isolation.\n- 10.15 Delta Moonshots track -- delivers IFC enforcement runtime.\n- 10.5 Security track -- delivers exfiltration corpus and declassification policy.\n- 10.7 Conformance + Verification track -- delivers receipt verification infrastructure.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.716828695Z","created_by":"ubuntu","updated_at":"2026-02-20T07:59:16.116040777Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-esst","title":"[16] Scientific Contribution Targets - Comprehensive Execution Epic","description":"Plan Reference: section 16 (Scientific Contribution Targets).\nPurpose: Operationalize this section's governance/validation/adoption requirements into enforceable engineering work.\nQuality requirements for all children:\n- explicit acceptance criteria and failure semantics\n- unit-test and e2e/integration verification expectations\n- detailed structured logging and reproducibility artifacts where applicable\n- traceability back to category-level goals (security, performance, explainability, adoption)\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:34:15.754049481Z","created_by":"ubuntu","updated_at":"2026-02-20T07:53:36.323393241Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-16"],"dependencies":[{"issue_id":"bd-esst","depends_on_id":"bd-16up","type":"parent-child","created_at":"2026-02-20T07:52:43.066907304Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-1jak","type":"blocks","created_at":"2026-02-20T07:34:38.887370442Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-1tsf","type":"blocks","created_at":"2026-02-20T07:34:38.203687358Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-21ds","type":"blocks","created_at":"2026-02-20T07:34:38.790126648Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-2501","type":"parent-child","created_at":"2026-02-20T07:53:36.323316037Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-2cc8","type":"parent-child","created_at":"2026-02-20T07:52:47.501470326Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-2pwr","type":"parent-child","created_at":"2026-02-20T07:52:48.911310567Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-2zk0","type":"parent-child","created_at":"2026-02-20T07:52:50.578236785Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-37cc","type":"parent-child","created_at":"2026-02-20T07:52:51.260019140Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-3c8n","type":"parent-child","created_at":"2026-02-20T07:52:51.784681513Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-3ebk","type":"parent-child","created_at":"2026-02-20T07:52:52.024234073Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-esst","depends_on_id":"bd-52ko","type":"parent-child","created_at":"2026-02-20T07:52:54.581387404Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-ewy","title":"[10.12] Define attested execution-cell architecture and trust-root interface contract.","description":"Plan Reference: section 10.12 (Frontier Programs Execution Track (9H Canonical Owners)).\nObjective: Define attested execution-cell architecture and trust-root interface contract.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:39.482664196Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.318551135Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-f7n","title":"[10.9] Publish first category-shift report demonstrating beyond-parity capabilities with evidence bundles.","description":"## Plan Reference\nSection 10.9, item 10 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is the **capstone deliverable** of the Moonshot Disruption Track. It is the publication of the first category-shift report -- a formal document demonstrating that FrankenEngine has achieved beyond-parity capabilities relative to incumbent JS/TS runtimes, backed by evidence bundles from all preceding release gates. Unlike the other beads in 10.9 which are verification gates, this bead produces a public-facing artifact that synthesizes gate results into a coherent narrative with auditable evidence.\n\nThis bead cannot be completed until all other 10.9 gates have passed and the disruption scorecard (bd-6pk) shows all three dimensions at or above their target thresholds.\n\n## Gate Criteria\n1. All nine preceding 10.9 beads (bd-1ze through bd-dkh) are closed with passing evidence bundles.\n2. The disruption scorecard (bd-6pk) shows all three dimensions (`performance_delta`, `security_delta`, `autonomy_delta`) at or above their target thresholds (not just hard floors).\n3. The report includes a structured evidence section for each beyond-parity capability, with: capability name, claim statement, evidence summary, link to full evidence bundle, and reproduction instructions.\n4. Beyond-parity capabilities documented must include at minimum: proof-carrying optimization, deterministic IFC, PLAS with signed witnesses, autonomous quarantine mesh, and adversarial compromise-rate suppression.\n5. The report includes a methodology section explaining how claims were validated, the statistical frameworks used, and known limitations or caveats.\n6. The report is peer-reviewed by at least two reviewers who did not author the evidence bundles.\n7. All evidence bundles referenced in the report are published alongside it in a content-addressed archive with integrity hashes.\n\n## Implementation Ownership\n- **10.9 (this bead):** Authors the report, synthesizes evidence from all gates, coordinates peer review, and publishes the final artifact.\n- **All other 10.9 gate beads:** Supply the evidence bundles that the report references.\n- **bd-6pk (disruption scorecard):** Supplies the aggregate scoring that validates the beyond-parity claim.\n\n## Rationale\nThe category-shift report is the external-facing proof that FrankenEngine has achieved its moonshot ambitions. Without this report, the project's achievements remain internal engineering milestones. With it, the achievements become a public, auditable, reproducible demonstration of category-shifting capability. The report transforms engineering evidence into a strategic asset.\n\nThis report directly addresses the 9F moonshot vision (15 frontier capabilities) and the 9I delta moonshot vision (8 additional capabilities) by providing a single, coherent document that maps evidence to capabilities.\n\nRelated 9I moonshots: Moonshot Portfolio Governor (the report is, in effect, the portfolio governor's output artifact).\n\n## Verification Requirements\n- **Gate prerequisite check:** Confirm all nine preceding 10.9 beads are in `closed` status with passing evidence bundles before report authoring begins.\n- **Scorecard threshold check:** Confirm the disruption scorecard shows all three dimensions at or above target thresholds.\n- **Evidence completeness audit:** For each claim in the report, confirm the referenced evidence bundle exists, is accessible, and its integrity hash matches.\n- **Reproduction spot-check:** For at least three claims, an independent operator follows the reproduction instructions and confirms the stated result.\n- **Peer review:** At least two reviewers who did not author evidence bundles sign off on the report's accuracy, completeness, and fair representation of limitations.\n- **Publication verification:** Confirm the report and all referenced evidence bundles are published in the content-addressed archive with correct integrity hashes.\n- **Structured logging:** Report generation and publication emit structured logs with fields: `trace_id`, `report_version`, `claim_id`, `evidence_bundle_ref`, `evidence_hash`, `reviewer_id`, `review_status`, `publication_hash`.\n\n## Dependencies\n- bd-1ze (Node/Bun comparison harness gate) -- supplies performance evidence.\n- bd-6pk (disruption scorecard) -- supplies aggregate scoring.\n- bd-uwc (quarantine mesh gate) -- supplies quarantine resilience evidence.\n- bd-2rx (proof-carrying optimization gate) -- supplies proof pipeline evidence.\n- bd-3rd (adversarial campaign runner gate) -- supplies compromise-rate suppression evidence.\n- bd-2n3 (PLAS gate) -- supplies PLAS accountability evidence.\n- bd-181 (GA native lanes gate) -- supplies native lane evidence.\n- bd-eke (IFC gate) -- supplies exfiltration blocking evidence.\n- bd-dkh (proof-specialized lanes gate) -- supplies performance delta and receipt coverage evidence.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.996358340Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:14.954499440Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-fp53","title":"[14] Equivalent side-effect trace class (filesystem/network/process/policy actions normalized by contract schema).","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Equivalent side-effect trace class (filesystem/network/process/policy actions normalized by contract schema).\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:29.692115611Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:40.663375431Z","closed_at":"2026-02-20T07:41:21.126076460Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-gr1","title":"[10.11] Add BOCPD-based regime detector for workload/health stream shifts feeding policy decisions.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add BOCPD-based regime detector for workload/health stream shifts feeding policy decisions.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:35.371586294Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.318118761Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-hli","title":"[10.11] Gate all remote operations behind explicit runtime capability (no implicit network side effects).","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Gate all remote operations behind explicit runtime capability (no implicit network side effects).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:36.110278994Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.089632435Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-iqrn","title":"[15] Migration kits that convert existing Node/Bun extension workflows into capability-typed FrankenEngine workflows.","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Migration kits that convert existing Node/Bun extension workflows into capability-typed FrankenEngine workflows.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:34.599613006Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:40.782995134Z","closed_at":"2026-02-20T07:45:53.787429606Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-j7z","title":"[10.1] Add feature-parity tracker wired to `test262`, lockstep corpora, and waiver governance.","description":"## Plan Reference\nSection 10.1, item 7. Cross-refs: 9F.6 (Tri-Runtime Lockstep Oracle), 10.7 (conformance + verification), Phase A/D exit gates.\n\n## What\nAdd a feature-parity tracker wired to test262, lockstep corpora, and waiver governance. This tracks which ES2020 features are implemented, which pass test262, and which have formal waivers.\n\n## Detailed Requirements\n- Feature matrix: every ES2020 spec feature with status (not started, in progress, passing, waived)\n- test262 integration: automated tracking of test262 pass/fail per feature area\n- Lockstep corpus integration: automated tracking of behavior match vs Node/Bun per feature\n- Waiver governance: formal waiver process for features that intentionally differ from spec or incumbents\n- Zero silent failures: any test262 failure must be either fixed or formally waived (no ignored failures)\n- Dashboard: queryable current status for release gate decisions\n\n## Rationale\nPhase A exit gate requires native execution lanes pass baseline conformance. Phase D requires Node/Bun surface superset. Without systematic tracking, it's impossible to know which features are missing, which are intentionally different, and which are bugs. The waiver governance prevents silent spec non-compliance.\n\n## Testing Requirements\n- Integration: test262 suite runs and results are captured in tracker\n- Integration: lockstep corpus runs and results are captured in tracker\n- Governance: waiver records are immutable and auditable\n- Gate: release pipeline queries tracker and blocks on failing criteria\n\n## Dependencies\n- Blocked by: semantic donor spec (bd-3u5)\n- Blocks: Phase A/D exit gates, compliance tracking\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.280072732Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.773319234Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-1"]}
{"id":"bd-jaqy","title":"[10.13] Add fallback validation proving control-plane failure degrades to deterministic safe mode rather than undefined behavior.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Add fallback validation proving control-plane failure degrades to deterministic safe mode rather than undefined behavior.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:44.412727627Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.284649267Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-js4","title":"[10.6] Add opportunity matrix scoring to optimization workflow.","description":"## Plan Reference\nSection 10.6, item 4. Cross-refs: 9D (extreme-software-optimization - opportunity score >= 2.0), 9F.14 (Autopilot Performance Scientist - VOI selection).\n\n## What\nAdd opportunity matrix scoring to the optimization workflow. Each potential optimization is scored based on expected gain, risk, and engineering cost before implementation begins.\n\n## Detailed Requirements\n- Opportunity matrix: ranked list of optimization candidates with scores\n- Scoring inputs: hotspot profile data, estimated performance gain, implementation risk, engineering effort\n- Opportunity score threshold: only pursue optimizations with score >= 2.0 (per 9D global rule)\n- VOI-based prioritization: score includes value-of-information component (9F.14) estimating expected performance gain per engineering hour\n- Historical tracking: record which optimizations were pursued, their predicted vs actual impact\n- Integration with flamegraph data (bd-1nn) and benchmark results (bd-2ql)\n\n## Rationale\nPer 9D global rule: 'Implement one lever per commit with opportunity score >= 2.0.' This prevents random optimization and focuses effort where measured impact is highest. The Autopilot Performance Scientist (9F.14) concept formalizes this: 'Optimization effort concentrates where probability of meaningful win is highest, reducing random tuning churn.'\n\n## Testing Requirements\n- Unit tests: scoring function produces correct scores for known inputs\n- Unit tests: threshold filter rejects low-score candidates\n- Unit tests: scoring is deterministic given same inputs\n- Integration test: end-to-end flow from profile data → candidate generation → scoring → ranked output\n\n## Dependencies\n- Blocked by: flamegraph pipeline (bd-1nn), benchmark suite (bd-2ql)\n- Blocks: one-lever policy enforcement (bd-2l6)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:25.615583411Z","created_by":"ubuntu","updated_at":"2026-02-20T07:54:09.937292413Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-6"]}
{"id":"bd-kfe4","title":"[10.15] Add version-matrix CI lane (N/N-1/N+1 where applicable) for contract compatibility checks across supported repo/version combinations.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Add version-matrix CI lane (N/N-1/N+1 where applicable) for contract compatibility checks across supported repo/version combinations.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:49.135710723Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:41.562157030Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-kr99","title":"[10.15] Implement signed replacement-lineage log with transparency-verifiable append semantics and independent verifier CLI integration.","description":"Plan Reference: section 10.15 (Delta Moonshots Execution Track (9I)).\nObjective: Implement signed replacement-lineage log with transparency-verifiable append semantics and independent verifier CLI integration.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:54.408624545Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.998884219Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-15"]}
{"id":"bd-lpl","title":"[10.10] Persist highest accepted checkpoint frontier and reject rollback/regression attempts.","description":"Plan Reference: section 10.10 (FCP-Inspired Hardening + Interop Track).\nObjective: Persist highest accepted checkpoint frontier and reject rollback/regression attempts.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:29.977331511Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:44.609075066Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-10"]}
{"id":"bd-m9pa","title":"[10.13] Integrate obligation-tracking for two-phase safety-critical operations on extension-host paths and fail lab runs on unresolved obligations.","description":"# Integrate Obligation-Tracking for Two-Phase Safety-Critical Operations\n\n## Plan Reference\nSection 10.13, Item 8.\n\n## What\nIntegrate the obligation-tracking system (owned by 10.11) into extension-host paths so that every two-phase safety-critical operation (e.g., resource allocation followed by guaranteed cleanup, permission grant followed by audit) is tracked as an obligation, and frankenlab runs fail if any obligation remains unresolved at region close.\n\n## Detailed Requirements\n- **Integration/binding nature**: The obligation-tracking primitive (create obligation -> fulfill/cancel obligation) is defined by 10.11. This bead wires it into the extension-host subsystem at every point where a two-phase operation occurs.\n- Identify all two-phase safety-critical operations in the extension-host subsystem:\n  - Resource allocation (memory, file handles, network sockets) with guaranteed cleanup.\n  - Permission grants with mandatory audit trail.\n  - State mutations with mandatory rollback-on-failure.\n  - Evidence commitments (begin-evidence -> commit-evidence).\n- Each two-phase operation must create an obligation when phase 1 begins and resolve it when phase 2 completes.\n- Obligations are scoped to the enclosing execution region (bd-1ukb): when a region closes, all obligations must be resolved.\n- Unresolved obligations at region close must:\n  - Emit a critical evidence entry (coordinated with bd-uvmm).\n  - Fail the frankenlab run if in a test/lab context (coordinated with bd-24bu).\n  - Trigger a fallback resolution (e.g., forced cleanup) in production, logged as a safety event.\n- Obligation state must be queryable via `Cx` for debugging and dashboard purposes (bd-36of).\n\n## Rationale\nTwo-phase operations are the primary source of resource leaks and inconsistent state in extension-host systems. Obligation tracking makes these operations explicit and auditable, turning silent leaks into loud, testable failures. Failing frankenlab runs on unresolved obligations ensures that no safety-critical path ships without complete lifecycle coverage.\n\n## Testing Requirements\n- Unit test: create an obligation, fulfill it, verify no error at region close.\n- Unit test: create an obligation, do NOT fulfill it, verify error at region close.\n- Integration test: full extension lifecycle with multiple two-phase operations; verify all obligations resolve.\n- Leak detection test: deliberately leak an obligation in a frankenlab scenario; verify the run fails.\n- Evidence test: verify unresolved obligations emit correctly-structured critical evidence entries.\n- Cancellation interaction test: cancel a region with pending obligations; verify obligations are force-resolved and evidence is emitted.\n\n## Implementation Notes\n- **10.11 primitive ownership**: Obligation creation, fulfillment, cancellation, and region-scoped tracking are 10.11 primitives. This bead integrates them into extension-host two-phase operations.\n- Use the adapter layer (bd-23om) for obligation-tracking imports.\n- The obligation inventory (list of all two-phase operations) should be maintained as a living document updated when new extension-host APIs are added.\n\n## Dependencies\n- Depends on bd-23om (adapter layer), bd-2ygl (Cx threading), bd-1ukb (region-scoped obligations), bd-2wz9 (cancellation interacts with obligations).\n- Depended upon by bd-1o7u (frankenlab scenarios test obligation tracking) and bd-24bu (obligation failures block releases).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:42.795493644Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.761605691Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-mhz4","title":"[14] Implement benchmark harness, scoring calculator, and neutral verifier mode.","description":"## Plan Reference\nSection 14.2-14.3: Claim Denominator and Reproducibility\nSection 10.6: Performance Program TODOs\n\n## What\nBuild the executable benchmark infrastructure: harness runner, weighted-geometric-mean scoring calculator, equivalence checker, neutral verifier mode, and artifact storage integration.\n\n## Components\n1. **Benchmark harness runner**: Orchestrates workload execution across FrankenEngine/Node/Bun with deterministic seeding, warm/cold cache control, and artifact capture\n2. **Weighted geometric mean calculator**: Implements the exact scoring formula from Section 14.2\n3. **Behavior-equivalence checker**: Validates output canonical digests, side-effect trace equivalence, and error-class semantics\n4. **Neutral verifier mode**: One-command mode for third parties to replay and validate scoring independently\n5. **Artifact storage**: Integration with frankensqlite for result ledgers and frankentui for operator dashboards\n6. **Publication gate**: Automated check that all prerequisites are met before allowing claim publication\n\n## Implementation Details\n- CLI: frankenctl benchmark run --suite extension-heavy --profile S/M/L\n- CLI: frankenctl benchmark score --baseline node --compare ./results/\n- CLI: frankenctl benchmark verify --manifest ./results/manifest.json\n- Run manifests include: hardware, kernel, runtime versions, flags, dataset checksums, seed transcripts, harness commit IDs\n- Store raw per-run data, not just aggregates\n- Native-coverage progression published alongside benchmark releases\n\n## Testing Requirements\n- Unit tests for scoring formula with known inputs/outputs\n- Unit tests for equivalence checker (matching and non-matching cases)\n- Integration tests for full harness lifecycle (setup, run, score, verify)\n- E2E test with mini workload producing complete artifact set\n- Regression test ensuring scoring formula changes require version bump\n\n## Rationale\nSection 14.3 requires at least two independent third-party reruns. The neutral verifier mode must be robust enough for external use. From Section 7.5: every published claim must include verifier scripts and deterministic repro commands.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.\n\n## Scope Boundary\\nThis bead integrates and productionizes benchmark tooling components (harness, scoring, neutral verifier) and should consume prerequisite benchmark-spec and denominator-calculation outputs rather than re-specifying them.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:42:12.677337908Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.100012387Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["benchmark","detailed","performance","plan","section-14","tooling"],"dependencies":[{"issue_id":"bd-mhz4","depends_on_id":"bd-19l0","type":"blocks","created_at":"2026-02-20T07:56:09.035740178Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-mhz4","depends_on_id":"bd-2n9","type":"blocks","created_at":"2026-02-20T07:56:09.101567088Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-mrf8","title":"[15] Signed extension registry with enforceable provenance, attestation, and revocation policies.","description":"Plan Reference: section 15 (Ecosystem Capture Strategy).\nObjective: Signed extension registry with enforceable provenance, attestation, and revocation policies.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:34:34.395892910Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.145671903Z","closed_at":"2026-02-20T07:45:56.851175521Z","close_reason":"Consolidated into single ecosystem capture bead with full plan context","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-15"]}
{"id":"bd-nhp","title":"[10.12] Implement epoch-bound specialization invalidation and deterministic fallback to baseline paths on proof/policy churn.","description":"## Plan Reference\n- **10.12 Item 4** (Epoch-bound specialization invalidation and fallback)\n- **9H.1**: Proof-Carrying Adaptive Optimizer -> canonical owner: 9F.1 (Verified Adaptive Compiler), execution: 10.12\n- **9H.14**: Security-Proof-Guided Specialization Flywheel -> canonical owner: 9I.8, execution: 10.12 + 10.15\n- **9I.8**: Specializations are invalidated deterministically on policy/proof epoch changes, with automatic fallback to unspecialized baseline paths\n\n## What\nImplement the epoch-bound invalidation subsystem that deterministically revokes active specializations and falls back to baseline execution paths whenever underlying proofs, policies, or security epochs change. This ensures that no stale optimization survives a trust-state transition.\n\n## Detailed Requirements\n\n### Epoch-Bound Validity Model\n1. Every active specialization carries an explicit `validity_epoch_range` derived from its source proofs and policy bindings.\n2. Validity is checked against the monotonic `security_epoch` model (10.11): specialization is valid only while `current_epoch` falls within `validity_epoch_range`.\n3. Epoch transitions are triggered by: policy rotation, key rotation, capability revocation, PLAS witness update, IFC flow-proof update, or explicit operator invalidation.\n\n### Deterministic Invalidation\n1. On epoch transition, the invalidation engine scans all active specializations and deterministically identifies those whose validity constraints are no longer satisfied.\n2. Invalidation is atomic per specialization: no partial invalidation states.\n3. Invalidation order is deterministic (sorted by `specialization_id`) to ensure replay consistency across nodes.\n4. Each invalidation emits a signed `invalidation_receipt` containing: `specialization_id`, `invalidation_reason`, `old_epoch`, `new_epoch`, `rollback_token_id`, `baseline_restoration_hash`, `timestamp`.\n5. Bulk invalidation during major epoch transitions (e.g., fleet-wide policy rotation) must complete within bounded time (SLO: invalidation latency <= 100ms for up to 1000 active specializations).\n\n### Deterministic Fallback to Baseline\n1. On invalidation, execution immediately transitions to the unspecialized baseline IR path using the stored `rollback_token`.\n2. Fallback is transparent to callers: no observable behavior change except potential performance regression.\n3. Fallback state is persistent: if node restarts during fallback, it resumes in baseline mode (no re-activation of invalidated specializations).\n4. Fallback mode emits continuous telemetry: `fallback_active`, `specialization_id`, `invalidation_reason`, `baseline_performance_metrics`.\n\n### Re-Specialization Path\n1. After fallback, the ingestion path (bd-1o2) may receive updated proofs from the new epoch.\n2. New proofs trigger fresh hypothesis generation and validation -- there is no shortcut re-activation of previously invalidated specializations.\n3. Re-specialization follows the full staging pipeline (shadow -> canary -> ramp -> default) even if the optimization class is identical to the prior specialization.\n\n### Policy Churn Protection\n1. Under rapid policy churn (e.g., incident response with multiple policy updates), the system must not thrash between specialization and fallback.\n2. Implement churn dampening: if more than N invalidations occur within a sliding window, the subsystem enters conservative mode where new specializations require extended canary burn-in.\n3. Churn dampening parameters are policy-configurable with explicit defaults.\n\n## Rationale\n> \"Specializations are invalidated deterministically on policy/proof epoch changes, with automatic fallback to unspecialized baseline paths.\" -- 9I.8\n> \"Every adaptive subsystem must include deterministic safe-mode fallback.\" -- Section 4 (Non-Negotiable Constraints)\n\nStale specializations are a security risk: an optimization derived from a now-revoked capability proof could execute code paths that should no longer be reachable. Deterministic invalidation is the safety net that makes proof-guided specialization trustworthy.\n\n## Testing Requirements\n1. **Unit tests**: Epoch validity checking for boundary conditions (exact-match, expired, future, overlapping ranges); invalidation ordering determinism; rollback token consumption; churn dampening state machine.\n2. **Property tests**: Fuzz epoch transition sequences to verify no specialization survives past its validity window; verify invalidation determinism across different execution orders.\n3. **Integration tests**: Full cycle: activate specialization -> trigger epoch transition -> verify invalidation -> verify baseline fallback -> inject new proofs -> verify re-specialization through full staging pipeline.\n4. **Stress tests**: Bulk invalidation of 1000+ specializations under epoch transition; verify SLO compliance. Rapid epoch churn to trigger and verify dampening behavior.\n5. **Replay tests**: Record invalidation sequence, replay on different node; verify identical invalidation ordering and fallback state.\n\n## Implementation Notes\n- Maintain an indexed registry of active specializations keyed by `(specialization_id, validity_epoch_range)` for efficient epoch-transition scanning.\n- Use 10.11 epoch transition barrier integration to receive epoch-change notifications.\n- Fallback state machine: `{active, invalidating, baseline_fallback, re_specializing}` with persistent state for crash recovery.\n- Churn dampening uses a sliding-window counter with configurable threshold and cooldown period.\n\n## Dependencies\n- bd-yqe: Proof schema (rollback_token, opt_receipt structures)\n- bd-2qj: Translation-validation gate (re-specialization must pass full validation)\n- bd-1o2: Security-proof ingestion (provides new proofs for re-specialization)\n- 10.11: Security epoch model, epoch transition barriers\n- 10.10: Audit chain for invalidation receipts","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:38.688630984Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.527174554Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-ntq","title":"[10.2] VM Core - Comprehensive Execution Epic","description":"## Plan Reference\nSection 10.2 (VM Core). This is the top-level epic for the entire VM Core execution track.\n\n## Purpose\nThe VM Core epic encompasses the fundamental execution engine of FrankenEngine - from source parsing through multi-level IR compilation to baseline interpretation and full ES2020 semantics. This is the architectural spine on which all other subsystems (memory/GC, module system, security, performance optimization) depend.\n\n## Scope and Ambition\nThe VM Core must deliver:\n1. **De novo execution**: No dependency on external JS engine bindings (V8, QuickJS) for core runtime behavior. Both execution lanes are native Rust implementations.\n2. **Full ES2020 semantics**: No permanent subset scope. Every ES2020 feature must be implemented correctly.\n3. **Proof-carrying compilation**: Every IR lowering stage emits machine-checkable witnesses for evidence graph linkage.\n4. **IFC-annotated IR**: Information Flow Control labels are first-class citizens in IR2, enabling deterministic exfiltration prevention.\n5. **Security-proof-guided specialization**: Security proofs serve as optimizer inputs, creating a flywheel where tighter verification yields faster code.\n6. **Verified self-replacement**: Typed execution slots enable incremental convergence from delegate cells to native cells.\n7. **Deterministic replay**: All execution produces witness artifacts (IR4) enabling byte-identical replay.\n8. **TS-first authoring**: TypeScript source is normalized to ES2020-equivalent IR with capability annotations preserved.\n\n## Child Beads (dependency order)\n### Foundation Layer\n- **bd-crp**: Parser trait + canonical AST for ES2020 script/module goals (IR0 foundation)\n- **bd-1wa**: Multi-level IR contract (IR0/IR1/IR2/IR3/IR4) with canonical serialization/hash invariants\n- **bd-20b**: Typed execution-slot registry and ABI contract for verified self-replacement\n\n### Compilation Pipeline\n- **bd-ug9**: Lowering pipelines (IR0→IR1→IR2→IR3) with per-pass verification and witness emission\n- **bd-1fm**: IFC flow-lattice semantics in IR2 (label classes, clearance classes, declassification obligations)\n- **bd-3jg**: Static flow-check pass proving source/sink legality with flow-proof witness artifacts\n- **bd-161**: Proof-to-specialization linkage in IR3/IR4 (security proofs as optimizer inputs)\n\n### Execution Layer\n- **bd-2f8**: Baseline interpreter skeleton for both lanes (QuickJS-inspired-native, V8-inspired-native)\n- **bd-1m9**: Complete ES2020 object/prototype semantics (Proxy, Reflect, property descriptors, no permanent subset)\n- **bd-1k7**: Closure and lexical scope model (lexical scoping, TDZ, scope chain, IFC label propagation)\n- **bd-o8v**: Deterministic Promise jobs/microtask ordering and async semantics\n- **bd-2tx**: Deterministic error/exception semantics with eval error contract\n\n### Front-End\n- **bd-309**: TS front-end normalization contract (TS → ES2020-equivalent IR with capability extraction)\n\n## Exit Gates\n- **Phase A**: Native execution lanes pass baseline conformance (test262 ES2020 subset). All child beads in Foundation and Execution layers must be complete.\n- **Phase B**: Security subsystems active (IFC flow-check, proof-to-specialization linkage). Compilation Pipeline beads must be complete.\n- **Phase C**: >= 3x performance vs Node/Bun. Requires optimization work in 10.6 but depends on correct baselines from this epic.\n\n## Cross-Section Dependencies\n- **Blocks**: 10.3 (Memory + GC), 10.4 (Module + Runtime Surface), 10.5 (Extension Host + Security), 10.6 (Performance Program), 10.7 (Conformance + Verification), 10.10 (FCP-Inspired Hardening), 10.15 (Delta Moonshots)\n- **Blocked by**: nothing (this is the foundational execution track)\n\n## Success Criteria\n1. All child beads complete with artifact-backed acceptance evidence\n2. Both execution lanes produce identical results for identical inputs (determinism invariant)\n3. test262 ES2020 parse/eval conformance meets Phase A exit gate threshold\n4. IR witness artifacts are emitted at every compilation and execution stage\n5. IFC flow labels propagate correctly through the full IR stack\n6. TS-first authoring produces behaviorally equivalent results to tsc+Node baseline\n7. Execution-slot registry supports runtime slot swapping with behavior preservation","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:32:18.302155218Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:56.750602284Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-2"],"dependencies":[{"issue_id":"bd-ntq","depends_on_id":"bd-161","type":"parent-child","created_at":"2026-02-20T07:52:42.944714339Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-1fm","type":"parent-child","created_at":"2026-02-20T07:52:44.042229023Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-1k7","type":"parent-child","created_at":"2026-02-20T07:52:44.714629212Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-1m9","type":"parent-child","created_at":"2026-02-20T07:52:44.980743074Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-1wa","type":"parent-child","created_at":"2026-02-20T07:52:45.988273023Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-20b","type":"parent-child","created_at":"2026-02-20T07:52:46.395673104Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-2f8","type":"parent-child","created_at":"2026-02-20T07:52:47.703189678Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-2tx","type":"parent-child","created_at":"2026-02-20T07:52:49.665728572Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-309","type":"parent-child","created_at":"2026-02-20T07:52:50.657421454Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-3jg","type":"parent-child","created_at":"2026-02-20T07:52:52.519160831Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-3vh","type":"blocks","created_at":"2026-02-20T07:32:55.347873177Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-crp","type":"parent-child","created_at":"2026-02-20T07:52:55.318112615Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-o8v","type":"parent-child","created_at":"2026-02-20T07:52:56.343733262Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ntq","depends_on_id":"bd-ug9","type":"parent-child","created_at":"2026-02-20T07:52:56.750530450Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-o8v","title":"[10.2] Implement deterministic Promise jobs/microtask ordering and async semantics.","description":"## Plan Reference\nSection 10.2, item 12. Cross-refs: 9A.3 (deterministic evidence graph), 9F.3 (deterministic replay), 9F.4 (Capability-Typed TS Execution), Phase A exit gate.\n\n## What\nImplement deterministic Promise job queue, microtask ordering, and async/await semantics. The key design constraint is full determinism: given the same inputs, Promise resolution order must be identical across runs, across execution lanes, and across replays.\n\n## Detailed Requirements\n- Promise state machine: pending, fulfilled, rejected with correct state transitions\n- Promise.resolve, Promise.reject, Promise.all, Promise.allSettled, Promise.any, Promise.race with correct semantics\n- Microtask queue: enqueue PromiseReactionJob and PromiseResolveThenableJob per ES2020 spec\n- Job ordering: microtask queue drains completely before returning to macrotask queue (event loop integration)\n- async/await: async functions return Promises; await suspends execution and enqueues continuation as microtask\n- for-await-of: async iteration protocol\n- Deterministic ordering: the microtask queue must produce identical ordering given identical inputs, regardless of system timing, thread scheduling, or execution lane choice\n- Replay compatibility: Promise resolution order must be captured in IR4 witness artifacts for deterministic replay (per 9F.3)\n- Error propagation: unhandled rejections must follow deterministic reporting order\n\n## Rationale\nNon-deterministic scheduling is the single most common cause of replay divergence in JavaScript runtimes. If two Promises resolve in different order across runs, replay fails, evidence graphs become inconsistent, and IFC flow analysis may miss data paths. The plan (9A.3, 9F.3) requires deterministic replay as a first-class property. This means the Promise/microtask system cannot rely on OS scheduling, timer jitter, or any external non-deterministic input. Every scheduling decision must be a deterministic function of program state. This is a hard architectural constraint that must be designed in from the start, not patched later.\n\n## Testing Requirements\n- Unit tests: Promise state transitions (pending → fulfilled, pending → rejected, settled is immutable)\n- Unit tests: Promise.all/race/any/allSettled with various resolution patterns\n- Unit tests: microtask ordering - verify exact microtask execution sequence for known patterns\n- Unit tests: async/await - verify suspension and resumption produces correct values\n- Unit tests: nested Promise chains - verify resolution order matches ES2020 spec\n- Unit tests: determinism - run same async code 100 times, verify identical microtask ordering\n- Unit tests: replay - capture witness, replay from witness, verify identical behavior\n- Conformance: test262 built-ins/Promise, language/expressions/await, language/statements/for-await-of\n- Stress tests: deeply nested Promise chains, Promise.all with 1000+ elements, rapid resolve/reject cycling\n\n## Implementation Notes\n- Microtask queue should be a simple FIFO with no priority or preemption\n- async/await desugaring should happen at IR1→IR2 lowering, not in the interpreter\n- Witness emission: record each microtask enqueue/dequeue event in IR4 for replay\n- No reliance on tokio/async-std scheduling - the microtask queue is purely synchronous within a single execution turn\n- Both execution lanes (QuickJS-inspired and V8-inspired) must produce identical microtask ordering for identical programs\n\n## Dependencies\n- Blocked by: baseline interpreter skeleton (bd-2f8), ES2020 object semantics (bd-1m9) for Promise objects, closure/scope model (bd-1k7) for async function scoping\n- Blocks: Phase A exit gate conformance, deterministic replay system (10.5), event loop integration (10.4)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:22.839997827Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.242757413Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-pace","title":"[13] all SQLite-backed control-plane persistence in FrankenEngine is delivered through `/dp/frankensqlite` integration, with `/dp/sqlmodel_rust` used where typed model layers materially improve safety","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: all SQLite-backed control-plane persistence in FrankenEngine is delivered through `/dp/frankensqlite` integration, with `/dp/sqlmodel_rust` used where typed model layers materially improve safety\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:22.173603817Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.305371118Z","closed_at":"2026-02-20T07:39:59.484477117Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-qozg","title":"[13] security and performance claims are artifact-backed and reproducible","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: security and performance claims are artifact-backed and reproducible\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:19.631811548Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.345127298Z","closed_at":"2026-02-20T07:40:00.719193158Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-qse","title":"[10.11] Add obligation leak response policy split (`lab=fatal`, `prod=diagnostic + scoped failover`).","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add obligation leak response policy split (`lab=fatal`, `prod=diagnostic + scoped failover`).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:34.207033523Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.688334165Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-rr94","title":"[10.14] Add cross-repo contract tests validating schema/API compatibility for integration boundaries (`frankentui`, `frankensqlite`, `sqlmodel_rust`, `fastapi_rust`).","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Add cross-repo contract tests validating schema/API compatibility for integration boundaries (`frankentui`, `frankensqlite`, `sqlmodel_rust`, `fastapi_rust`).\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:46.516678118Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.262596661Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-skw6","title":"[13] untrusted extension code is actively monitored and auto-contained under attack scenarios","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: untrusted extension code is actively monitored and auto-contained under attack scenarios\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:19.423294387Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.463391746Z","closed_at":"2026-02-20T07:40:00.817580432Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-t2m","title":"[10.5] Implement forensic replay tooling for incident traces.","description":"## Plan Reference\nSection 10.5, item 7 (Implement forensic replay tooling for incident traces). Cross-refs: 9A.3 (deterministic replay infrastructure), 9F.3 (deterministic time-travel + counterfactual replay), 9C.2 (decision loop must be explainable and replayable).\n\n## What\nImplement tooling that can replay a recorded incident trace -- comprising hostcall telemetry logs, posterior update history, decision events, and containment actions -- and reproduce the exact sequence of security decisions that were made during the original incident. The replay tool also supports counterfactual analysis: given an incident trace, the operator can modify parameters (e.g., change the loss matrix, adjust the prior, inject additional evidence) and observe how the decision trajectory would have changed. This is the forensic and continuous-improvement backbone of the security system.\n\n## Detailed Requirements\n- Define `IncidentTrace` struct containing: `trace_id: TraceId`, `extension_id: ExtensionId`, `telemetry_log: Vec<HostcallTelemetryRecord>`, `posterior_history: Vec<(u64, Posterior)>`, `decision_log: Vec<ActionDecision>`, `containment_log: Vec<ContainmentReceipt>`, `metadata: IncidentMetadata`.\n- Implement `ForensicReplayer` with methods:\n  - `replay(trace: &IncidentTrace, config: ReplayConfig) -> ReplayResult` - replay the trace deterministically, producing an identical decision trajectory.\n  - `counterfactual(trace: &IncidentTrace, modifications: CounterfactualSpec) -> ReplayResult` - replay with modified parameters and report divergence points.\n  - `diff(original: &ReplayResult, counterfactual: &ReplayResult) -> ReplayDiff` - structured diff showing where and why decisions diverged.\n- `CounterfactualSpec` allows modifying: prior, loss matrix, evidence injection/removal, posterior updater configuration.\n- `ReplayResult` contains the full decision trajectory: `Vec<(step_index, Evidence, Posterior, ActionDecision)>`.\n- `ReplayDiff` identifies: first divergence point, list of decision changes, final outcome difference.\n- Deterministic replay guarantee: `replay(trace, default_config)` MUST produce bit-identical `ReplayResult` to the original decision trajectory. Any divergence is a bug.\n- The replayer must be usable both as a library API and as a CLI tool (`franken-forensic-replay`) for operator use.\n- Support streaming replay for large traces that do not fit in memory.\n- Include a trace validation step that checks internal consistency (monotonic timestamps, posterior sums to 1.0, decisions match posteriors).\n\n## Rationale\nPer 9F.3, the engine must support deterministic time-travel and counterfactual replay. This is essential for: (a) post-incident analysis (\"why did the engine quarantine this extension?\"), (b) decision system tuning (\"would a different loss matrix have caught this earlier?\"), (c) regression testing (\"does a model update change decisions on historical incidents?\"), and (d) auditor/regulator requirements (\"prove that this security action was the correct response to the evidence\"). The counterfactual capability is what separates forensic replay from simple log viewing: it enables causal reasoning about security decisions.\n\n## Testing Requirements\n- **Determinism tests**: Record a live incident trace, replay it, and verify bit-identical decision trajectory. Repeat 100 times; all must match.\n- **Counterfactual tests**: Replay with a more aggressive loss matrix; verify earlier containment. Replay with injected additional malicious evidence; verify faster detection. Replay with removed evidence; verify delayed or missed detection.\n- **Diff tests**: Verify `ReplayDiff` correctly identifies divergence points and classifies decision changes.\n- **Consistency validation tests**: Inject corrupted traces (out-of-order timestamps, posteriors that do not sum to 1.0, decisions that do not match posteriors) and verify the validator catches them.\n- **Streaming tests**: Replay a trace larger than available memory in streaming mode; verify correct results.\n- **CLI tests**: End-to-end test of the `franken-forensic-replay` CLI tool with a recorded trace file.\n\n## Implementation Notes\n- The replayer instantiates a fresh `BayesianPosteriorUpdater` and `ExpectedLossSelector` with the trace's original configuration, then feeds evidence records one at a time, comparing each step's output to the recorded trajectory.\n- For counterfactual replay, the replayer uses the modified configuration but the same evidence sequence (unless evidence injection/removal is specified).\n- Trace serialization format should be CBOR or a custom binary format for compactness and determinism; avoid JSON for large traces.\n- The CLI tool should support output formats: human-readable summary, JSON detail, and a structured diff format.\n- Consider integration with the telemetry recorder's (bd-5pk) checkpoint mechanism for trace extraction.\n\n## Dependencies\n- **Blocked by**: bd-5pk (telemetry records are the trace input), bd-3md (posterior updater must be replayable), bd-1y5 (action selector must be replayable), bd-2gl (containment receipts are part of the trace).\n- **Blocks**: Calibration and continuous improvement of the Bayesian models. Phase B exit gate evidence (proving detection-to-containment latency compliance on historical incidents).\n- **Parent**: bd-1yq (10.5 epic).\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:24.687661517Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.614275453Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-5"]}
{"id":"bd-tgv","title":"[10.4] Implement module resolver trait with policy hooks.","description":"## Plan Reference\nSection 10.4, item 1. Cross-refs: 9A.1 (TS-first authoring), 9A.7 (capability lattice), Phase D (Node/Bun surface superset).\n\n## What\nImplement the module resolver trait with policy hooks. The resolver determines how import/require statements are resolved to actual code, with security policy enforcement at resolution time.\n\n## Detailed Requirements\n- Module resolver trait: generic interface for resolving module specifiers to loadable code\n- Policy hooks: capability checks at resolution time (can this extension import this module?)\n- Support both ES module (import) and CommonJS (require) resolution semantics\n- Resolution must be deterministic: same specifier + same policy → same resolution\n- Built-in module resolution for FrankenEngine standard library\n- External module resolution with provenance tracking (where did this code come from?)\n- Resolution errors must be structured and deterministic (not platform-dependent)\n- Policy hook integration: capability lattice checks before allowing resolution (per 9A.7)\n\n## Rationale\nModule resolution is a security boundary: it determines what code an extension can access. The plan requires capability-typed execution (9A.1) which means module access must be governed by the capability lattice. Without policy hooks at resolution time, extensions could bypass capability restrictions by importing unrestricted modules. Phase D requires Node/Bun module compatibility, so the resolver must support both ESM and CJS.\n\n## Testing Requirements\n- Unit tests: resolve built-in module specifiers correctly\n- Unit tests: resolve relative and absolute path specifiers\n- Unit tests: policy hook denies resolution when capability is missing\n- Unit tests: deterministic resolution (same inputs → same output)\n- Integration tests: resolve chains (A imports B imports C), verify transitive policy checks\n- Compatibility tests: Node-style resolution for CJS modules, ESM resolution for ES modules\n\n## Implementation Notes\n- Define trait in crates/franken-engine with default implementations for common cases\n- Policy hooks should accept Capability context from the extension manifest\n- Consider caching resolved modules (but cache invalidation is bd-16x)\n- Resolution provenance should feed into evidence graph for forensic audit\n\n## Dependencies\n- Blocked by: parser trait (10.2 bd-crp) for module parsing, capability lattice design (10.5)\n- Blocks: module cache invalidation (bd-16x), compatibility mode matrix (bd-3vp), Phase D work\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:23.504206677Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:37.995010101Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-4"]}
{"id":"bd-ttd","title":"[10.0] Top-10 #7: Capability lattice + typed policy DSL (strategy: `9A.7`; deep semantics: `9F.8`; execution owners: `10.5`, `10.10`, `10.12`, `10.13`).","description":"## Plan Reference\nSection 10.0 item 7. Strategy: 9A.7. Deep semantics: 9F.8 (Policy Compiler With Formal Merge Guarantees). Enhancement maps: 9B.7 (OCA discipline, macaroons, signed policy-as-data), 9C.7 (formal semantics, merge operators with proofs), 9D.7 (policy compile/load/eval profiling).\n\n## What\nStrategic tracking bead for Initiative #7: Capability lattice + typed policy DSL for machine-checkable policy. Permissions modeled as composable lattice with typed rules.\n\n## Execution Owners\n- **10.5** (Extension Host): runtime capability enforcement, flow-label propagation\n- **10.10** (FCP-Inspired Hardening): capability token format, delegated attenuation chains\n- **10.12** (Frontier Programs): policy theorem compiler, counterexample synthesizer\n- **10.13** (Asupersync Integration): dependency policy, ambient-authority audit\n\n## Strategic Rationale (from 9A.7)\n'Fine-grained security at scale fails without strongly structured policy semantics and tool-verified correctness.'\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:20.022177843Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:39.072400792Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-0"]}
{"id":"bd-twz2","title":"[13] secure extension reputation graph drives measurable reduction in first-time compromise windows","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: secure extension reputation graph drives measurable reduction in first-time compromise windows\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:23.441037994Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.622194541Z","closed_at":"2026-02-20T07:39:58.886875205Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
{"id":"bd-ug9","title":"[10.2] Implement lowering pipelines with per-pass verification and witness emission.","description":"## Plan Reference\nSection 10.2, item 3. Cross-refs: 9B.1 (incremental/self-adjusting compilation), 9C.1 (proof-carrying compilation with isomorphism ledger), 9D.1 (compilation benchmark suite).\n\n## What\nImplement the lowering pipelines that transform code through the IR stack: IR0→IR1→IR2→IR3. Each pass must emit verification witnesses proving the transformation preserves semantics.\n\n## Detailed Requirements\n- IR0→IR1 lowering: resolve scopes, bindings, and spec-level semantics\n- IR1→IR2 lowering: annotate capability intent, effect boundaries, and IFC flow labels\n- IR2→IR3 lowering: produce execution-ready form with proof linkage metadata\n- Each pass must emit a witness artifact proving semantic preservation (per 9C.1 proof-carrying compilation contract)\n- Isomorphism ledger: record ordering/tie-break semantics and verify behavioral equivalence on golden corpora (per 9C.1)\n- Passes must be independently testable and composable\n- Support per-pass verification: each lowering step can be validated in isolation\n- Consider incremental/self-adjusting compilation (per 9B.1) for low-latency rebuilds under rapid extension edits\n\n## Rationale\nThe plan requires proof-carrying compilation (9C.1): 'each lowering stage emits invariants and a machine-checkable witness that capability annotations are preserved end-to-end.' This means lowering is not just a transformation but a verified transformation pipeline. The witness artifacts feed into the deterministic evidence graph (9A.3) and are required for replay/audit.\n\n## Testing Requirements\n- Unit tests: lower valid IR0 through each stage, verify output IR type and content\n- Unit tests: verify witness artifacts are emitted for each pass\n- Unit tests: verify lowering rejects invalid IR (missing required annotations)\n- Golden corpus tests: lower known inputs, compare output IR hashes against golden values\n- Isomorphism tests: verify lowered IR produces identical behavior to source\n- Performance: benchmark each lowering pass separately (per 9D.1)\n\n## Implementation Notes\n- Each pass should be a separate function/module for testability\n- Witness format should be defined in the IR contract (bd-1wa)\n- Consider arena allocation for intermediate IR nodes\n- Passes should be pure functions (no side effects) for determinism\n\n## Dependencies\n- Blocked by: parser trait (bd-crp), IR contract (bd-1wa)\n- Blocks: interpreter skeleton (bd-2f8), IFC flow-check (bd-3jg), proof-to-specialization (bd-161)\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:21.672487055Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:38.623442449Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-2"]}
{"id":"bd-ulle","title":"[11] Define deterministic rollback command and known-good recovery path","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: rollback command\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:17.140889042Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.700719822Z","closed_at":"2026-02-20T07:38:22.899595123Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"],"dependencies":[{"issue_id":"bd-ulle","depends_on_id":"bd-3tjn","type":"blocks","created_at":"2026-02-20T07:38:26.506754839Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-uvmm","title":"[10.13] Emit canonical evidence entries via `franken-evidence` for all high-impact actions, linked to `trace_id`, `decision_id`, `policy_id`, and artifact hashes.","description":"Plan Reference: section 10.13 (Asupersync Constitutional Integration Track).\nObjective: Emit canonical evidence entries via `franken-evidence` for all high-impact actions, linked to `trace_id`, `decision_id`, `policy_id`, and artifact hashes.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:43.116221318Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:34.666483424Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-uwc","title":"[10.9] Release gate: autonomous quarantine mesh is implemented and validated under fault injection (implementation ownership: `10.12`).","description":"## Plan Reference\nSection 10.9, item 3 -- Moonshot Disruption Track (release gates for frontier programs).\n\n## What\nThis is a **release gate**, not an implementation task. It verifies that the autonomous quarantine mesh -- built by the Frontier Programs track (10.12) as part of the Fleet Immune System and Revocation Mesh moonshots -- has been implemented and validated under realistic fault-injection scenarios. The gate confirms that the mesh can autonomously detect, isolate, and contain compromised or misbehaving components without operator intervention, and that this capability degrades gracefully under adverse conditions.\n\nThe gate owner does not build the quarantine mesh; the gate owner subjects the delivered mesh to fault-injection validation and confirms it meets the resilience bar.\n\n## Gate Criteria\n1. The quarantine mesh autonomously detects and isolates a compromised component within a defined SLA (e.g., < 500ms from anomaly signal to quarantine enforcement).\n2. Fault injection scenarios cover: network partition, Byzantine component behavior, cascading failure propagation, resource exhaustion, and clock skew.\n3. Under each fault scenario, the mesh maintains isolation invariants -- no quarantined component can issue capability-bearing requests to non-quarantined peers.\n4. Mesh recovery after fault clearance is automatic and verifiable: quarantined components re-enter the active set only after re-attestation.\n5. All quarantine decisions are logged with cryptographic receipts enabling post-incident replay.\n6. The mesh operates correctly in degraded mode (e.g., when the mesh coordinator itself is partitioned) with documented fallback semantics.\n\n## Implementation Ownership\n- **10.12 (Frontier Programs):** Builds the quarantine mesh runtime, detection heuristics, isolation enforcement, and recovery protocols. Encompasses 9F moonshots: Fleet Immune System, Revocation Mesh, Live Safety Twin.\n- **10.9 (this gate):** Designs and executes fault-injection validation campaigns, evaluates results against gate criteria, and produces the pass/fail evidence bundle.\n\n## Rationale\nAn autonomous quarantine mesh is a cornerstone of FrankenEngine's security-beyond-parity claim. If the mesh fails under real-world fault conditions (partitions, Byzantine behavior), the entire fleet immune system becomes unreliable. This gate ensures that the mesh is not merely implemented but is proven resilient under adversarial operating conditions, directly feeding the `security_delta` dimension of the disruption scorecard (bd-6pk).\n\nRelated 9F moonshots: Fleet Immune System, Revocation Mesh, Live Safety Twin.\nRelated 9I moonshots: Moonshot Portfolio Governor.\n\n## Verification Requirements\n- **Fault-injection campaign:** A structured campaign of at least the five fault categories listed in Gate Criteria, each with deterministic seed-based reproduction.\n- **Isolation invariant proof:** For each fault scenario, demonstrate via structured logs and receipts that no quarantined component successfully communicated with non-quarantined peers.\n- **Recovery validation:** After fault clearance, confirm re-attestation flow completes and the component rejoins with a fresh capability set.\n- **Degraded-mode testing:** Validate mesh behavior when the coordinator itself is faulted; confirm documented fallback semantics hold.\n- **Scorecard integration:** Results feed `security_delta` in the disruption scorecard (bd-6pk).\n- **Structured logging:** Fault-injection runs emit structured logs with fields: `trace_id`, `fault_type`, `target_component`, `quarantine_action`, `latency_ns`, `isolation_verified`, `receipt_hash`.\n\n## Dependencies\n- bd-6pk (disruption scorecard) -- gate results feed `security_delta` dimension.\n- bd-3rd (adversarial campaign runner) -- shares fault-injection infrastructure and methodology.\n- 10.12 Frontier Programs track -- delivers the quarantine mesh implementation.\n- bd-1xm (parent epic) -- this bead is a child of the Moonshot Disruption Track epic.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:28.000188653Z","created_by":"ubuntu","updated_at":"2026-02-20T07:57:23.156307685Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-9"]}
{"id":"bd-von8","title":"[11] Require explicit expected-loss model with asymmetric risk costs","description":"Plan Reference: section 11 (Evidence And Decision Contracts (Mandatory)).\nObjective: expected-loss model\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:16.487226497Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.817908817Z","closed_at":"2026-02-20T07:38:23.204039826Z","close_reason":"Consolidated into single evidence-contract template bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-11"],"dependencies":[{"issue_id":"bd-von8","depends_on_id":"bd-3qm1","type":"blocks","created_at":"2026-02-20T07:38:26.156742107Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xga","title":"[10.11] Define monotonic `security_epoch` model and validity-window checks across signed trust artifacts.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Define monotonic `security_epoch` model and validity-window checks across signed trust artifacts.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:35.669967173Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:36.226493897Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-xq7","title":"Port extension manifest validation scaffold into franken-extension-host","description":"## Plan Reference\nSection 10.5, item 1 (Port extension manifest validation into compile-active modules). Cross-refs: 9A.1 (capability-typed execution model), 9A.7 (capability lattice + typed policy DSL), 9A.5 (supply-chain trust fabric).\n\n## What\nPromote the existing runtime manifest validation logic in `crates/franken-extension-host/src/lib.rs` into a compile-active module so that manifest correctness is enforced at build time wherever possible. The existing `ExtensionManifest`, `Capability` enum, `ManifestValidationError`, and `validate_manifest()` function form the foundation. This bead extends them with: (a) compile-time const-evaluable validation paths for statically-known manifests, (b) capability-lattice awareness so that declared capabilities are checked against the 9A.7 lattice ordering (e.g., `FsWrite` implies `FsRead`), (c) supply-chain provenance fields required by 9A.5 (publisher signature, content hash, trust-chain reference), and (d) deterministic serialization so manifest bytes are reproducible for signature verification.\n\n## Detailed Requirements\n- Extend `ExtensionManifest` with fields: `publisher_signature: Option<Vec<u8>>`, `content_hash: [u8; 32]`, `trust_chain_ref: Option<String>`, `min_engine_version: String`.\n- Extend `ManifestValidationError` with variants: `InvalidCapabilityLattice { declared: Capability, missing_implied: Capability }`, `InvalidContentHash`, `MissingPublisherSignature`, `UnsupportedEngineVersion`.\n- Implement `validate_capability_lattice()` that checks declared capabilities against the partial order defined in the capability lattice (9A.7). If an extension declares `FsWrite` but not `FsRead`, validation must fail.\n- Implement `validate_provenance()` that checks publisher signature and content hash fields when the trust level requires them.\n- Provide a `const fn`-compatible validation path for manifests known at compile time (using `const`-friendly subset of checks).\n- All validation errors must produce deterministic, structured error messages suitable for logging with `trace_id` and `extension_id` context.\n- Manifest serialization must be canonical (sorted keys, no optional whitespace) to ensure content-hash stability.\n\n## Rationale\nThe plan mandates that extension security is impossible-by-default: no extension runs without a validated manifest. Moving validation to compile-active modules means that statically-linked extensions are verified at build time, eliminating an entire class of runtime failures. The capability lattice check ensures extensions cannot under-declare their authority footprint. Provenance fields connect to the supply-chain trust fabric (9A.5) so that the runtime can verify publisher identity before loading any extension code.\n\n## Testing Requirements\n- **Unit tests**: Validate manifests with every valid capability combination. Test lattice violations (e.g., `FsWrite` without `FsRead`). Test all error variants produce correct deterministic messages. Test canonical serialization round-trips.\n- **Compile-time tests**: Verify that `const`-path validation catches errors at compile time for static manifests.\n- **Integration tests**: Load a manifest from TOML/JSON, validate, and check that provenance fields are correctly verified against a test trust chain.\n- **Adversarial tests**: Malformed manifests (missing fields, extra fields, duplicate capabilities, empty strings, extremely long strings, invalid UTF-8 in name).\n\n## Implementation Notes\n- Existing code in `crates/franken-extension-host/src/lib.rs` already has `Capability` (5 variants), `ExtensionManifest`, `ManifestValidationError` (5 variants), `validate_manifest()`, and comprehensive tests for the current validation surface.\n- The `BTreeSet`-based duplicate detection is already in place; extend it with lattice-implication checks.\n- Use `serde` with `#[serde(rename_all = \"snake_case\")]` (already present) and add canonical serialization via a deterministic JSON serializer or CBOR.\n- `#![forbid(unsafe_code)]` is already set; maintain this invariant.\n\n## Dependencies\n- **Blocked by**: None (foundational bead for 10.5).\n- **Blocks**: bd-1hu (lifecycle manager needs validated manifests), bd-5pk (telemetry references manifest identity), bd-375 (delegate cells need manifest validation path), all downstream 10.5 beads that assume manifest integrity.\n- **Parent**: bd-1yq (10.5 epic).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"in_progress","priority":1,"issue_type":"task","assignee":"AzureMountain","created_at":"2026-02-20T07:24:27.192973464Z","created_by":"AzureMountain","updated_at":"2026-02-20T08:00:39.503662955Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["extension-host","plan","section-10-5","security","validation"]}
{"id":"bd-ye6k","title":"[14] Update standards with explicit versioning and migration notes.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Update standards with explicit versioning and migration notes.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:28.509746083Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:41.935795683Z","closed_at":"2026-02-20T07:41:21.621584293Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-yi6","title":"[10.11] Add phase gates for this track: deterministic replay pass, interleaving suite pass, conformance vectors pass, and fuzz/adversarial pass.","description":"Plan Reference: section 10.11 (FrankenSQLite-Inspired Runtime Systems Track).\nObjective: Add phase gates for this track: deterministic replay pass, interleaving suite pass, conformance vectors pass, and fuzz/adversarial pass.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:38.071605272Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.141714854Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-11"]}
{"id":"bd-ypl4","title":"[10.13] Add naming guidance to the ADR: Cargo package names (`franken-kernel`, `franken-decision`, `franken-evidence`) and Rust crate paths (`franken_kernel`, `franken_decision`, `franken_evidence`) are both normative references.","description":"# Add Naming Guidance to the ADR\n\n## Plan Reference\nSection 10.13, Item 2.\n\n## What\nExtend the control-plane adoption ADR (bd-3vlb) with normative naming guidance that maps Cargo package names to Rust crate paths, ensuring all FrankenEngine code and documentation uses consistent, unambiguous identifiers when referencing asupersync control-plane crates.\n\n## Detailed Requirements\n- **Integration/binding nature**: This bead does not define new crates or rename existing ones. It documents the binding between Cargo's hyphenated package names and Rust's underscored crate paths as used in `use` statements and `extern crate` declarations.\n- Normative mappings to document:\n  - `franken-kernel` (Cargo package) <-> `franken_kernel` (Rust crate path)\n  - `franken-decision` (Cargo package) <-> `franken_decision` (Rust crate path)\n  - `franken-evidence` (Cargo package) <-> `franken_evidence` (Rust crate path)\n- The guidance must specify which name form is used in which context: `Cargo.toml` dependencies use hyphenated names; Rust source uses underscored paths.\n- Include examples of correct `Cargo.toml` entries and correct `use` statements.\n- Add a \"common mistakes\" section listing known anti-patterns (e.g., `use franken-kernel` which is a Rust syntax error, or declaring `franken_kernel` as a Cargo dependency which silently creates a different package reference).\n\n## Rationale\nCargo's automatic name normalization (hyphens to underscores) is a well-known source of confusion. Explicitly documenting both forms prevents CI failures, grep misses, and dependency resolution surprises, especially for contributors unfamiliar with the Rust ecosystem's naming conventions.\n\n## Testing Requirements\n- CI lint verifies all `Cargo.toml` files use the hyphenated form for these three packages.\n- CI lint verifies all `.rs` files use the underscored form in `use`/`extern crate` statements.\n- ADR section passes markdown lint.\n\n## Implementation Notes\n- **10.11 primitive ownership**: The crate names themselves are defined by the asupersync project (10.11 domain). This bead only documents how FrankenEngine refers to them.\n- This bead is a companion to the ADR (bd-3vlb) and the dependency policy (bd-2fa1).\n\n## Dependencies\n- Depends on bd-3vlb (the ADR must exist before naming guidance is appended to it).","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:32:41.801377101Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:35.049421826Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-13"]}
{"id":"bd-yqe","title":"[10.12] Define proof schema and signer model for optimizer activation witnesses (`opt_receipt`, `rollback_token`, `invariance_digest`).","description":"## Plan Reference\n- **10.12 Item 1** (Verified Adaptive Compiler proof-schema definition)\n- **9H.1**: Proof-Carrying Adaptive Optimizer -> canonical owner: 9F.1 (Verified Adaptive Compiler), execution: 10.12\n- **9F.1**: Verified Adaptive Compiler -- proof-carrying activation with translation witnesses and rollback tokens\n\n## What\nDefine the canonical proof schema and cryptographic signer model for optimizer activation witnesses. This creates the foundational data structures (`opt_receipt`, `rollback_token`, `invariance_digest`) that every adaptive optimization path must produce before activation is permitted.\n\n## Detailed Requirements\n\n### Proof Schema\n1. **`opt_receipt`**: Structured receipt containing `optimization_id`, `optimization_class` (superinstruction / trace-specialization / layout-specialization / devirtualized-hostcall-fast-path), `baseline_ir_hash`, `candidate_ir_hash`, `translation_witness_hash`, `invariance_digest`, `rollback_token_id`, `replay_compatibility_metadata`, `policy_epoch`, `timestamp`, and `signer_key_id`.\n2. **`rollback_token`**: Immutable artifact linking `token_id`, `optimization_id`, `baseline_snapshot_hash`, `activation_stage` (shadow / canary / ramp / default), `expiry_epoch`, and `issuer_signature`. Must be independently verifiable and sufficient to deterministically restore baseline execution without re-running validation.\n3. **`invariance_digest`**: Cryptographic commitment over the semantic equivalence claim between baseline IR traces and optimized candidate traces, including `golden_corpus_hash`, `trace_comparison_methodology`, `equivalence_verdict`, and `witness_chain_root`.\n4. **Canonical encoding**: All schema objects use deterministic serialization with schema-hash prefix validation (per 10.10 `EngineObjectId` derivation contract). No silent normalization of non-canonical encodings.\n5. **Schema versioning**: Include `schema_version` field with explicit migration contract; old-version receipts remain verifiable by newer verifiers.\n\n### Signer Model\n1. Define which runtime principals are authorized to sign each artifact type (optimizer subsystem for receipts, policy plane for epoch bindings, attestation cells for TEE-bound variants).\n2. Key roles follow 10.10 split principal model: separate signing/encryption/issuance keys with independent revocation.\n3. Signature preimage contract uses unsigned-view encoding and deterministic field ordering (per 10.10).\n4. Support optional threshold-signing for high-impact promotions (shadow->canary and canary->ramp transitions).\n5. Key attestation objects with expiry and nonce freshness requirements bound to `security_epoch` (per 10.11).\n\n### Evidence Integration\n1. All emitted receipts append to the append-only hash-linked audit chain (10.10) with `correlation_id` and trace context.\n2. Receipts are consumable by the replay engine (10.12 item 7) for counterfactual analysis.\n3. Schema must be extensible for TEE attestation bindings (9I.1 / 10.15) without breaking backward compatibility.\n\n## Rationale\n> \"Traditional adaptive optimizers fail socially because operators cannot prove why they are safe. Proof-carrying activation solves that trust gap and creates a defensible technical moat: fast paths with verification-grade confidence instead of heuristic optimism.\" -- 9F.1\n\nWithout a rigorous proof schema, the entire Verified Adaptive Compiler pipeline cannot provide the trust guarantees that differentiate FrankenEngine from incumbent runtimes. This schema is the trust anchor for items 2-4 in this group.\n\n## Testing Requirements\n1. **Unit tests**: Schema serialization/deserialization round-trip with golden vectors; rejection of non-canonical encodings; signature verification with valid/invalid/expired/revoked keys; schema version migration correctness.\n2. **Property tests**: Fuzz serialization paths for decode DoS resistance; ensure `invariance_digest` commitment is binding (no second-preimage for different equivalence claims).\n3. **Integration tests**: End-to-end flow from optimizer candidate emission through receipt signing, audit-chain append, and replay-engine consumption with deterministic fixtures.\n4. **Adversarial tests**: Attempt receipt forgery, signature splice, rollback-token reuse after expiry, and epoch-mismatch acceptance -- all must be rejected.\n\n## Implementation Notes\n- Rust structs with `#[derive(Serialize, Deserialize)]` using deterministic encoding (consider canonical CBOR or similar).\n- Signer trait abstraction to support both software keys and future TEE-bound signers.\n- Place in a dedicated `franken_engine::proof_schema` or equivalent crate module so downstream consumers (translation-validation gate, replay engine, verifier CLI) can depend on it without pulling optimizer internals.\n- Align field naming with 10.10 `EngineObjectId` conventions and 10.11 `security_epoch` model.\n\n## Dependencies\n- 10.10: `EngineObjectId` derivation, deterministic serialization, signature preimage contract, split principal key roles\n- 10.11: `security_epoch` model, epoch-scoped key derivation\n- Downstream consumers: bd-2qj (translation-validation gate), bd-1o2 (security-proof ingestion), bd-nhp (epoch-bound invalidation), bd-1nh (replay engine)","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:38.223290222Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:43.648574106Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-12"]}
{"id":"bd-yqg5","title":"[10.14] Add release checklist item requiring explicit “reuse vs reimplement” justification for any new console, SQLite, or service layer work.","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nObjective: Add release checklist item requiring explicit “reuse vs reimplement” justification for any new console, SQLite, or service layer work.\nRationale:\n- This work item is required to preserve the full architectural and security/performance intent of the FrankenEngine charter.\n- Implementation must preserve deterministic behavior, replayability, and explicit evidence surfaces where the feature touches runtime decisions.\nImplementation expectations:\n1. Produce concrete code/docs/artifacts for the objective with no hidden compatibility shims.\n2. Document constraints, assumptions, and non-goals in commit/PR notes.\n3. Keep interfaces explicit and testable; avoid ambient authority patterns.\nVerification requirements (mandatory):\n- Unit tests: nominal path, edge conditions, and failure-path invariants for this item.\n- E2E/integration tests: realistic scenario coverage with deterministic setup/teardown.\n- Logging/observability: emit structured logs with stable fields; include trace/policy/decision identifiers when applicable.\n- Reproducibility: outputs must support env/manifest/repro-lock artifact capture.\nDone definition:\n- Implementation merged with tests passing.\n- Failure modes and rollback semantics documented.\n- Any new artifacts wired into evidence/replay pathways where applicable.\n\n## Acceptance Criteria\n1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end/integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (`trace_id`, `decision_id`, `policy_id`, `component`, `event`, `outcome`, `error_code`) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document/execute via `rch`-wrapped commands for heavy compilation/test workloads.","acceptance_criteria":"1. Implement the full objective with explicit deterministic behavior, failure semantics, and rollback constraints where applicable.\n2. Add focused unit tests covering normal paths, boundary conditions, invalid/adversarial inputs, and invariant enforcement.\n3. Add end-to-end or integration test scripts that exercise lifecycle transitions and failure recovery paths using deterministic seeds/fixtures and CI-ready command lines.\n4. Emit structured logs with stable fields (trace_id, decision_id, policy_id, component, event, outcome, error_code) and add assertions for critical log events in tests.\n5. Produce reproducibility artifacts (run manifest, replay/evidence pointers, benchmark/check outputs) and document operator verification steps.\n6. For Rust build/test workflows introduced by this bead, document or execute via rch-wrapped commands for heavy compilation/test workloads.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:32:46.843784864Z","created_by":"ubuntu","updated_at":"2026-02-20T08:00:42.179500123Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-10-14"]}
{"id":"bd-zvn","title":"[10.14] FrankenSuite Sibling Integration Track - Comprehensive Execution Epic","description":"Plan Reference: section 10.14 (FrankenSuite Sibling Integration Track).\nPurpose: Convert the plan's intent into an executable, dependency-aware workstream without losing scope, ambition, or proof rigor.\nWhy this exists:\n- Keeps implementation aligned to the ambition-first charter and impossible-by-default capability goals.\n- Prevents drift between strategic language and engineering execution.\n- Ensures every deliverable carries deterministic verification, evidence artifacts, and replay-ready observability.\nRequired quality bar for all child beads:\n1. Include concrete implementation detail, not vague intent.\n2. Require focused unit tests for logic/invariant boundaries.\n3. Require end-to-end/integration scenarios with detailed structured logging (trace/policy/decision identifiers where relevant).\n4. Require artifact publication suitable for reproducibility contracts.\n\n## Success Criteria\n1. All child beads are complete with artifact-backed acceptance evidence (including unit tests, deterministic e2e/integration scripts, and structured logging validation).\n2. Section-level dependencies remain acyclic and executable in dependency order with no unresolved critical blockers.\n3. Reproducibility/evidence expectations are satisfied (replayability, benchmark/correctness artifacts, and operator verification instructions).\n4. Deliverables preserve full PLAN scope and capability intent with no silent feature/functionality reduction.","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-20T07:32:19.072342452Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:57.211028442Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-epic","plan","section-10-14"],"dependencies":[{"issue_id":"bd-zvn","depends_on_id":"bd-1ad6","type":"parent-child","created_at":"2026-02-20T07:52:43.346811442Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-1coe","type":"parent-child","created_at":"2026-02-20T07:52:43.679639987Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-1edh","type":"parent-child","created_at":"2026-02-20T07:52:43.879910219Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-1ps3","type":"parent-child","created_at":"2026-02-20T07:52:45.455616951Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-1qgn","type":"parent-child","created_at":"2026-02-20T07:52:45.495117745Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-26qa","type":"parent-child","created_at":"2026-02-20T07:52:46.919061405Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-2d21","type":"parent-child","created_at":"2026-02-20T07:52:47.623806439Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-2l0x","type":"parent-child","created_at":"2026-02-20T07:52:48.373481580Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-30vf","type":"parent-child","created_at":"2026-02-20T07:52:50.739553002Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-3azm","type":"parent-child","created_at":"2026-02-20T07:52:51.625613273Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-3nr","type":"blocks","created_at":"2026-02-20T07:32:57.715391711Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-3o95","type":"parent-child","created_at":"2026-02-20T07:52:53.114680753Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-89l2","type":"parent-child","created_at":"2026-02-20T07:52:54.995524254Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-rr94","type":"parent-child","created_at":"2026-02-20T07:52:56.503033824Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zvn","depends_on_id":"bd-yqg5","type":"parent-child","created_at":"2026-02-20T07:52:57.210951659Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-zze6","title":"[14] Throughput claims must be accompanied by latency/error envelopes so speedups cannot hide tail-collapse or correctness loss.","description":"Plan Reference: section 14 (Public Benchmark + Standardization Strategy).\nObjective: Throughput claims must be accompanied by latency/error envelopes so speedups cannot hide tail-collapse or correctness loss.\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:31.392914698Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:42.178504260Z","closed_at":"2026-02-20T07:41:20.401677447Z","close_reason":"Consolidated into coherent benchmark implementation beads","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-14"]}
{"id":"bd-zzgz","title":"[13] proof-specialized execution lanes show measurable throughput or tail-latency improvement versus ambient-authority lanes at equivalent semantics","description":"Plan Reference: section 13 (Program Success Criteria).\nObjective: proof-specialized execution lanes show measurable throughput or tail-latency improvement versus ambient-authority lanes at equivalent semantics\nContext and rationale:\n- This item is part of the project's non-optional governance, verification, or adoption contract.\n- It exists to ensure technical claims remain auditable, reproducible, and externally defensible.\nImplementation requirements:\n1. Define precise interfaces/artifacts/checks needed for this objective.\n2. Integrate with existing evidence/replay/benchmark/control surfaces where relevant.\n3. Document operator/developer workflows and rollback/failure behavior.\nValidation requirements:\n- Unit tests for parsing/rules/logic where code is introduced.\n- End-to-end or system-level scenarios with detailed logging and deterministic assertions.\n- Artifact outputs compatible with reproducibility and independent verification workflows.\nDone definition:\n- Objective implemented with tests and observability.\n- Dependencies and operational runbooks updated.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:34:26.640725162Z","created_by":"ubuntu","updated_at":"2026-02-20T07:52:42.218405901Z","closed_at":"2026-02-20T07:39:57.492950760Z","close_reason":"Consolidated into comprehensive program success criteria bead","source_repo":".","compaction_level":0,"original_size":0,"labels":["detailed","plan","section-13"]}
