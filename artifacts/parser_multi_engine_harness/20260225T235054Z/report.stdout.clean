  2026-02-26T00:06:50.345329Z  INFO rch::hook: Selected worker: vmi1153651 at root@38.242.134.66 (6 slots, speed 50.0)
    at rch/src/hook.rs:284 on ThreadId(1)

  2026-02-26T00:06:55.543657Z  INFO rch::hook: Starting remote compilation pipeline for franken_engine (hash: 9963725bd422d0d6)
    at rch/src/hook.rs:4112 on ThreadId(1)

  2026-02-26T00:06:55.543722Z  INFO rch::hook: Prepared dependency sync manifest for 7 roots
    at rch/src/hook.rs:4134 on ThreadId(1)

  2026-02-26T00:06:58.642841Z  WARN rch::hook: repo_updater sync-dry-run failed on vmi1153651 attempt 1/3 (status Some(4)): ✗ Unknown option: --format
ru - Repo Updater

A beautiful, automation-friendly CLI for synchronizing GitHub repositories.

USAGE:
    ru [command] [options]

COMMANDS:
    sync            Clone missing repos and pull updates (default)
    status          Show repository status without making changes
    init            Initialize configuration directory and files
    add <repo>      Add a repository to your list
    remove <repo>   Remove a repository from your list
    list            Show configured repositories
    doctor          Run system diagnostics
    self-update     Update ru to the latest version
    config          Show or set configuration values
    prune           Find and manage orphan repositories
    import <file>   Import repos from file with auto visibility detection
    review          Review GitHub issues and PRs using Claude Code

GLOBAL OPTIONS:
    -h, --help           Show this help message
    -v, --version        Show version
    --json               Output JSON to stdout
    -q, --quiet          Minimal output (errors only)
    --verbose            Detailed output
    --non-interactive    Never prompt (for CI/automation)

SYNC OPTIONS:
    --clone-only         Only clone missing repos, don't pull
    --pull-only          Only pull existing repos, don't clone
    --autostash          Stash changes before pull, pop after
    --rebase             Use git pull --rebase
    --dry-run            Show what would happen without making changes
    --dir PATH           Override projects directory
    --parallel N, -j N   Sync N repos concurrently (default: 1, sequential)
    --resume             Resume an interrupted sync from where it left off
    --restart            Discard interrupted sync state and start fresh
    --timeout SECONDS    Network timeout for slow operations (default: 30)

STATUS OPTIONS:
    --fetch              Fetch remotes first (default)
    --no-fetch           Skip fetch, use cached state

INIT OPTIONS:
    --example            Include example repositories in initial config

ADD OPTIONS:
    --private            Add to private.txt instead of repos.txt
    --from-cwd           Detect repo from current working directory

LIST OPTIONS:
    --paths              Show local paths instead of URLs
    --public             Show only repos from repos.txt
    --private            Show only repos from private.txt

DOCTOR OPTIONS:
    --review             Include review command prerequisites

PRUNE OPTIONS:
    (no options)         List orphan repositories (dry run)
    --archive            Move orphans to archive directory
    --delete             Delete orphans (requires confirmation)

IMPORT OPTIONS:
    --public             Force all repos to be added as public
    --private            Force all repos to be added as private
    --dry-run            Preview import without modifying config

REVIEW OPTIONS:
    --plan               Generate review plans only, no mutations (default)
    --apply              Execute approved plans from previous --plan run
    --analytics          Show review metrics dashboard and exit
    --basic              Use basic question TUI (gum/ANSI) and exit
    --mode=MODE          Driver: auto, ntm, or local (default: auto)
    --parallel=N, -jN    Concurrent review sessions (default: 4)
    --repos=PATTERN      Filter repos by pattern
    --priority=LEVEL     Min priority: all, critical, high, normal, low
    --skip-days=N        Skip repos reviewed within N days (default: 7)
    --dry-run            Discovery only, don't start sessions
    --status             Show review lock/checkpoint status and exit
    --resume             Resume interrupted review from checkpoint
    --push               Allow pushing changes (with --apply)
    --auto-answer=POLICY Auto-answer policy in non-interactive mode (auto|skip|fail)
    --invalidate-cache=R Invalidate digest cache for repo(s) (use "all" for all)
    --max-repos=N        Limit number of repos to review
    --max-runtime=MIN    Time budget in minutes
    --max-questions=N    Question budget before pausing

EXAMPLES:
    ru sync              Sync all configured repos
    ru sync --dry-run    Preview sync without changes
    ru status            Show status of all repos
    ru add owner/repo    Add a repository
    ru remove owner/repo Remove a repository
    ru doctor            Check system configuration
    ru prune             Find orphan repos not in config
    ru doctor --review   Check system and review prerequisites
    ru prune --archive   Archive orphan repos
    ru import repos.txt  Import repos from file (auto-detects visibility)
    ru review --dry-run  Discover issues/PRs without starting reviews
    ru review --status   Show review lock/checkpoint status
    ru review            Start AI-assisted review of issues/PRs
    ru review --apply    Execute approved changes from plan
    ru review --basic    Answer queued review questions
    ru review --analytics Show review analytics dashboard

CONFIGURATION:
    Config:  ~/.config/ru/config
    Repos:   ~/.config/ru/repos.d/repos.txt
    Logs:    ~/.local/state/ru/logs/

EXIT CODES:
    0  Success
    1  Partial failure (some repos failed)
    2  Conflicts exist (need manual resolution)
    3  Dependency/system error (gh missing, auth failed, doctor issues)
    4  Invalid arguments
    5  Interrupted sync detected (use --resume or --restart)

More info: https://github.com/Dicklesworthstone/repo_updater
    at rch/src/hook.rs:2771 on ThreadId(1)

  2026-02-26T00:07:00.550630Z  WARN rch::hook: repo_updater sync-dry-run failed on vmi1153651 attempt 2/3 (status Some(4)): ✗ Unknown option: --format
ru - Repo Updater

A beautiful, automation-friendly CLI for synchronizing GitHub repositories.

USAGE:
    ru [command] [options]

COMMANDS:
    sync            Clone missing repos and pull updates (default)
    status          Show repository status without making changes
    init            Initialize configuration directory and files
    add <repo>      Add a repository to your list
    remove <repo>   Remove a repository from your list
    list            Show configured repositories
    doctor          Run system diagnostics
    self-update     Update ru to the latest version
    config          Show or set configuration values
    prune           Find and manage orphan repositories
    import <file>   Import repos from file with auto visibility detection
    review          Review GitHub issues and PRs using Claude Code

GLOBAL OPTIONS:
    -h, --help           Show this help message
    -v, --version        Show version
    --json               Output JSON to stdout
    -q, --quiet          Minimal output (errors only)
    --verbose            Detailed output
    --non-interactive    Never prompt (for CI/automation)

SYNC OPTIONS:
    --clone-only         Only clone missing repos, don't pull
    --pull-only          Only pull existing repos, don't clone
    --autostash          Stash changes before pull, pop after
    --rebase             Use git pull --rebase
    --dry-run            Show what would happen without making changes
    --dir PATH           Override projects directory
    --parallel N, -j N   Sync N repos concurrently (default: 1, sequential)
    --resume             Resume an interrupted sync from where it left off
    --restart            Discard interrupted sync state and start fresh
    --timeout SECONDS    Network timeout for slow operations (default: 30)

STATUS OPTIONS:
    --fetch              Fetch remotes first (default)
    --no-fetch           Skip fetch, use cached state

INIT OPTIONS:
    --example            Include example repositories in initial config

ADD OPTIONS:
    --private            Add to private.txt instead of repos.txt
    --from-cwd           Detect repo from current working directory

LIST OPTIONS:
    --paths              Show local paths instead of URLs
    --public             Show only repos from repos.txt
    --private            Show only repos from private.txt

DOCTOR OPTIONS:
    --review             Include review command prerequisites

PRUNE OPTIONS:
    (no options)         List orphan repositories (dry run)
    --archive            Move orphans to archive directory
    --delete             Delete orphans (requires confirmation)

IMPORT OPTIONS:
    --public             Force all repos to be added as public
    --private            Force all repos to be added as private
    --dry-run            Preview import without modifying config

REVIEW OPTIONS:
    --plan               Generate review plans only, no mutations (default)
    --apply              Execute approved plans from previous --plan run
    --analytics          Show review metrics dashboard and exit
    --basic              Use basic question TUI (gum/ANSI) and exit
    --mode=MODE          Driver: auto, ntm, or local (default: auto)
    --parallel=N, -jN    Concurrent review sessions (default: 4)
    --repos=PATTERN      Filter repos by pattern
    --priority=LEVEL     Min priority: all, critical, high, normal, low
    --skip-days=N        Skip repos reviewed within N days (default: 7)
    --dry-run            Discovery only, don't start sessions
    --status             Show review lock/checkpoint status and exit
    --resume             Resume interrupted review from checkpoint
    --push               Allow pushing changes (with --apply)
    --auto-answer=POLICY Auto-answer policy in non-interactive mode (auto|skip|fail)
    --invalidate-cache=R Invalidate digest cache for repo(s) (use "all" for all)
    --max-repos=N        Limit number of repos to review
    --max-runtime=MIN    Time budget in minutes
    --max-questions=N    Question budget before pausing

EXAMPLES:
    ru sync              Sync all configured repos
    ru sync --dry-run    Preview sync without changes
    ru status            Show status of all repos
    ru add owner/repo    Add a repository
    ru remove owner/repo Remove a repository
    ru doctor            Check system configuration
    ru prune             Find orphan repos not in config
    ru doctor --review   Check system and review prerequisites
    ru prune --archive   Archive orphan repos
    ru import repos.txt  Import repos from file (auto-detects visibility)
    ru review --dry-run  Discover issues/PRs without starting reviews
    ru review --status   Show review lock/checkpoint status
    ru review            Start AI-assisted review of issues/PRs
    ru review --apply    Execute approved changes from plan
    ru review --basic    Answer queued review questions
    ru review --analytics Show review analytics dashboard

CONFIGURATION:
    Config:  ~/.config/ru/config
    Repos:   ~/.config/ru/repos.d/repos.txt
    Logs:    ~/.local/state/ru/logs/

EXIT CODES:
    0  Success
    1  Partial failure (some repos failed)
    2  Conflicts exist (need manual resolution)
    3  Dependency/system error (gh missing, auth failed, doctor issues)
    4  Invalid arguments
    5  Interrupted sync detected (use --resume or --restart)

More info: https://github.com/Dicklesworthstone/repo_updater
    at rch/src/hook.rs:2771 on ThreadId(1)

  2026-02-26T00:07:02.779637Z  WARN rch::hook: repo_updater sync-dry-run failed on vmi1153651 attempt 3/3 (status Some(4)): ✗ Unknown option: --format
ru - Repo Updater

A beautiful, automation-friendly CLI for synchronizing GitHub repositories.

USAGE:
    ru [command] [options]

COMMANDS:
    sync            Clone missing repos and pull updates (default)
    status          Show repository status without making changes
    init            Initialize configuration directory and files
    add <repo>      Add a repository to your list
    remove <repo>   Remove a repository from your list
    list            Show configured repositories
    doctor          Run system diagnostics
    self-update     Update ru to the latest version
    config          Show or set configuration values
    prune           Find and manage orphan repositories
    import <file>   Import repos from file with auto visibility detection
    review          Review GitHub issues and PRs using Claude Code

GLOBAL OPTIONS:
    -h, --help           Show this help message
    -v, --version        Show version
    --json               Output JSON to stdout
    -q, --quiet          Minimal output (errors only)
    --verbose            Detailed output
    --non-interactive    Never prompt (for CI/automation)

SYNC OPTIONS:
    --clone-only         Only clone missing repos, don't pull
    --pull-only          Only pull existing repos, don't clone
    --autostash          Stash changes before pull, pop after
    --rebase             Use git pull --rebase
    --dry-run            Show what would happen without making changes
    --dir PATH           Override projects directory
    --parallel N, -j N   Sync N repos concurrently (default: 1, sequential)
    --resume             Resume an interrupted sync from where it left off
    --restart            Discard interrupted sync state and start fresh
    --timeout SECONDS    Network timeout for slow operations (default: 30)

STATUS OPTIONS:
    --fetch              Fetch remotes first (default)
    --no-fetch           Skip fetch, use cached state

INIT OPTIONS:
    --example            Include example repositories in initial config

ADD OPTIONS:
    --private            Add to private.txt instead of repos.txt
    --from-cwd           Detect repo from current working directory

LIST OPTIONS:
    --paths              Show local paths instead of URLs
    --public             Show only repos from repos.txt
    --private            Show only repos from private.txt

DOCTOR OPTIONS:
    --review             Include review command prerequisites

PRUNE OPTIONS:
    (no options)         List orphan repositories (dry run)
    --archive            Move orphans to archive directory
    --delete             Delete orphans (requires confirmation)

IMPORT OPTIONS:
    --public             Force all repos to be added as public
    --private            Force all repos to be added as private
    --dry-run            Preview import without modifying config

REVIEW OPTIONS:
    --plan               Generate review plans only, no mutations (default)
    --apply              Execute approved plans from previous --plan run
    --analytics          Show review metrics dashboard and exit
    --basic              Use basic question TUI (gum/ANSI) and exit
    --mode=MODE          Driver: auto, ntm, or local (default: auto)
    --parallel=N, -jN    Concurrent review sessions (default: 4)
    --repos=PATTERN      Filter repos by pattern
    --priority=LEVEL     Min priority: all, critical, high, normal, low
    --skip-days=N        Skip repos reviewed within N days (default: 7)
    --dry-run            Discovery only, don't start sessions
    --status             Show review lock/checkpoint status and exit
    --resume             Resume interrupted review from checkpoint
    --push               Allow pushing changes (with --apply)
    --auto-answer=POLICY Auto-answer policy in non-interactive mode (auto|skip|fail)
    --invalidate-cache=R Invalidate digest cache for repo(s) (use "all" for all)
    --max-repos=N        Limit number of repos to review
    --max-runtime=MIN    Time budget in minutes
    --max-questions=N    Question budget before pausing

EXAMPLES:
    ru sync              Sync all configured repos
    ru sync --dry-run    Preview sync without changes
    ru status            Show status of all repos
    ru add owner/repo    Add a repository
    ru remove owner/repo Remove a repository
    ru doctor            Check system configuration
    ru prune             Find orphan repos not in config
    ru doctor --review   Check system and review prerequisites
    ru prune --archive   Archive orphan repos
    ru import repos.txt  Import repos from file (auto-detects visibility)
    ru review --dry-run  Discover issues/PRs without starting reviews
    ru review --status   Show review lock/checkpoint status
    ru review            Start AI-assisted review of issues/PRs
    ru review --apply    Execute approved changes from plan
    ru review --basic    Answer queued review questions
    ru review --analytics Show review analytics dashboard

CONFIGURATION:
    Config:  ~/.config/ru/config
    Repos:   ~/.config/ru/repos.d/repos.txt
    Logs:    ~/.local/state/ru/logs/

EXIT CODES:
    0  Success
    1  Partial failure (some repos failed)
    2  Conflicts exist (need manual resolution)
    3  Dependency/system error (gh missing, auth failed, doctor issues)
    4  Invalid arguments
    5  Interrupted sync detected (use --resume or --restart)

More info: https://github.com/Dicklesworthstone/repo_updater
    at rch/src/hook.rs:2771 on ThreadId(1)

  2026-02-26T00:07:04.825124Z  WARN rch::hook: repo_updater sync-apply failed on vmi1153651 attempt 1/3 (status Some(4)): ✗ Unknown option: --format
ru - Repo Updater

A beautiful, automation-friendly CLI for synchronizing GitHub repositories.

USAGE:
    ru [command] [options]

COMMANDS:
    sync            Clone missing repos and pull updates (default)
    status          Show repository status without making changes
    init            Initialize configuration directory and files
    add <repo>      Add a repository to your list
    remove <repo>   Remove a repository from your list
    list            Show configured repositories
    doctor          Run system diagnostics
    self-update     Update ru to the latest version
    config          Show or set configuration values
    prune           Find and manage orphan repositories
    import <file>   Import repos from file with auto visibility detection
    review          Review GitHub issues and PRs using Claude Code

GLOBAL OPTIONS:
    -h, --help           Show this help message
    -v, --version        Show version
    --json               Output JSON to stdout
    -q, --quiet          Minimal output (errors only)
    --verbose            Detailed output
    --non-interactive    Never prompt (for CI/automation)

SYNC OPTIONS:
    --clone-only         Only clone missing repos, don't pull
    --pull-only          Only pull existing repos, don't clone
    --autostash          Stash changes before pull, pop after
    --rebase             Use git pull --rebase
    --dry-run            Show what would happen without making changes
    --dir PATH           Override projects directory
    --parallel N, -j N   Sync N repos concurrently (default: 1, sequential)
    --resume             Resume an interrupted sync from where it left off
    --restart            Discard interrupted sync state and start fresh
    --timeout SECONDS    Network timeout for slow operations (default: 30)

STATUS OPTIONS:
    --fetch              Fetch remotes first (default)
    --no-fetch           Skip fetch, use cached state

INIT OPTIONS:
    --example            Include example repositories in initial config

ADD OPTIONS:
    --private            Add to private.txt instead of repos.txt
    --from-cwd           Detect repo from current working directory

LIST OPTIONS:
    --paths              Show local paths instead of URLs
    --public             Show only repos from repos.txt
    --private            Show only repos from private.txt

DOCTOR OPTIONS:
    --review             Include review command prerequisites

PRUNE OPTIONS:
    (no options)         List orphan repositories (dry run)
    --archive            Move orphans to archive directory
    --delete             Delete orphans (requires confirmation)

IMPORT OPTIONS:
    --public             Force all repos to be added as public
    --private            Force all repos to be added as private
    --dry-run            Preview import without modifying config

REVIEW OPTIONS:
    --plan               Generate review plans only, no mutations (default)
    --apply              Execute approved plans from previous --plan run
    --analytics          Show review metrics dashboard and exit
    --basic              Use basic question TUI (gum/ANSI) and exit
    --mode=MODE          Driver: auto, ntm, or local (default: auto)
    --parallel=N, -jN    Concurrent review sessions (default: 4)
    --repos=PATTERN      Filter repos by pattern
    --priority=LEVEL     Min priority: all, critical, high, normal, low
    --skip-days=N        Skip repos reviewed within N days (default: 7)
    --dry-run            Discovery only, don't start sessions
    --status             Show review lock/checkpoint status and exit
    --resume             Resume interrupted review from checkpoint
    --push               Allow pushing changes (with --apply)
    --auto-answer=POLICY Auto-answer policy in non-interactive mode (auto|skip|fail)
    --invalidate-cache=R Invalidate digest cache for repo(s) (use "all" for all)
    --max-repos=N        Limit number of repos to review
    --max-runtime=MIN    Time budget in minutes
    --max-questions=N    Question budget before pausing

EXAMPLES:
    ru sync              Sync all configured repos
    ru sync --dry-run    Preview sync without changes
    ru status            Show status of all repos
    ru add owner/repo    Add a repository
    ru remove owner/repo Remove a repository
    ru doctor            Check system configuration
    ru prune             Find orphan repos not in config
    ru doctor --review   Check system and review prerequisites
    ru prune --archive   Archive orphan repos
    ru import repos.txt  Import repos from file (auto-detects visibility)
    ru review --dry-run  Discover issues/PRs without starting reviews
    ru review --status   Show review lock/checkpoint status
    ru review            Start AI-assisted review of issues/PRs
    ru review --apply    Execute approved changes from plan
    ru review --basic    Answer queued review questions
    ru review --analytics Show review analytics dashboard

CONFIGURATION:
    Config:  ~/.config/ru/config
    Repos:   ~/.config/ru/repos.d/repos.txt
    Logs:    ~/.local/state/ru/logs/

EXIT CODES:
    0  Success
    1  Partial failure (some repos failed)
    2  Conflicts exist (need manual resolution)
    3  Dependency/system error (gh missing, auth failed, doctor issues)
    4  Invalid arguments
    5  Interrupted sync detected (use --resume or --restart)

More info: https://github.com/Dicklesworthstone/repo_updater
    at rch/src/hook.rs:2771 on ThreadId(1)

  2026-02-26T00:07:06.645948Z  WARN rch::hook: repo_updater sync-apply failed on vmi1153651 attempt 2/3 (status Some(4)): ✗ Unknown option: --format
ru - Repo Updater

A beautiful, automation-friendly CLI for synchronizing GitHub repositories.

USAGE:
    ru [command] [options]

COMMANDS:
    sync            Clone missing repos and pull updates (default)
    status          Show repository status without making changes
    init            Initialize configuration directory and files
    add <repo>      Add a repository to your list
    remove <repo>   Remove a repository from your list
    list            Show configured repositories
    doctor          Run system diagnostics
    self-update     Update ru to the latest version
    config          Show or set configuration values
    prune           Find and manage orphan repositories
    import <file>   Import repos from file with auto visibility detection
    review          Review GitHub issues and PRs using Claude Code

GLOBAL OPTIONS:
    -h, --help           Show this help message
    -v, --version        Show version
    --json               Output JSON to stdout
    -q, --quiet          Minimal output (errors only)
    --verbose            Detailed output
    --non-interactive    Never prompt (for CI/automation)

SYNC OPTIONS:
    --clone-only         Only clone missing repos, don't pull
    --pull-only          Only pull existing repos, don't clone
    --autostash          Stash changes before pull, pop after
    --rebase             Use git pull --rebase
    --dry-run            Show what would happen without making changes
    --dir PATH           Override projects directory
    --parallel N, -j N   Sync N repos concurrently (default: 1, sequential)
    --resume             Resume an interrupted sync from where it left off
    --restart            Discard interrupted sync state and start fresh
    --timeout SECONDS    Network timeout for slow operations (default: 30)

STATUS OPTIONS:
    --fetch              Fetch remotes first (default)
    --no-fetch           Skip fetch, use cached state

INIT OPTIONS:
    --example            Include example repositories in initial config

ADD OPTIONS:
    --private            Add to private.txt instead of repos.txt
    --from-cwd           Detect repo from current working directory

LIST OPTIONS:
    --paths              Show local paths instead of URLs
    --public             Show only repos from repos.txt
    --private            Show only repos from private.txt

DOCTOR OPTIONS:
    --review             Include review command prerequisites

PRUNE OPTIONS:
    (no options)         List orphan repositories (dry run)
    --archive            Move orphans to archive directory
    --delete             Delete orphans (requires confirmation)

IMPORT OPTIONS:
    --public             Force all repos to be added as public
    --private            Force all repos to be added as private
    --dry-run            Preview import without modifying config

REVIEW OPTIONS:
    --plan               Generate review plans only, no mutations (default)
    --apply              Execute approved plans from previous --plan run
    --analytics          Show review metrics dashboard and exit
    --basic              Use basic question TUI (gum/ANSI) and exit
    --mode=MODE          Driver: auto, ntm, or local (default: auto)
    --parallel=N, -jN    Concurrent review sessions (default: 4)
    --repos=PATTERN      Filter repos by pattern
    --priority=LEVEL     Min priority: all, critical, high, normal, low
    --skip-days=N        Skip repos reviewed within N days (default: 7)
    --dry-run            Discovery only, don't start sessions
    --status             Show review lock/checkpoint status and exit
    --resume             Resume interrupted review from checkpoint
    --push               Allow pushing changes (with --apply)
    --auto-answer=POLICY Auto-answer policy in non-interactive mode (auto|skip|fail)
    --invalidate-cache=R Invalidate digest cache for repo(s) (use "all" for all)
    --max-repos=N        Limit number of repos to review
    --max-runtime=MIN    Time budget in minutes
    --max-questions=N    Question budget before pausing

EXAMPLES:
    ru sync              Sync all configured repos
    ru sync --dry-run    Preview sync without changes
    ru status            Show status of all repos
    ru add owner/repo    Add a repository
    ru remove owner/repo Remove a repository
    ru doctor            Check system configuration
    ru prune             Find orphan repos not in config
    ru doctor --review   Check system and review prerequisites
    ru prune --archive   Archive orphan repos
    ru import repos.txt  Import repos from file (auto-detects visibility)
    ru review --dry-run  Discover issues/PRs without starting reviews
    ru review --status   Show review lock/checkpoint status
    ru review            Start AI-assisted review of issues/PRs
    ru review --apply    Execute approved changes from plan
    ru review --basic    Answer queued review questions
    ru review --analytics Show review analytics dashboard

CONFIGURATION:
    Config:  ~/.config/ru/config
    Repos:   ~/.config/ru/repos.d/repos.txt
    Logs:    ~/.local/state/ru/logs/

EXIT CODES:
    0  Success
    1  Partial failure (some repos failed)
    2  Conflicts exist (need manual resolution)
    3  Dependency/system error (gh missing, auth failed, doctor issues)
    4  Invalid arguments
    5  Interrupted sync detected (use --resume or --restart)

More info: https://github.com/Dicklesworthstone/repo_updater
    at rch/src/hook.rs:2771 on ThreadId(1)

  2026-02-26T00:07:08.735039Z  WARN rch::hook: repo_updater sync-apply failed on vmi1153651 attempt 3/3 (status Some(4)): ✗ Unknown option: --format
ru - Repo Updater

A beautiful, automation-friendly CLI for synchronizing GitHub repositories.

USAGE:
    ru [command] [options]

COMMANDS:
    sync            Clone missing repos and pull updates (default)
    status          Show repository status without making changes
    init            Initialize configuration directory and files
    add <repo>      Add a repository to your list
    remove <repo>   Remove a repository from your list
    list            Show configured repositories
    doctor          Run system diagnostics
    self-update     Update ru to the latest version
    config          Show or set configuration values
    prune           Find and manage orphan repositories
    import <file>   Import repos from file with auto visibility detection
    review          Review GitHub issues and PRs using Claude Code

GLOBAL OPTIONS:
    -h, --help           Show this help message
    -v, --version        Show version
    --json               Output JSON to stdout
    -q, --quiet          Minimal output (errors only)
    --verbose            Detailed output
    --non-interactive    Never prompt (for CI/automation)

SYNC OPTIONS:
    --clone-only         Only clone missing repos, don't pull
    --pull-only          Only pull existing repos, don't clone
    --autostash          Stash changes before pull, pop after
    --rebase             Use git pull --rebase
    --dry-run            Show what would happen without making changes
    --dir PATH           Override projects directory
    --parallel N, -j N   Sync N repos concurrently (default: 1, sequential)
    --resume             Resume an interrupted sync from where it left off
    --restart            Discard interrupted sync state and start fresh
    --timeout SECONDS    Network timeout for slow operations (default: 30)

STATUS OPTIONS:
    --fetch              Fetch remotes first (default)
    --no-fetch           Skip fetch, use cached state

INIT OPTIONS:
    --example            Include example repositories in initial config

ADD OPTIONS:
    --private            Add to private.txt instead of repos.txt
    --from-cwd           Detect repo from current working directory

LIST OPTIONS:
    --paths              Show local paths instead of URLs
    --public             Show only repos from repos.txt
    --private            Show only repos from private.txt

DOCTOR OPTIONS:
    --review             Include review command prerequisites

PRUNE OPTIONS:
    (no options)         List orphan repositories (dry run)
    --archive            Move orphans to archive directory
    --delete             Delete orphans (requires confirmation)

IMPORT OPTIONS:
    --public             Force all repos to be added as public
    --private            Force all repos to be added as private
    --dry-run            Preview import without modifying config

REVIEW OPTIONS:
    --plan               Generate review plans only, no mutations (default)
    --apply              Execute approved plans from previous --plan run
    --analytics          Show review metrics dashboard and exit
    --basic              Use basic question TUI (gum/ANSI) and exit
    --mode=MODE          Driver: auto, ntm, or local (default: auto)
    --parallel=N, -jN    Concurrent review sessions (default: 4)
    --repos=PATTERN      Filter repos by pattern
    --priority=LEVEL     Min priority: all, critical, high, normal, low
    --skip-days=N        Skip repos reviewed within N days (default: 7)
    --dry-run            Discovery only, don't start sessions
    --status             Show review lock/checkpoint status and exit
    --resume             Resume interrupted review from checkpoint
    --push               Allow pushing changes (with --apply)
    --auto-answer=POLICY Auto-answer policy in non-interactive mode (auto|skip|fail)
    --invalidate-cache=R Invalidate digest cache for repo(s) (use "all" for all)
    --max-repos=N        Limit number of repos to review
    --max-runtime=MIN    Time budget in minutes
    --max-questions=N    Question budget before pausing

EXAMPLES:
    ru sync              Sync all configured repos
    ru sync --dry-run    Preview sync without changes
    ru status            Show status of all repos
    ru add owner/repo    Add a repository
    ru remove owner/repo Remove a repository
    ru doctor            Check system configuration
    ru prune             Find orphan repos not in config
    ru doctor --review   Check system and review prerequisites
    ru prune --archive   Archive orphan repos
    ru import repos.txt  Import repos from file (auto-detects visibility)
    ru review --dry-run  Discover issues/PRs without starting reviews
    ru review --status   Show review lock/checkpoint status
    ru review            Start AI-assisted review of issues/PRs
    ru review --apply    Execute approved changes from plan
    ru review --basic    Answer queued review questions
    ru review --analytics Show review analytics dashboard

CONFIGURATION:
    Config:  ~/.config/ru/config
    Repos:   ~/.config/ru/repos.d/repos.txt
    Logs:    ~/.local/state/ru/logs/

EXIT CODES:
    0  Success
    1  Partial failure (some repos failed)
    2  Conflicts exist (need manual resolution)
    3  Dependency/system error (gh missing, auth failed, doctor issues)
    4  Invalid arguments
    5  Interrupted sync detected (use --resume or --restart)

More info: https://github.com/Dicklesworthstone/repo_updater
    at rch/src/hook.rs:2771 on ThreadId(1)

  2026-02-26T00:07:08.735138Z  INFO rch::hook: Syncing project to worker vmi1153651...
    at rch/src/hook.rs:4158 on ThreadId(1)

  2026-02-26T00:07:08.735182Z  INFO rch::transfer: Syncing /data/projects/asupersync/franken_decision -> /data/projects/asupersync/franken_decision on vmi1153651
    at rch/src/transfer.rs:927 on ThreadId(1)

  2026-02-26T00:07:10.824208Z  INFO rch::transfer: Sync completed in 2089ms
    at rch/src/transfer.rs:996 on ThreadId(1)

  2026-02-26T00:07:10.824286Z  INFO rch::transfer: Syncing /data/projects/asupersync/franken_evidence -> /data/projects/asupersync/franken_evidence on vmi1153651
    at rch/src/transfer.rs:927 on ThreadId(1)

  2026-02-26T00:07:12.857698Z  INFO rch::transfer: Sync completed in 2033ms
    at rch/src/transfer.rs:996 on ThreadId(1)

  2026-02-26T00:07:12.857772Z  INFO rch::transfer: Syncing /data/projects/asupersync/franken_kernel -> /data/projects/asupersync/franken_kernel on vmi1153651
    at rch/src/transfer.rs:927 on ThreadId(1)

  2026-02-26T00:07:14.972821Z  INFO rch::transfer: Sync completed in 2115ms
    at rch/src/transfer.rs:996 on ThreadId(1)

  2026-02-26T00:07:14.972899Z  INFO rch::transfer: Syncing /data/projects/franken_engine -> /data/projects/franken_engine on vmi1153651
    at rch/src/transfer.rs:927 on ThreadId(1)

  2026-02-26T00:07:20.038137Z  INFO rch::transfer: Sync completed in 5065ms
    at rch/src/transfer.rs:996 on ThreadId(1)

  2026-02-26T00:07:20.038198Z  INFO rch::transfer: Syncing /data/projects/franken_engine/crates/franken-engine -> /data/projects/franken_engine/crates/franken-engine on vmi1153651
    at rch/src/transfer.rs:927 on ThreadId(1)

  2026-02-26T00:07:22.371338Z  INFO rch::transfer: Sync completed in 2333ms
    at rch/src/transfer.rs:996 on ThreadId(1)

  2026-02-26T00:07:22.371419Z  INFO rch::transfer: Syncing /data/projects/franken_engine/crates/franken-extension-host -> /data/projects/franken_engine/crates/franken-extension-host on vmi1153651
    at rch/src/transfer.rs:927 on ThreadId(1)

  2026-02-26T00:07:24.470330Z  INFO rch::transfer: Sync completed in 2098ms
    at rch/src/transfer.rs:996 on ThreadId(1)

  2026-02-26T00:07:24.470409Z  INFO rch::transfer: Syncing /data/projects/franken_engine/crates/franken-metamorphic -> /data/projects/franken_engine/crates/franken-metamorphic on vmi1153651
    at rch/src/transfer.rs:927 on ThreadId(1)

  2026-02-26T00:07:26.529577Z  INFO rch::transfer: Sync completed in 2059ms
    at rch/src/transfer.rs:996 on ThreadId(1)

  2026-02-26T00:07:26.529622Z  INFO rch::hook: Sync complete: 24112 files, 787184 bytes in 17792ms
    at rch/src/hook.rs:4304 on ThreadId(1)

  2026-02-26T00:07:33.065239Z  INFO rch::hook: Executing command remotely: env RUSTUP_TOOLCHAIN=nightly CARGO_TARGET_DIR=/tmp/rch_target_franken_engine_parser_multi_engine_harness cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --fixture-limit 8 --seed 7 --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1 --locale C --timezone UTC --out artifacts/parser_multi_engine_harness/20260225T235054Z/report.json
    at rch/src/hook.rs:4331 on ThreadId(1)

  2026-02-26T00:07:33.065271Z  INFO rch::transfer: Wrapping command with external timeout protection, kind: cargo build, timeout_secs: 300
    at rch/src/transfer.rs:688 on ThreadId(1)

   Compiling frankenengine-engine v0.1.0 (/data/projects/franken_engine/crates/franken-engine)
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 1m 34s
     Running `/tmp/rch_target_franken_engine_parser_multi_engine_harness/debug/franken_parser_multi_engine_harness --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --fixture-limit 8 --seed 7 --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1 --locale C --timezone UTC --out artifacts/parser_multi_engine_harness/20260225T235054Z/report.json`
{
  "schema_version": "franken-engine.parser-multi-engine.report.v2",
  "generated_at_utc": "2026-02-26T00:09:09Z",
  "run_id": "sha256:881d83a311cd4b3a7b71b2a3b1ed1f0a459671afa5475f47f79871c044e6132a",
  "trace_id": "trace-parser-multi-engine-harness-20260225T235054Z",
  "decision_id": "decision-parser-multi-engine-harness-20260225T235054Z",
  "policy_id": "policy-parser-multi-engine-harness-v1",
  "fixture_catalog_path": "crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json",
  "fixture_catalog_hash": "sha256:223e5161db6cbff5d3da21c222825f609cc39e4ed7727c2bcceba92ad96ab056",
  "parser_mode": "scalar_reference",
  "seed": 7,
  "locale": "C",
  "timezone": "UTC",
  "fixture_count": 8,
  "engine_specs": [
    {
      "engine_id": "franken_canonical",
      "display_name": "FrankenEngine Canonical Parser",
      "kind": "franken_canonical",
      "version_pin": "frankenengine-engine@workspace",
      "command": null,
      "args": []
    },
    {
      "engine_id": "fixture_expected_hash",
      "display_name": "Fixture Expected Hash Baseline",
      "kind": "fixture_expected_hash",
      "version_pin": "fixture-catalog@phase0-v1",
      "command": null,
      "args": []
    }
  ],
  "parser_telemetry": {
    "schema_version": "franken-engine.parser-telemetry.v1",
    "sample_count": 16,
    "throughput_sources_per_second_millionths": 3741814780,
    "throughput_mib_per_second_millionths": 22302,
    "latency_ns_p50": 257000,
    "latency_ns_p95": 371000,
    "latency_ns_p99": 371000,
    "ns_per_token_millionths": 152714285714,
    "allocs_per_token_millionths": 2428571,
    "bytes_per_source_avg": 6,
    "tokens_per_source_avg": 1,
    "peak_rss_bytes": 3678208
  },
  "summary": {
    "total_fixtures": 8,
    "equivalent_fixtures": 8,
    "divergent_fixtures": 0,
    "fixtures_with_nondeterminism": 0,
    "drift_minor_fixtures": 0,
    "drift_critical_fixtures": 0,
    "drift_counts_by_category": {}
  },
  "fixture_results": [
    {
      "fixture_id": "script_identifier",
      "family_id": "statement.expression",
      "goal": "script",
      "source_hash": "sha256:8ed3f6ad685b959ead7022518e1af76cd816f8e8ec7ccdda1ed4018e8f2223f8",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_identifier --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 515786947179751381,
          "first_run": {
            "kind": "hash",
            "value": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a",
            "deterministic": true,
            "duration_us": 259,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a",
            "deterministic": true,
            "duration_us": 257,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 14688422264879224774,
          "first_run": {
            "kind": "hash",
            "value": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a07edc8a5c638cc207bd432c9023fe49638763bdc29835f5f058064d688ff8a"
            }
          }
        }
      ]
    },
    {
      "fixture_id": "script_numeric_signed",
      "family_id": "literal.numeric_signed_i64",
      "goal": "script",
      "source_hash": "sha256:a770d3270c9dcdedf12ed9fd70444f7c8a95c26cae3cae9bd867499090a2f14b",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_numeric_signed --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 15719662148193577839,
          "first_run": {
            "kind": "hash",
            "value": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4",
            "deterministic": true,
            "duration_us": 242,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4",
            "deterministic": true,
            "duration_us": 227,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 10313179175436143987,
          "first_run": {
            "kind": "hash",
            "value": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:d959b7cbce9a409871d9a288d6feb3c043bdf3ce6ee54ff39051909db432adc4"
            }
          }
        }
      ]
    },
    {
      "fixture_id": "script_string",
      "family_id": "literal.string_single_double_quote",
      "goal": "script",
      "source_hash": "sha256:5aa762ae383fbb727af3c7a36d4940a5b8c40a989452d2304fc958ff3f354e7a",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_string --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 6090001423694011095,
          "first_run": {
            "kind": "hash",
            "value": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125",
            "deterministic": true,
            "duration_us": 249,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125",
            "deterministic": true,
            "duration_us": 371,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 10397902231069728896,
          "first_run": {
            "kind": "hash",
            "value": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:2d22eb6cf286e1c9df2260a49d1fd7fd3d49fd78b5a768522203402fa466b125"
            }
          }
        }
      ]
    },
    {
      "fixture_id": "script_boolean",
      "family_id": "literal.boolean",
      "goal": "script",
      "source_hash": "sha256:b5bea41b6c623f7c09f1bf24dcae58ebab3c0cdd90ad966bc43a45b44867e12b",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_boolean --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 18144005667927601117,
          "first_run": {
            "kind": "hash",
            "value": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855",
            "deterministic": true,
            "duration_us": 282,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855",
            "deterministic": true,
            "duration_us": 180,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 12062810660187563705,
          "first_run": {
            "kind": "hash",
            "value": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:e8563a21efb68e6939c9a81f736ab6009cc99ce19daca3e7bc620aba847b7855"
            }
          }
        }
      ]
    },
    {
      "fixture_id": "script_null",
      "family_id": "literal.null",
      "goal": "script",
      "source_hash": "sha256:74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_null --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 7240621484153917693,
          "first_run": {
            "kind": "hash",
            "value": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a",
            "deterministic": true,
            "duration_us": 214,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a",
            "deterministic": true,
            "duration_us": 228,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 12343017309324008314,
          "first_run": {
            "kind": "hash",
            "value": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:5a9979b7cad676cb459bd03b7c2cfa43c6b94fde2bc6a7c3e00a430b4d0a5b2a"
            }
          }
        }
      ]
    },
    {
      "fixture_id": "script_undefined",
      "family_id": "literal.undefined",
      "goal": "script",
      "source_hash": "sha256:eb045d78d273107348b0300c01d29b7552d622abbc6faf81b3ec55359aa9950c",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_undefined --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 2115478872511663410,
          "first_run": {
            "kind": "hash",
            "value": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f",
            "deterministic": true,
            "duration_us": 348,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f",
            "deterministic": true,
            "duration_us": 224,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 12617272629058508906,
          "first_run": {
            "kind": "hash",
            "value": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:0c28b681a522f99cebea13bc3b803fb92c22422c05b13927f734f475008a688f"
            }
          }
        }
      ]
    },
    {
      "fixture_id": "script_await",
      "family_id": "expression.await",
      "goal": "script",
      "source_hash": "sha256:a1df4a2b85ddcb7af06228e59170052cf8e02e2146b48d228706ff224c3207c7",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_await --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 18061169297927070154,
          "first_run": {
            "kind": "hash",
            "value": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7",
            "deterministic": true,
            "duration_us": 292,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7",
            "deterministic": true,
            "duration_us": 354,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 13956575453232386375,
          "first_run": {
            "kind": "hash",
            "value": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:b4edc109d6bcd04a494a18133607b2b4a68a707834d11228ca0a09c05ce1e8e7"
            }
          }
        }
      ]
    },
    {
      "fixture_id": "script_raw_binary",
      "family_id": "expression.binary_precedence",
      "goal": "script",
      "source_hash": "sha256:e9a74729daea9b844d7bcc267f1eeed2409ea198f1c4f207f841bf3368e4d5fc",
      "equivalent_across_engines": true,
      "nondeterministic_engine_count": 0,
      "divergence_reason": null,
      "replay_command": "cargo run -p frankenengine-engine --bin franken_parser_multi_engine_harness -- --fixture-catalog crates/franken-engine/tests/fixtures/parser_phase0_semantic_fixtures.json --seed 7 --fixture-id script_raw_binary --trace-id trace-parser-multi-engine-harness-20260225T235054Z --decision-id decision-parser-multi-engine-harness-20260225T235054Z --policy-id policy-parser-multi-engine-harness-v1",
      "engine_results": [
        {
          "engine_id": "franken_canonical",
          "display_name": "FrankenEngine Canonical Parser",
          "version_pin": "frankenengine-engine@workspace",
          "derived_seed": 2386689570902096528,
          "first_run": {
            "kind": "hash",
            "value": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d",
            "deterministic": true,
            "duration_us": 295,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d",
            "deterministic": true,
            "duration_us": 254,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d"
            }
          }
        },
        {
          "engine_id": "fixture_expected_hash",
          "display_name": "Fixture Expected Hash Baseline",
          "version_pin": "fixture-catalog@phase0-v1",
          "derived_seed": 7485168832390117500,
          "first_run": {
            "kind": "hash",
            "value": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d"
            }
          },
          "second_run": {
            "kind": "hash",
            "value": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d",
            "deterministic": true,
            "duration_us": 0,
            "normalized_ast": {
              "schema_version": "franken-engine.parser-ast-normalization.v1",
              "adapter": "canonical_hash_passthrough_v1",
              "canonical_hash": "sha256:62a4e52514327b26c52adc6fc35c648bc3ebede50e821c9d72c8e9e2ab75100d"
            }
          }
        }
      ]
    }
  ]
}
  2026-02-26T00:09:09.275522Z  INFO rch::hook: Remote command finished: exit=0 in 96210ms
    at rch/src/hook.rs:4452 on ThreadId(1)

  2026-02-26T00:09:14.276294Z  INFO rch::hook: Retrieving build artifacts...
    at rch/src/hook.rs:4501 on ThreadId(1)

  2026-02-26T00:09:14.276330Z  INFO rch::transfer: Retrieving artifacts from /data/projects/franken_engine on vmi1153651
    at rch/src/transfer.rs:1541 on ThreadId(1)

  2026-02-26T00:09:18.026613Z  INFO rch::transfer: Artifacts retrieved in 3750ms (6599 files, 661563 bytes)
    at rch/src/transfer.rs:1580 on ThreadId(1)

  2026-02-26T00:09:18.026644Z  INFO rch::hook: Artifacts retrieved: 6599 files, 661563 bytes in 3750ms
    at rch/src/hook.rs:4534 on ThreadId(1)

